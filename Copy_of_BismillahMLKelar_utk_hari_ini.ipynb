{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKuLMs_lrvr0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/Trashure-C241-PS226/ML/main/Mobile%20phone%20price.csv'\n",
        "data  = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "jX2SuRmysTdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoders = {}\n",
        "categorical_columns = ['Brand', 'Model']\n",
        "for column in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    data[column] = le.fit_transform(data[column])\n",
        "    label_encoders[column] = le"
      ],
      "metadata": {
        "id": "IbJ4_cyXQUK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_memory_size(memory):\n",
        "    if 'GB' in memory:\n",
        "        return int(memory.replace('GB', ''))\n",
        "    elif 'MB' in memory:\n",
        "        return int(memory.replace('MB', ''))\n",
        "    return int(memory)\n"
      ],
      "metadata": {
        "id": "pMtPPOJIQYx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "desc = data['Price_($)'].describe()\n",
        "\n",
        "# Tentukan batas kategori\n",
        "q1 = desc['25%']\n",
        "q2 = desc['50%']\n",
        "q3 = desc['75%']\n",
        "\n",
        "# Fungsi untuk mengkategorikan harga\n",
        "def categorize_price(price):\n",
        "    if price < q1:\n",
        "        return 0\n",
        "    elif q1 <= price < q2:\n",
        "        return 1\n",
        "    elif q2 <= price < q3:\n",
        "        return 2\n",
        "    else:\n",
        "        return 3\n",
        "\n",
        "# Terapkan fungsi pengategorian\n",
        "data['Category'] = data['Price_($)'].apply(categorize_price)"
      ],
      "metadata": {
        "id": "6WuEx-03fCq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Category'].value_counts()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VD5Qwz4xVws8",
        "outputId": "813a9937-da6a-4c66-c9f1-a07e300112e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Category\n",
              "1    108\n",
              "2    104\n",
              "3    102\n",
              "0     91\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Storage '] = data['Storage '].apply(convert_memory_size)\n",
        "data['RAM '] = data['RAM '].apply(convert_memory_size)\n",
        "\n",
        "data.columns = data.columns.str.strip()\n",
        "data.columns = data.columns.str.replace(' ', '_')\n",
        "\n",
        "# data = data.drop(['Brand'], axis=1)\n",
        "# data = data.drop(['Model'], axis=1)\n",
        "# data = data.drop(['Screen_Size_(inches)'], axis=1)\n",
        "# data = data.drop(['Camera_(MP)'], axis=1)\n",
        "# data = data.drop(['Battery_Capacity_(mAh)'], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data[\"Camera_(MP)\"] = data[\"Camera_(MP)\"].str.replace(\"MP\",\"\")\n",
        "data[\"Camera_(MP)\"] = data[\"Camera_(MP)\"].str.replace(\"D\",\"\")\n",
        "\n",
        "data[\"Camera_(MP)\"] = data[\"Camera_(MP)\"].str.split(\"+\")\n",
        "\n",
        "data = data[~(data[\"Screen_Size_(inches)\"] == \"7.6 (unfolded)\")]\n",
        "data = data[~(data[\"Screen_Size_(inches)\"] == \"6.8 + 3.9\")]\n",
        "data[\"Screen_Size_(inches)\"] = data[\"Screen_Size_(inches)\"].astype(\"float64\")\n",
        "\n",
        "listx = []\n",
        "for i in data.index:\n",
        "    listx.append(data[\"Camera_(MP)\"][i][0])\n",
        "\n",
        "data[\"Camera_(MP)\"] = listx\n",
        "data[\"Camera_(MP)\"] = data[\"Camera_(MP)\"].astype(\"float64\")\n",
        "\n",
        "data['Price_($)'] = data['Price_($)'].str.replace('$','')\n",
        "data['Brand'] = data['Brand'].astype(\"float64\")\n",
        "data['Storage'] = data['Storage'].astype(\"float64\")\n",
        "data['RAM'] = data['RAM'].astype(\"float64\")\n",
        "data['Battery_Capacity_(mAh)'] = data['Battery_Capacity_(mAh)'].astype(\"float64\")\n",
        "data['Price_($)'] = data['Price_($)'].str.replace(',','')\n",
        "data['Price_($)'] = data['Price_($)'].astype(\"float64\")"
      ],
      "metadata": {
        "id": "93-7dgdjQbqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop(['Price_($)'], axis=1)"
      ],
      "metadata": {
        "id": "0Qr4fRulg2_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "JA7IR4XEg-mJ",
        "outputId": "d2d7e17a-dd68-490e-ab50-38ebbc6d8609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Brand  Model  Storage   RAM  Screen_Size_(inches)  Camera_(MP)  \\\n",
              "0      0.0    232    128.0   6.0                  6.10         12.0   \n",
              "1     12.0    100    256.0  12.0                  6.80        108.0   \n",
              "2      9.0     19    128.0   8.0                  6.70         48.0   \n",
              "3     15.0    178    128.0   6.0                  6.67         64.0   \n",
              "4      4.0    162    128.0   8.0                  6.40         50.0   \n",
              "..     ...    ...      ...   ...                   ...          ...   \n",
              "402   12.0     95    128.0   8.0                  6.70         12.0   \n",
              "403   15.0    111    128.0   6.0                  6.57         48.0   \n",
              "404    0.0    229    128.0   6.0                  6.70         12.0   \n",
              "405   10.0    188    128.0   8.0                  6.40         48.0   \n",
              "406   12.0     96    128.0   6.0                  6.70         48.0   \n",
              "\n",
              "     Battery_Capacity_(mAh)  Category  \n",
              "0                    3095.0         3  \n",
              "1                    5000.0         3  \n",
              "2                    4500.0         3  \n",
              "3                    5020.0         1  \n",
              "4                    4614.0         3  \n",
              "..                      ...       ...  \n",
              "402                  4300.0         3  \n",
              "403                  4160.0         2  \n",
              "404                  3687.0         3  \n",
              "405                  4025.0         2  \n",
              "406                  4500.0         3  \n",
              "\n",
              "[405 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e0128e4-296b-4b20-8189-97983c357a0d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Brand</th>\n",
              "      <th>Model</th>\n",
              "      <th>Storage</th>\n",
              "      <th>RAM</th>\n",
              "      <th>Screen_Size_(inches)</th>\n",
              "      <th>Camera_(MP)</th>\n",
              "      <th>Battery_Capacity_(mAh)</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>232</td>\n",
              "      <td>128.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.10</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3095.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12.0</td>\n",
              "      <td>100</td>\n",
              "      <td>256.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>6.80</td>\n",
              "      <td>108.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.0</td>\n",
              "      <td>19</td>\n",
              "      <td>128.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.70</td>\n",
              "      <td>48.0</td>\n",
              "      <td>4500.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15.0</td>\n",
              "      <td>178</td>\n",
              "      <td>128.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.67</td>\n",
              "      <td>64.0</td>\n",
              "      <td>5020.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>162</td>\n",
              "      <td>128.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.40</td>\n",
              "      <td>50.0</td>\n",
              "      <td>4614.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>12.0</td>\n",
              "      <td>95</td>\n",
              "      <td>128.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.70</td>\n",
              "      <td>12.0</td>\n",
              "      <td>4300.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>403</th>\n",
              "      <td>15.0</td>\n",
              "      <td>111</td>\n",
              "      <td>128.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.57</td>\n",
              "      <td>48.0</td>\n",
              "      <td>4160.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404</th>\n",
              "      <td>0.0</td>\n",
              "      <td>229</td>\n",
              "      <td>128.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.70</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3687.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405</th>\n",
              "      <td>10.0</td>\n",
              "      <td>188</td>\n",
              "      <td>128.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.40</td>\n",
              "      <td>48.0</td>\n",
              "      <td>4025.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>406</th>\n",
              "      <td>12.0</td>\n",
              "      <td>96</td>\n",
              "      <td>128.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.70</td>\n",
              "      <td>48.0</td>\n",
              "      <td>4500.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>405 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e0128e4-296b-4b20-8189-97983c357a0d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6e0128e4-296b-4b20-8189-97983c357a0d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6e0128e4-296b-4b20-8189-97983c357a0d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ffd24924-a434-4d1d-9122-8e0b041a9629\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ffd24924-a434-4d1d-9122-8e0b041a9629')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ffd24924-a434-4d1d-9122-8e0b041a9629 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 405,\n  \"fields\": [\n    {\n      \"column\": \"Brand\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.1842204495075315,\n        \"min\": 0.0,\n        \"max\": 15.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.0,\n          12.0,\n          10.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 70,\n        \"min\": 0,\n        \"max\": 238,\n        \"num_unique_values\": 237,\n        \"samples\": [\n          84,\n          119,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Storage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 64.44504836407594,\n        \"min\": 32.0,\n        \"max\": 512.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          256.0,\n          512.0,\n          64.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RAM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.4161579703093308,\n        \"min\": 2.0,\n        \"max\": 16.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          12.0,\n          2.0,\n          6.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Screen_Size_(inches)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3159461337287799,\n        \"min\": 4.5,\n        \"max\": 6.9,\n        \"num_unique_values\": 39,\n        \"samples\": [\n          6.49,\n          6.47,\n          6.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Camera_(MP)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24.659402888904385,\n        \"min\": 8.0,\n        \"max\": 108.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          13.0,\n          12.0,\n          40.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Battery_Capacity_(mAh)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 798.4044616320672,\n        \"min\": 1821.0,\n        \"max\": 7000.0,\n        \"num_unique_values\": 48,\n        \"samples\": [\n          5050.0,\n          3174.0,\n          4950.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          0,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = data.drop(columns=['Category'])\n",
        "target = data['Category']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "features = scaler.fit_transform(features)\n",
        "# target_log = np.log1p(target)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "S-RrlN8xPDv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7E7OH18_i1ju",
        "outputId": "13cbf1de-75c3-4b4c-c63d-55a85f9a5365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "356    0\n",
              "235    1\n",
              "3      1\n",
              "18     2\n",
              "132    3\n",
              "      ..\n",
              "71     1\n",
              "107    0\n",
              "271    1\n",
              "349    1\n",
              "103    3\n",
              "Name: Category, Length: 324, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = X_train.shape[1]\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(128, input_dim=input_dim, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.2),\n",
        "    Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=1000, validation_split=0.2, batch_size=32, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZCQAbZGPOs_",
        "outputId": "cf7646fa-433f-4e01-a5c2-26a04cc4e449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_31 (Dense)            (None, 128)               1024      \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 4)                 132       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11492 (44.89 KB)\n",
            "Trainable params: 11492 (44.89 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "9/9 [==============================] - 1s 29ms/step - loss: 1.5031 - accuracy: 0.3012 - val_loss: 1.4231 - val_accuracy: 0.6462\n",
            "Epoch 2/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.3705 - accuracy: 0.5251 - val_loss: 1.3240 - val_accuracy: 0.5846\n",
            "Epoch 3/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.2958 - accuracy: 0.5637 - val_loss: 1.2128 - val_accuracy: 0.5385\n",
            "Epoch 4/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.1813 - accuracy: 0.6332 - val_loss: 1.1244 - val_accuracy: 0.5385\n",
            "Epoch 5/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0980 - accuracy: 0.6062 - val_loss: 1.0495 - val_accuracy: 0.5385\n",
            "Epoch 6/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.0527 - accuracy: 0.6178 - val_loss: 0.9836 - val_accuracy: 0.6000\n",
            "Epoch 7/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9820 - accuracy: 0.6371 - val_loss: 0.9382 - val_accuracy: 0.6615\n",
            "Epoch 8/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9429 - accuracy: 0.6525 - val_loss: 0.9072 - val_accuracy: 0.6615\n",
            "Epoch 9/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9119 - accuracy: 0.6486 - val_loss: 0.8978 - val_accuracy: 0.6462\n",
            "Epoch 10/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8845 - accuracy: 0.6525 - val_loss: 0.8681 - val_accuracy: 0.6923\n",
            "Epoch 11/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8754 - accuracy: 0.6448 - val_loss: 0.8379 - val_accuracy: 0.6769\n",
            "Epoch 12/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.8405 - accuracy: 0.6680 - val_loss: 0.8258 - val_accuracy: 0.6923\n",
            "Epoch 13/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.8484 - accuracy: 0.6718 - val_loss: 0.8130 - val_accuracy: 0.7077\n",
            "Epoch 14/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.7969 - accuracy: 0.7066 - val_loss: 0.8151 - val_accuracy: 0.7077\n",
            "Epoch 15/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8267 - accuracy: 0.7259 - val_loss: 0.8339 - val_accuracy: 0.7077\n",
            "Epoch 16/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7734 - accuracy: 0.7297 - val_loss: 0.8051 - val_accuracy: 0.7538\n",
            "Epoch 17/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7507 - accuracy: 0.7606 - val_loss: 0.7891 - val_accuracy: 0.7231\n",
            "Epoch 18/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7621 - accuracy: 0.7104 - val_loss: 0.8124 - val_accuracy: 0.7385\n",
            "Epoch 19/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7751 - accuracy: 0.7104 - val_loss: 0.8050 - val_accuracy: 0.7692\n",
            "Epoch 20/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7670 - accuracy: 0.7181 - val_loss: 0.7749 - val_accuracy: 0.7692\n",
            "Epoch 21/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7783 - accuracy: 0.6873 - val_loss: 0.7932 - val_accuracy: 0.7846\n",
            "Epoch 22/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7340 - accuracy: 0.7375 - val_loss: 0.8028 - val_accuracy: 0.7692\n",
            "Epoch 23/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7121 - accuracy: 0.7143 - val_loss: 0.8000 - val_accuracy: 0.7538\n",
            "Epoch 24/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7530 - accuracy: 0.7181 - val_loss: 0.7896 - val_accuracy: 0.7692\n",
            "Epoch 25/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6936 - accuracy: 0.7104 - val_loss: 0.8051 - val_accuracy: 0.7692\n",
            "Epoch 26/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7518 - accuracy: 0.7143 - val_loss: 0.7696 - val_accuracy: 0.8000\n",
            "Epoch 27/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6904 - accuracy: 0.7490 - val_loss: 0.7640 - val_accuracy: 0.8154\n",
            "Epoch 28/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7133 - accuracy: 0.7529 - val_loss: 0.7826 - val_accuracy: 0.7692\n",
            "Epoch 29/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.6236 - accuracy: 0.7992 - val_loss: 0.8066 - val_accuracy: 0.7692\n",
            "Epoch 30/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6404 - accuracy: 0.7606 - val_loss: 0.7800 - val_accuracy: 0.7538\n",
            "Epoch 31/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6801 - accuracy: 0.7606 - val_loss: 0.7711 - val_accuracy: 0.7538\n",
            "Epoch 32/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6621 - accuracy: 0.7683 - val_loss: 0.8055 - val_accuracy: 0.7692\n",
            "Epoch 33/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6650 - accuracy: 0.7568 - val_loss: 0.7910 - val_accuracy: 0.7692\n",
            "Epoch 34/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6299 - accuracy: 0.7838 - val_loss: 0.7927 - val_accuracy: 0.7846\n",
            "Epoch 35/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6506 - accuracy: 0.7876 - val_loss: 0.8070 - val_accuracy: 0.7692\n",
            "Epoch 36/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6288 - accuracy: 0.7876 - val_loss: 0.7871 - val_accuracy: 0.7846\n",
            "Epoch 37/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6619 - accuracy: 0.7761 - val_loss: 0.7927 - val_accuracy: 0.7692\n",
            "Epoch 38/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6338 - accuracy: 0.7683 - val_loss: 0.8045 - val_accuracy: 0.7692\n",
            "Epoch 39/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6397 - accuracy: 0.7915 - val_loss: 0.8086 - val_accuracy: 0.7538\n",
            "Epoch 40/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6237 - accuracy: 0.8108 - val_loss: 0.7583 - val_accuracy: 0.7538\n",
            "Epoch 41/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6252 - accuracy: 0.8031 - val_loss: 0.7708 - val_accuracy: 0.7692\n",
            "Epoch 42/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6037 - accuracy: 0.7954 - val_loss: 0.7777 - val_accuracy: 0.7692\n",
            "Epoch 43/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6130 - accuracy: 0.7954 - val_loss: 0.7798 - val_accuracy: 0.7846\n",
            "Epoch 44/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5648 - accuracy: 0.8108 - val_loss: 0.7881 - val_accuracy: 0.7846\n",
            "Epoch 45/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5859 - accuracy: 0.7954 - val_loss: 0.7703 - val_accuracy: 0.7846\n",
            "Epoch 46/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6177 - accuracy: 0.7799 - val_loss: 0.7676 - val_accuracy: 0.7846\n",
            "Epoch 47/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.5847 - accuracy: 0.7915 - val_loss: 0.7835 - val_accuracy: 0.7846\n",
            "Epoch 48/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5952 - accuracy: 0.8031 - val_loss: 0.7666 - val_accuracy: 0.8000\n",
            "Epoch 49/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5749 - accuracy: 0.8185 - val_loss: 0.7714 - val_accuracy: 0.7846\n",
            "Epoch 50/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6022 - accuracy: 0.7722 - val_loss: 0.7938 - val_accuracy: 0.7538\n",
            "Epoch 51/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5983 - accuracy: 0.8031 - val_loss: 0.8383 - val_accuracy: 0.7538\n",
            "Epoch 52/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5522 - accuracy: 0.8340 - val_loss: 0.8764 - val_accuracy: 0.7692\n",
            "Epoch 53/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6176 - accuracy: 0.7992 - val_loss: 0.8561 - val_accuracy: 0.7692\n",
            "Epoch 54/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5769 - accuracy: 0.7876 - val_loss: 0.8295 - val_accuracy: 0.7538\n",
            "Epoch 55/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6007 - accuracy: 0.8185 - val_loss: 0.8486 - val_accuracy: 0.7692\n",
            "Epoch 56/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5799 - accuracy: 0.8185 - val_loss: 0.8200 - val_accuracy: 0.7538\n",
            "Epoch 57/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5718 - accuracy: 0.7954 - val_loss: 0.7958 - val_accuracy: 0.7692\n",
            "Epoch 58/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6010 - accuracy: 0.7799 - val_loss: 0.7943 - val_accuracy: 0.7692\n",
            "Epoch 59/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5095 - accuracy: 0.8456 - val_loss: 0.7950 - val_accuracy: 0.7846\n",
            "Epoch 60/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5606 - accuracy: 0.7954 - val_loss: 0.7911 - val_accuracy: 0.7846\n",
            "Epoch 61/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5670 - accuracy: 0.7992 - val_loss: 0.8091 - val_accuracy: 0.7846\n",
            "Epoch 62/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5658 - accuracy: 0.7992 - val_loss: 0.8023 - val_accuracy: 0.7692\n",
            "Epoch 63/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5446 - accuracy: 0.8301 - val_loss: 0.8038 - val_accuracy: 0.7692\n",
            "Epoch 64/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5596 - accuracy: 0.8031 - val_loss: 0.8209 - val_accuracy: 0.7692\n",
            "Epoch 65/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5601 - accuracy: 0.7915 - val_loss: 0.8385 - val_accuracy: 0.7692\n",
            "Epoch 66/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5541 - accuracy: 0.7915 - val_loss: 0.8299 - val_accuracy: 0.7846\n",
            "Epoch 67/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5670 - accuracy: 0.7915 - val_loss: 0.8171 - val_accuracy: 0.7692\n",
            "Epoch 68/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5171 - accuracy: 0.8301 - val_loss: 0.7643 - val_accuracy: 0.8000\n",
            "Epoch 69/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5474 - accuracy: 0.7992 - val_loss: 0.7606 - val_accuracy: 0.7846\n",
            "Epoch 70/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5745 - accuracy: 0.7876 - val_loss: 0.7530 - val_accuracy: 0.8154\n",
            "Epoch 71/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.5094 - accuracy: 0.8263 - val_loss: 0.7746 - val_accuracy: 0.8154\n",
            "Epoch 72/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5368 - accuracy: 0.8224 - val_loss: 0.8014 - val_accuracy: 0.7692\n",
            "Epoch 73/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5559 - accuracy: 0.8069 - val_loss: 0.7717 - val_accuracy: 0.7846\n",
            "Epoch 74/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5499 - accuracy: 0.7915 - val_loss: 0.7711 - val_accuracy: 0.8000\n",
            "Epoch 75/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5093 - accuracy: 0.8649 - val_loss: 0.7816 - val_accuracy: 0.7846\n",
            "Epoch 76/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5010 - accuracy: 0.8108 - val_loss: 0.8103 - val_accuracy: 0.7692\n",
            "Epoch 77/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5133 - accuracy: 0.8378 - val_loss: 0.8022 - val_accuracy: 0.7846\n",
            "Epoch 78/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5218 - accuracy: 0.8185 - val_loss: 0.7958 - val_accuracy: 0.7692\n",
            "Epoch 79/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5033 - accuracy: 0.8378 - val_loss: 0.8123 - val_accuracy: 0.7846\n",
            "Epoch 80/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5424 - accuracy: 0.8031 - val_loss: 0.7876 - val_accuracy: 0.7846\n",
            "Epoch 81/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5248 - accuracy: 0.8263 - val_loss: 0.7827 - val_accuracy: 0.8000\n",
            "Epoch 82/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4996 - accuracy: 0.8417 - val_loss: 0.8041 - val_accuracy: 0.7846\n",
            "Epoch 83/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4777 - accuracy: 0.8571 - val_loss: 0.8341 - val_accuracy: 0.7538\n",
            "Epoch 84/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4875 - accuracy: 0.8417 - val_loss: 0.8499 - val_accuracy: 0.7692\n",
            "Epoch 85/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5474 - accuracy: 0.8069 - val_loss: 0.8283 - val_accuracy: 0.8000\n",
            "Epoch 86/1000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.5084 - accuracy: 0.8340 - val_loss: 0.8184 - val_accuracy: 0.8000\n",
            "Epoch 87/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.8224 - val_loss: 0.8130 - val_accuracy: 0.8000\n",
            "Epoch 88/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5056 - accuracy: 0.8301 - val_loss: 0.8340 - val_accuracy: 0.8154\n",
            "Epoch 89/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4879 - accuracy: 0.8147 - val_loss: 0.8249 - val_accuracy: 0.8000\n",
            "Epoch 90/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.8533 - val_loss: 0.8196 - val_accuracy: 0.8000\n",
            "Epoch 91/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4879 - accuracy: 0.8494 - val_loss: 0.8106 - val_accuracy: 0.8154\n",
            "Epoch 92/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5276 - accuracy: 0.7838 - val_loss: 0.8132 - val_accuracy: 0.7538\n",
            "Epoch 93/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4806 - accuracy: 0.8610 - val_loss: 0.8293 - val_accuracy: 0.7385\n",
            "Epoch 94/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4966 - accuracy: 0.8378 - val_loss: 0.8295 - val_accuracy: 0.7692\n",
            "Epoch 95/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5283 - accuracy: 0.8108 - val_loss: 0.8262 - val_accuracy: 0.7692\n",
            "Epoch 96/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5219 - accuracy: 0.8494 - val_loss: 0.7802 - val_accuracy: 0.7692\n",
            "Epoch 97/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4524 - accuracy: 0.8803 - val_loss: 0.7809 - val_accuracy: 0.8000\n",
            "Epoch 98/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.5365 - accuracy: 0.8031 - val_loss: 0.8101 - val_accuracy: 0.8000\n",
            "Epoch 99/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4922 - accuracy: 0.8147 - val_loss: 0.8716 - val_accuracy: 0.7385\n",
            "Epoch 100/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4636 - accuracy: 0.8571 - val_loss: 0.8769 - val_accuracy: 0.7231\n",
            "Epoch 101/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4934 - accuracy: 0.8301 - val_loss: 0.8434 - val_accuracy: 0.7385\n",
            "Epoch 102/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4564 - accuracy: 0.8301 - val_loss: 0.8488 - val_accuracy: 0.7692\n",
            "Epoch 103/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5294 - accuracy: 0.8031 - val_loss: 0.8283 - val_accuracy: 0.7692\n",
            "Epoch 104/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4722 - accuracy: 0.8494 - val_loss: 0.8149 - val_accuracy: 0.7538\n",
            "Epoch 105/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4666 - accuracy: 0.8571 - val_loss: 0.8387 - val_accuracy: 0.7692\n",
            "Epoch 106/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4608 - accuracy: 0.8533 - val_loss: 0.8552 - val_accuracy: 0.7846\n",
            "Epoch 107/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4544 - accuracy: 0.8417 - val_loss: 0.8741 - val_accuracy: 0.7692\n",
            "Epoch 108/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4548 - accuracy: 0.8417 - val_loss: 0.8632 - val_accuracy: 0.7692\n",
            "Epoch 109/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4819 - accuracy: 0.8224 - val_loss: 0.8549 - val_accuracy: 0.7692\n",
            "Epoch 110/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.4418 - accuracy: 0.8842 - val_loss: 0.8979 - val_accuracy: 0.7385\n",
            "Epoch 111/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4934 - accuracy: 0.8378 - val_loss: 0.8672 - val_accuracy: 0.7538\n",
            "Epoch 112/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.4630 - accuracy: 0.8687 - val_loss: 0.8600 - val_accuracy: 0.7385\n",
            "Epoch 113/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.4414 - accuracy: 0.8494 - val_loss: 0.8651 - val_accuracy: 0.8000\n",
            "Epoch 114/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.4712 - accuracy: 0.8687 - val_loss: 0.8619 - val_accuracy: 0.7846\n",
            "Epoch 115/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.4247 - accuracy: 0.8880 - val_loss: 0.8641 - val_accuracy: 0.7846\n",
            "Epoch 116/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.5013 - accuracy: 0.8340 - val_loss: 0.8952 - val_accuracy: 0.7692\n",
            "Epoch 117/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.4731 - accuracy: 0.8378 - val_loss: 0.8915 - val_accuracy: 0.7692\n",
            "Epoch 118/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.4922 - accuracy: 0.8185 - val_loss: 0.8850 - val_accuracy: 0.8000\n",
            "Epoch 119/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4534 - accuracy: 0.8687 - val_loss: 0.8919 - val_accuracy: 0.8000\n",
            "Epoch 120/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4521 - accuracy: 0.8571 - val_loss: 0.8636 - val_accuracy: 0.8000\n",
            "Epoch 121/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4831 - accuracy: 0.8224 - val_loss: 0.8590 - val_accuracy: 0.7846\n",
            "Epoch 122/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4575 - accuracy: 0.8571 - val_loss: 0.8735 - val_accuracy: 0.7846\n",
            "Epoch 123/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.4271 - accuracy: 0.8726 - val_loss: 0.8601 - val_accuracy: 0.8000\n",
            "Epoch 124/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4626 - accuracy: 0.8494 - val_loss: 0.8625 - val_accuracy: 0.8000\n",
            "Epoch 125/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.4651 - accuracy: 0.8378 - val_loss: 0.8761 - val_accuracy: 0.7846\n",
            "Epoch 126/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.4267 - accuracy: 0.8764 - val_loss: 0.8793 - val_accuracy: 0.8000\n",
            "Epoch 127/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.4251 - accuracy: 0.8571 - val_loss: 0.8747 - val_accuracy: 0.8000\n",
            "Epoch 128/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4024 - accuracy: 0.8842 - val_loss: 0.8665 - val_accuracy: 0.8000\n",
            "Epoch 129/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.4093 - accuracy: 0.8764 - val_loss: 0.8579 - val_accuracy: 0.8000\n",
            "Epoch 130/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.4224 - accuracy: 0.8571 - val_loss: 0.8400 - val_accuracy: 0.8154\n",
            "Epoch 131/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4160 - accuracy: 0.8649 - val_loss: 0.8586 - val_accuracy: 0.8154\n",
            "Epoch 132/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.4113 - accuracy: 0.8649 - val_loss: 0.8694 - val_accuracy: 0.8154\n",
            "Epoch 133/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.4497 - accuracy: 0.8649 - val_loss: 0.8779 - val_accuracy: 0.7846\n",
            "Epoch 134/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4196 - accuracy: 0.8958 - val_loss: 0.9017 - val_accuracy: 0.7846\n",
            "Epoch 135/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.4247 - accuracy: 0.8649 - val_loss: 0.9036 - val_accuracy: 0.8000\n",
            "Epoch 136/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.4403 - accuracy: 0.8649 - val_loss: 0.8984 - val_accuracy: 0.8154\n",
            "Epoch 137/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.4492 - accuracy: 0.8378 - val_loss: 0.8683 - val_accuracy: 0.8000\n",
            "Epoch 138/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.4423 - accuracy: 0.8340 - val_loss: 0.8634 - val_accuracy: 0.8000\n",
            "Epoch 139/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.4168 - accuracy: 0.8764 - val_loss: 0.8359 - val_accuracy: 0.8154\n",
            "Epoch 140/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.4275 - accuracy: 0.8494 - val_loss: 0.8431 - val_accuracy: 0.8000\n",
            "Epoch 141/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4204 - accuracy: 0.8417 - val_loss: 0.8505 - val_accuracy: 0.7846\n",
            "Epoch 142/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.4126 - accuracy: 0.8687 - val_loss: 0.8680 - val_accuracy: 0.7846\n",
            "Epoch 143/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3970 - accuracy: 0.8687 - val_loss: 0.8791 - val_accuracy: 0.7846\n",
            "Epoch 144/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.4236 - accuracy: 0.8649 - val_loss: 0.8622 - val_accuracy: 0.7846\n",
            "Epoch 145/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4162 - accuracy: 0.8610 - val_loss: 0.8658 - val_accuracy: 0.8000\n",
            "Epoch 146/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4128 - accuracy: 0.8610 - val_loss: 0.8754 - val_accuracy: 0.7538\n",
            "Epoch 147/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4179 - accuracy: 0.8533 - val_loss: 0.8722 - val_accuracy: 0.7692\n",
            "Epoch 148/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4276 - accuracy: 0.8533 - val_loss: 0.8918 - val_accuracy: 0.8000\n",
            "Epoch 149/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4003 - accuracy: 0.8687 - val_loss: 0.9123 - val_accuracy: 0.7692\n",
            "Epoch 150/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4167 - accuracy: 0.8494 - val_loss: 0.9272 - val_accuracy: 0.7692\n",
            "Epoch 151/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4052 - accuracy: 0.8764 - val_loss: 0.9424 - val_accuracy: 0.7231\n",
            "Epoch 152/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3963 - accuracy: 0.8803 - val_loss: 0.9466 - val_accuracy: 0.7231\n",
            "Epoch 153/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8919 - val_loss: 0.9176 - val_accuracy: 0.7385\n",
            "Epoch 154/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4460 - accuracy: 0.8417 - val_loss: 0.9285 - val_accuracy: 0.7231\n",
            "Epoch 155/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4037 - accuracy: 0.8803 - val_loss: 0.9407 - val_accuracy: 0.7385\n",
            "Epoch 156/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4197 - accuracy: 0.8726 - val_loss: 0.9303 - val_accuracy: 0.7385\n",
            "Epoch 157/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3716 - accuracy: 0.8880 - val_loss: 0.9483 - val_accuracy: 0.7231\n",
            "Epoch 158/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4148 - accuracy: 0.8726 - val_loss: 0.9054 - val_accuracy: 0.7846\n",
            "Epoch 159/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4147 - accuracy: 0.8649 - val_loss: 0.9088 - val_accuracy: 0.7692\n",
            "Epoch 160/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4060 - accuracy: 0.8764 - val_loss: 0.9151 - val_accuracy: 0.7692\n",
            "Epoch 161/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4150 - accuracy: 0.8764 - val_loss: 0.9005 - val_accuracy: 0.7692\n",
            "Epoch 162/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4005 - accuracy: 0.8726 - val_loss: 0.8808 - val_accuracy: 0.7692\n",
            "Epoch 163/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3911 - accuracy: 0.8687 - val_loss: 0.9157 - val_accuracy: 0.7692\n",
            "Epoch 164/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4092 - accuracy: 0.8726 - val_loss: 0.9243 - val_accuracy: 0.7846\n",
            "Epoch 165/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8571 - val_loss: 0.8994 - val_accuracy: 0.8000\n",
            "Epoch 166/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4003 - accuracy: 0.8494 - val_loss: 0.8714 - val_accuracy: 0.8154\n",
            "Epoch 167/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4493 - accuracy: 0.8456 - val_loss: 0.9265 - val_accuracy: 0.7385\n",
            "Epoch 168/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4361 - accuracy: 0.8687 - val_loss: 0.9779 - val_accuracy: 0.7385\n",
            "Epoch 169/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4335 - accuracy: 0.8494 - val_loss: 0.9638 - val_accuracy: 0.7846\n",
            "Epoch 170/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4304 - accuracy: 0.8533 - val_loss: 0.9224 - val_accuracy: 0.8000\n",
            "Epoch 171/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3916 - accuracy: 0.8649 - val_loss: 0.9039 - val_accuracy: 0.7846\n",
            "Epoch 172/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4069 - accuracy: 0.8417 - val_loss: 0.9013 - val_accuracy: 0.8000\n",
            "Epoch 173/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3762 - accuracy: 0.8842 - val_loss: 0.9326 - val_accuracy: 0.7538\n",
            "Epoch 174/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3989 - accuracy: 0.8687 - val_loss: 0.9320 - val_accuracy: 0.8000\n",
            "Epoch 175/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3967 - accuracy: 0.8533 - val_loss: 0.9145 - val_accuracy: 0.8000\n",
            "Epoch 176/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3753 - accuracy: 0.8880 - val_loss: 0.9097 - val_accuracy: 0.8000\n",
            "Epoch 177/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4000 - accuracy: 0.8687 - val_loss: 0.8944 - val_accuracy: 0.7846\n",
            "Epoch 178/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4058 - accuracy: 0.8649 - val_loss: 0.8904 - val_accuracy: 0.7846\n",
            "Epoch 179/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3858 - accuracy: 0.8649 - val_loss: 0.8831 - val_accuracy: 0.8000\n",
            "Epoch 180/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3836 - accuracy: 0.8610 - val_loss: 0.8972 - val_accuracy: 0.7846\n",
            "Epoch 181/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3968 - accuracy: 0.8764 - val_loss: 0.9295 - val_accuracy: 0.7538\n",
            "Epoch 182/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4256 - accuracy: 0.8533 - val_loss: 0.9200 - val_accuracy: 0.7846\n",
            "Epoch 183/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3565 - accuracy: 0.8880 - val_loss: 0.8984 - val_accuracy: 0.8000\n",
            "Epoch 184/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3911 - accuracy: 0.8533 - val_loss: 0.8943 - val_accuracy: 0.8000\n",
            "Epoch 185/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3803 - accuracy: 0.8764 - val_loss: 0.9001 - val_accuracy: 0.8000\n",
            "Epoch 186/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3537 - accuracy: 0.8996 - val_loss: 0.9080 - val_accuracy: 0.7846\n",
            "Epoch 187/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3715 - accuracy: 0.8880 - val_loss: 0.9123 - val_accuracy: 0.8000\n",
            "Epoch 188/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.8610 - val_loss: 0.9297 - val_accuracy: 0.7846\n",
            "Epoch 189/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3846 - accuracy: 0.8764 - val_loss: 0.9326 - val_accuracy: 0.7846\n",
            "Epoch 190/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3657 - accuracy: 0.8764 - val_loss: 0.9277 - val_accuracy: 0.7846\n",
            "Epoch 191/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3498 - accuracy: 0.8764 - val_loss: 0.9271 - val_accuracy: 0.7846\n",
            "Epoch 192/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4258 - accuracy: 0.8301 - val_loss: 0.9592 - val_accuracy: 0.7385\n",
            "Epoch 193/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3909 - accuracy: 0.8842 - val_loss: 0.9971 - val_accuracy: 0.7385\n",
            "Epoch 194/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4002 - accuracy: 0.8610 - val_loss: 0.9583 - val_accuracy: 0.7692\n",
            "Epoch 195/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3788 - accuracy: 0.8803 - val_loss: 0.9289 - val_accuracy: 0.7846\n",
            "Epoch 196/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3529 - accuracy: 0.8842 - val_loss: 0.9234 - val_accuracy: 0.7231\n",
            "Epoch 197/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3680 - accuracy: 0.8842 - val_loss: 0.8779 - val_accuracy: 0.7538\n",
            "Epoch 198/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3716 - accuracy: 0.9035 - val_loss: 0.8968 - val_accuracy: 0.7538\n",
            "Epoch 199/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.8880 - val_loss: 0.9292 - val_accuracy: 0.8000\n",
            "Epoch 200/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3758 - accuracy: 0.8726 - val_loss: 0.9621 - val_accuracy: 0.7385\n",
            "Epoch 201/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3850 - accuracy: 0.8610 - val_loss: 0.9557 - val_accuracy: 0.7385\n",
            "Epoch 202/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3551 - accuracy: 0.9073 - val_loss: 0.9358 - val_accuracy: 0.7077\n",
            "Epoch 203/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8301 - val_loss: 0.9198 - val_accuracy: 0.7692\n",
            "Epoch 204/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3685 - accuracy: 0.8842 - val_loss: 0.9171 - val_accuracy: 0.7692\n",
            "Epoch 205/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3750 - accuracy: 0.8842 - val_loss: 0.9388 - val_accuracy: 0.7692\n",
            "Epoch 206/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3666 - accuracy: 0.8687 - val_loss: 0.9407 - val_accuracy: 0.7692\n",
            "Epoch 207/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3511 - accuracy: 0.8764 - val_loss: 0.9602 - val_accuracy: 0.7692\n",
            "Epoch 208/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3515 - accuracy: 0.8919 - val_loss: 0.9593 - val_accuracy: 0.8000\n",
            "Epoch 209/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3673 - accuracy: 0.8726 - val_loss: 0.9759 - val_accuracy: 0.8000\n",
            "Epoch 210/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3756 - accuracy: 0.8919 - val_loss: 1.0059 - val_accuracy: 0.7846\n",
            "Epoch 211/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3498 - accuracy: 0.8958 - val_loss: 0.9744 - val_accuracy: 0.7846\n",
            "Epoch 212/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3450 - accuracy: 0.8958 - val_loss: 0.9377 - val_accuracy: 0.7846\n",
            "Epoch 213/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3532 - accuracy: 0.8880 - val_loss: 0.9267 - val_accuracy: 0.7538\n",
            "Epoch 214/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3720 - accuracy: 0.8726 - val_loss: 0.9082 - val_accuracy: 0.8000\n",
            "Epoch 215/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3677 - accuracy: 0.8958 - val_loss: 0.9320 - val_accuracy: 0.7692\n",
            "Epoch 216/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3456 - accuracy: 0.8996 - val_loss: 1.0212 - val_accuracy: 0.7231\n",
            "Epoch 217/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3956 - accuracy: 0.8533 - val_loss: 1.0223 - val_accuracy: 0.7692\n",
            "Epoch 218/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3446 - accuracy: 0.8880 - val_loss: 1.0146 - val_accuracy: 0.7538\n",
            "Epoch 219/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3377 - accuracy: 0.8996 - val_loss: 1.0022 - val_accuracy: 0.7538\n",
            "Epoch 220/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3599 - accuracy: 0.8958 - val_loss: 1.0010 - val_accuracy: 0.7538\n",
            "Epoch 221/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3713 - accuracy: 0.8958 - val_loss: 1.0572 - val_accuracy: 0.7692\n",
            "Epoch 222/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3509 - accuracy: 0.9035 - val_loss: 1.0480 - val_accuracy: 0.7692\n",
            "Epoch 223/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3582 - accuracy: 0.8996 - val_loss: 1.0162 - val_accuracy: 0.8000\n",
            "Epoch 224/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3946 - accuracy: 0.8610 - val_loss: 1.0250 - val_accuracy: 0.8000\n",
            "Epoch 225/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3677 - accuracy: 0.8919 - val_loss: 1.0230 - val_accuracy: 0.7692\n",
            "Epoch 226/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3649 - accuracy: 0.8803 - val_loss: 1.0004 - val_accuracy: 0.7538\n",
            "Epoch 227/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3657 - accuracy: 0.8919 - val_loss: 0.9832 - val_accuracy: 0.7846\n",
            "Epoch 228/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3377 - accuracy: 0.8958 - val_loss: 0.9749 - val_accuracy: 0.7846\n",
            "Epoch 229/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3903 - accuracy: 0.8958 - val_loss: 0.9833 - val_accuracy: 0.7846\n",
            "Epoch 230/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3552 - accuracy: 0.8842 - val_loss: 1.0083 - val_accuracy: 0.7846\n",
            "Epoch 231/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3283 - accuracy: 0.9035 - val_loss: 1.0054 - val_accuracy: 0.7846\n",
            "Epoch 232/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3669 - accuracy: 0.8726 - val_loss: 0.9603 - val_accuracy: 0.8154\n",
            "Epoch 233/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3666 - accuracy: 0.8726 - val_loss: 0.9547 - val_accuracy: 0.8154\n",
            "Epoch 234/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3334 - accuracy: 0.9073 - val_loss: 0.9704 - val_accuracy: 0.7846\n",
            "Epoch 235/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3469 - accuracy: 0.8880 - val_loss: 0.9949 - val_accuracy: 0.7385\n",
            "Epoch 236/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3699 - accuracy: 0.8649 - val_loss: 0.9971 - val_accuracy: 0.7231\n",
            "Epoch 237/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3934 - accuracy: 0.8571 - val_loss: 0.9740 - val_accuracy: 0.7692\n",
            "Epoch 238/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3511 - accuracy: 0.8803 - val_loss: 0.9649 - val_accuracy: 0.7231\n",
            "Epoch 239/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3797 - accuracy: 0.8880 - val_loss: 0.9782 - val_accuracy: 0.7538\n",
            "Epoch 240/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3683 - accuracy: 0.8687 - val_loss: 0.9793 - val_accuracy: 0.7231\n",
            "Epoch 241/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3627 - accuracy: 0.9073 - val_loss: 1.0364 - val_accuracy: 0.7385\n",
            "Epoch 242/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3585 - accuracy: 0.8842 - val_loss: 1.1088 - val_accuracy: 0.7077\n",
            "Epoch 243/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3532 - accuracy: 0.8803 - val_loss: 1.0243 - val_accuracy: 0.7385\n",
            "Epoch 244/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3545 - accuracy: 0.8880 - val_loss: 1.0241 - val_accuracy: 0.7538\n",
            "Epoch 245/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3842 - accuracy: 0.8764 - val_loss: 1.0272 - val_accuracy: 0.7231\n",
            "Epoch 246/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3548 - accuracy: 0.8996 - val_loss: 0.9581 - val_accuracy: 0.7692\n",
            "Epoch 247/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3473 - accuracy: 0.8919 - val_loss: 0.9378 - val_accuracy: 0.7538\n",
            "Epoch 248/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3523 - accuracy: 0.8687 - val_loss: 0.8791 - val_accuracy: 0.7692\n",
            "Epoch 249/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3892 - accuracy: 0.8764 - val_loss: 0.8798 - val_accuracy: 0.7538\n",
            "Epoch 250/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3538 - accuracy: 0.8958 - val_loss: 0.8917 - val_accuracy: 0.7538\n",
            "Epoch 251/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3521 - accuracy: 0.8919 - val_loss: 0.9193 - val_accuracy: 0.7538\n",
            "Epoch 252/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3700 - accuracy: 0.8919 - val_loss: 0.9504 - val_accuracy: 0.7385\n",
            "Epoch 253/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3508 - accuracy: 0.8803 - val_loss: 0.9868 - val_accuracy: 0.7077\n",
            "Epoch 254/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3486 - accuracy: 0.8880 - val_loss: 1.0318 - val_accuracy: 0.7077\n",
            "Epoch 255/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3624 - accuracy: 0.8880 - val_loss: 1.0310 - val_accuracy: 0.7077\n",
            "Epoch 256/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3597 - accuracy: 0.8919 - val_loss: 0.9999 - val_accuracy: 0.7538\n",
            "Epoch 257/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3564 - accuracy: 0.8764 - val_loss: 0.9871 - val_accuracy: 0.7538\n",
            "Epoch 258/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3476 - accuracy: 0.8687 - val_loss: 0.9986 - val_accuracy: 0.7538\n",
            "Epoch 259/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3511 - accuracy: 0.8764 - val_loss: 0.9862 - val_accuracy: 0.7385\n",
            "Epoch 260/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3577 - accuracy: 0.8687 - val_loss: 0.9962 - val_accuracy: 0.7538\n",
            "Epoch 261/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3523 - accuracy: 0.8919 - val_loss: 0.9955 - val_accuracy: 0.7538\n",
            "Epoch 262/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3800 - accuracy: 0.8726 - val_loss: 0.9942 - val_accuracy: 0.7538\n",
            "Epoch 263/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3578 - accuracy: 0.8726 - val_loss: 0.9946 - val_accuracy: 0.7385\n",
            "Epoch 264/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3473 - accuracy: 0.8958 - val_loss: 1.0105 - val_accuracy: 0.7385\n",
            "Epoch 265/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3374 - accuracy: 0.9151 - val_loss: 0.9844 - val_accuracy: 0.7538\n",
            "Epoch 266/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3330 - accuracy: 0.8996 - val_loss: 0.9819 - val_accuracy: 0.7231\n",
            "Epoch 267/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3488 - accuracy: 0.8842 - val_loss: 0.9944 - val_accuracy: 0.7077\n",
            "Epoch 268/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3342 - accuracy: 0.8803 - val_loss: 1.0175 - val_accuracy: 0.7077\n",
            "Epoch 269/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3330 - accuracy: 0.9035 - val_loss: 1.0564 - val_accuracy: 0.6923\n",
            "Epoch 270/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3621 - accuracy: 0.8610 - val_loss: 1.0571 - val_accuracy: 0.7077\n",
            "Epoch 271/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3289 - accuracy: 0.9189 - val_loss: 1.0961 - val_accuracy: 0.7231\n",
            "Epoch 272/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3209 - accuracy: 0.9189 - val_loss: 1.0988 - val_accuracy: 0.7385\n",
            "Epoch 273/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3286 - accuracy: 0.9151 - val_loss: 1.0929 - val_accuracy: 0.7538\n",
            "Epoch 274/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3153 - accuracy: 0.8958 - val_loss: 1.1052 - val_accuracy: 0.7231\n",
            "Epoch 275/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3275 - accuracy: 0.9035 - val_loss: 1.1327 - val_accuracy: 0.7231\n",
            "Epoch 276/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3749 - accuracy: 0.8919 - val_loss: 1.0850 - val_accuracy: 0.7385\n",
            "Epoch 277/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3233 - accuracy: 0.8996 - val_loss: 1.0796 - val_accuracy: 0.7231\n",
            "Epoch 278/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3034 - accuracy: 0.9382 - val_loss: 1.0811 - val_accuracy: 0.7385\n",
            "Epoch 279/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3228 - accuracy: 0.8958 - val_loss: 1.0852 - val_accuracy: 0.7231\n",
            "Epoch 280/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3758 - accuracy: 0.8842 - val_loss: 1.0997 - val_accuracy: 0.7231\n",
            "Epoch 281/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3326 - accuracy: 0.8880 - val_loss: 1.1321 - val_accuracy: 0.7077\n",
            "Epoch 282/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3577 - accuracy: 0.8842 - val_loss: 1.1445 - val_accuracy: 0.7385\n",
            "Epoch 283/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3270 - accuracy: 0.9151 - val_loss: 1.1175 - val_accuracy: 0.7385\n",
            "Epoch 284/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3084 - accuracy: 0.9228 - val_loss: 1.1172 - val_accuracy: 0.7231\n",
            "Epoch 285/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2881 - accuracy: 0.9344 - val_loss: 1.1196 - val_accuracy: 0.7231\n",
            "Epoch 286/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2927 - accuracy: 0.9112 - val_loss: 1.1467 - val_accuracy: 0.7231\n",
            "Epoch 287/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3021 - accuracy: 0.9073 - val_loss: 1.1148 - val_accuracy: 0.8000\n",
            "Epoch 288/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3399 - accuracy: 0.8842 - val_loss: 1.1525 - val_accuracy: 0.7538\n",
            "Epoch 289/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3212 - accuracy: 0.9035 - val_loss: 1.1495 - val_accuracy: 0.7538\n",
            "Epoch 290/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3535 - accuracy: 0.8919 - val_loss: 1.1437 - val_accuracy: 0.7385\n",
            "Epoch 291/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3421 - accuracy: 0.8842 - val_loss: 1.1167 - val_accuracy: 0.7385\n",
            "Epoch 292/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3579 - accuracy: 0.8687 - val_loss: 1.1217 - val_accuracy: 0.7077\n",
            "Epoch 293/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3109 - accuracy: 0.9228 - val_loss: 1.1003 - val_accuracy: 0.7385\n",
            "Epoch 294/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3565 - accuracy: 0.8842 - val_loss: 1.0572 - val_accuracy: 0.7538\n",
            "Epoch 295/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3260 - accuracy: 0.9112 - val_loss: 1.0508 - val_accuracy: 0.7385\n",
            "Epoch 296/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3388 - accuracy: 0.8919 - val_loss: 1.1046 - val_accuracy: 0.7077\n",
            "Epoch 297/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3441 - accuracy: 0.8880 - val_loss: 1.1152 - val_accuracy: 0.7077\n",
            "Epoch 298/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3222 - accuracy: 0.8842 - val_loss: 1.0852 - val_accuracy: 0.7385\n",
            "Epoch 299/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3277 - accuracy: 0.9112 - val_loss: 1.0753 - val_accuracy: 0.7385\n",
            "Epoch 300/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.3111 - accuracy: 0.8996 - val_loss: 1.0982 - val_accuracy: 0.7385\n",
            "Epoch 301/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3401 - accuracy: 0.8880 - val_loss: 1.1133 - val_accuracy: 0.7077\n",
            "Epoch 302/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3315 - accuracy: 0.8996 - val_loss: 1.1138 - val_accuracy: 0.7077\n",
            "Epoch 303/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.3248 - accuracy: 0.8958 - val_loss: 1.1191 - val_accuracy: 0.7077\n",
            "Epoch 304/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3110 - accuracy: 0.8880 - val_loss: 1.1040 - val_accuracy: 0.7077\n",
            "Epoch 305/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3353 - accuracy: 0.9073 - val_loss: 1.0814 - val_accuracy: 0.7692\n",
            "Epoch 306/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3317 - accuracy: 0.8842 - val_loss: 1.0750 - val_accuracy: 0.7538\n",
            "Epoch 307/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.3554 - accuracy: 0.8880 - val_loss: 1.1099 - val_accuracy: 0.7231\n",
            "Epoch 308/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3425 - accuracy: 0.8958 - val_loss: 1.1148 - val_accuracy: 0.7231\n",
            "Epoch 309/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3112 - accuracy: 0.9035 - val_loss: 1.1119 - val_accuracy: 0.7231\n",
            "Epoch 310/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3334 - accuracy: 0.9035 - val_loss: 1.0823 - val_accuracy: 0.7231\n",
            "Epoch 311/1000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.3312 - accuracy: 0.8880 - val_loss: 1.0319 - val_accuracy: 0.7846\n",
            "Epoch 312/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.3194 - accuracy: 0.9112 - val_loss: 1.0570 - val_accuracy: 0.8000\n",
            "Epoch 313/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.3447 - accuracy: 0.9035 - val_loss: 1.0799 - val_accuracy: 0.7231\n",
            "Epoch 314/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3188 - accuracy: 0.8958 - val_loss: 1.0736 - val_accuracy: 0.7077\n",
            "Epoch 315/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3373 - accuracy: 0.8803 - val_loss: 1.0545 - val_accuracy: 0.7231\n",
            "Epoch 316/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3307 - accuracy: 0.9035 - val_loss: 1.0057 - val_accuracy: 0.7385\n",
            "Epoch 317/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3224 - accuracy: 0.8996 - val_loss: 1.0028 - val_accuracy: 0.7385\n",
            "Epoch 318/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3575 - accuracy: 0.8803 - val_loss: 1.0451 - val_accuracy: 0.6923\n",
            "Epoch 319/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3237 - accuracy: 0.8958 - val_loss: 1.0428 - val_accuracy: 0.6923\n",
            "Epoch 320/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.3118 - accuracy: 0.9151 - val_loss: 1.0729 - val_accuracy: 0.6923\n",
            "Epoch 321/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.3292 - accuracy: 0.8958 - val_loss: 1.0749 - val_accuracy: 0.6923\n",
            "Epoch 322/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3103 - accuracy: 0.9112 - val_loss: 1.0787 - val_accuracy: 0.7077\n",
            "Epoch 323/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3032 - accuracy: 0.9112 - val_loss: 1.0498 - val_accuracy: 0.7692\n",
            "Epoch 324/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3169 - accuracy: 0.9112 - val_loss: 1.0470 - val_accuracy: 0.7385\n",
            "Epoch 325/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2986 - accuracy: 0.8996 - val_loss: 1.0677 - val_accuracy: 0.7077\n",
            "Epoch 326/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3231 - accuracy: 0.8958 - val_loss: 1.0494 - val_accuracy: 0.7077\n",
            "Epoch 327/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3256 - accuracy: 0.8919 - val_loss: 1.0628 - val_accuracy: 0.7231\n",
            "Epoch 328/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3365 - accuracy: 0.8880 - val_loss: 1.1129 - val_accuracy: 0.7077\n",
            "Epoch 329/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3025 - accuracy: 0.9189 - val_loss: 1.1728 - val_accuracy: 0.6923\n",
            "Epoch 330/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3069 - accuracy: 0.9189 - val_loss: 1.1439 - val_accuracy: 0.7077\n",
            "Epoch 331/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3044 - accuracy: 0.9228 - val_loss: 1.0953 - val_accuracy: 0.7231\n",
            "Epoch 332/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3482 - accuracy: 0.8803 - val_loss: 1.0451 - val_accuracy: 0.7231\n",
            "Epoch 333/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3331 - accuracy: 0.8880 - val_loss: 1.0214 - val_accuracy: 0.7077\n",
            "Epoch 334/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3232 - accuracy: 0.9073 - val_loss: 1.0673 - val_accuracy: 0.7077\n",
            "Epoch 335/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3017 - accuracy: 0.8996 - val_loss: 1.0537 - val_accuracy: 0.7077\n",
            "Epoch 336/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3285 - accuracy: 0.8919 - val_loss: 1.0532 - val_accuracy: 0.7077\n",
            "Epoch 337/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3054 - accuracy: 0.9228 - val_loss: 0.9962 - val_accuracy: 0.7692\n",
            "Epoch 338/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3685 - accuracy: 0.8764 - val_loss: 1.0345 - val_accuracy: 0.7077\n",
            "Epoch 339/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3308 - accuracy: 0.8996 - val_loss: 1.0582 - val_accuracy: 0.6769\n",
            "Epoch 340/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3256 - accuracy: 0.8958 - val_loss: 1.0292 - val_accuracy: 0.6615\n",
            "Epoch 341/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3313 - accuracy: 0.9073 - val_loss: 1.0361 - val_accuracy: 0.7077\n",
            "Epoch 342/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3085 - accuracy: 0.9035 - val_loss: 1.0682 - val_accuracy: 0.7077\n",
            "Epoch 343/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3260 - accuracy: 0.8958 - val_loss: 1.1027 - val_accuracy: 0.7231\n",
            "Epoch 344/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3144 - accuracy: 0.9035 - val_loss: 1.1217 - val_accuracy: 0.7385\n",
            "Epoch 345/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3046 - accuracy: 0.9035 - val_loss: 1.1853 - val_accuracy: 0.7077\n",
            "Epoch 346/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3156 - accuracy: 0.9151 - val_loss: 1.1683 - val_accuracy: 0.7077\n",
            "Epoch 347/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3238 - accuracy: 0.9112 - val_loss: 1.1222 - val_accuracy: 0.7538\n",
            "Epoch 348/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3192 - accuracy: 0.9189 - val_loss: 1.0871 - val_accuracy: 0.7385\n",
            "Epoch 349/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3186 - accuracy: 0.9035 - val_loss: 1.1167 - val_accuracy: 0.7385\n",
            "Epoch 350/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3224 - accuracy: 0.9112 - val_loss: 1.1319 - val_accuracy: 0.7385\n",
            "Epoch 351/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3140 - accuracy: 0.9035 - val_loss: 1.1209 - val_accuracy: 0.7385\n",
            "Epoch 352/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2853 - accuracy: 0.9344 - val_loss: 1.1175 - val_accuracy: 0.7385\n",
            "Epoch 353/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2969 - accuracy: 0.9112 - val_loss: 1.0727 - val_accuracy: 0.7231\n",
            "Epoch 354/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3263 - accuracy: 0.8996 - val_loss: 1.0784 - val_accuracy: 0.7538\n",
            "Epoch 355/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3230 - accuracy: 0.8880 - val_loss: 1.1163 - val_accuracy: 0.7077\n",
            "Epoch 356/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2951 - accuracy: 0.9266 - val_loss: 1.0864 - val_accuracy: 0.7231\n",
            "Epoch 357/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2890 - accuracy: 0.9151 - val_loss: 1.0855 - val_accuracy: 0.7231\n",
            "Epoch 358/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3136 - accuracy: 0.8842 - val_loss: 1.0918 - val_accuracy: 0.7231\n",
            "Epoch 359/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3448 - accuracy: 0.9035 - val_loss: 1.1217 - val_accuracy: 0.7077\n",
            "Epoch 360/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3152 - accuracy: 0.9073 - val_loss: 1.1269 - val_accuracy: 0.6923\n",
            "Epoch 361/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2937 - accuracy: 0.9112 - val_loss: 1.1221 - val_accuracy: 0.7077\n",
            "Epoch 362/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2926 - accuracy: 0.9035 - val_loss: 1.1282 - val_accuracy: 0.7231\n",
            "Epoch 363/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3203 - accuracy: 0.8958 - val_loss: 1.1352 - val_accuracy: 0.7231\n",
            "Epoch 364/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2926 - accuracy: 0.9073 - val_loss: 1.1446 - val_accuracy: 0.6923\n",
            "Epoch 365/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3246 - accuracy: 0.8919 - val_loss: 1.1326 - val_accuracy: 0.6923\n",
            "Epoch 366/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2977 - accuracy: 0.9073 - val_loss: 1.1273 - val_accuracy: 0.7077\n",
            "Epoch 367/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2919 - accuracy: 0.8996 - val_loss: 1.1211 - val_accuracy: 0.7077\n",
            "Epoch 368/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3042 - accuracy: 0.9035 - val_loss: 1.1189 - val_accuracy: 0.7385\n",
            "Epoch 369/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2949 - accuracy: 0.9228 - val_loss: 1.1367 - val_accuracy: 0.7385\n",
            "Epoch 370/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3334 - accuracy: 0.8958 - val_loss: 1.1477 - val_accuracy: 0.6769\n",
            "Epoch 371/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3127 - accuracy: 0.9073 - val_loss: 1.0948 - val_accuracy: 0.6923\n",
            "Epoch 372/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2981 - accuracy: 0.9189 - val_loss: 1.0142 - val_accuracy: 0.7385\n",
            "Epoch 373/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3219 - accuracy: 0.8880 - val_loss: 1.0121 - val_accuracy: 0.7385\n",
            "Epoch 374/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3134 - accuracy: 0.9035 - val_loss: 1.0572 - val_accuracy: 0.7385\n",
            "Epoch 375/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3269 - accuracy: 0.8803 - val_loss: 1.1605 - val_accuracy: 0.6923\n",
            "Epoch 376/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3254 - accuracy: 0.8958 - val_loss: 1.1911 - val_accuracy: 0.6923\n",
            "Epoch 377/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3125 - accuracy: 0.9151 - val_loss: 1.1764 - val_accuracy: 0.6923\n",
            "Epoch 378/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3440 - accuracy: 0.9035 - val_loss: 1.1249 - val_accuracy: 0.7231\n",
            "Epoch 379/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2926 - accuracy: 0.9112 - val_loss: 1.1031 - val_accuracy: 0.7231\n",
            "Epoch 380/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3045 - accuracy: 0.8919 - val_loss: 1.0866 - val_accuracy: 0.7231\n",
            "Epoch 381/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3098 - accuracy: 0.9112 - val_loss: 1.1134 - val_accuracy: 0.7231\n",
            "Epoch 382/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2856 - accuracy: 0.9228 - val_loss: 1.1554 - val_accuracy: 0.7385\n",
            "Epoch 383/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3198 - accuracy: 0.8958 - val_loss: 1.1397 - val_accuracy: 0.7231\n",
            "Epoch 384/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3183 - accuracy: 0.9151 - val_loss: 1.1190 - val_accuracy: 0.6769\n",
            "Epoch 385/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3429 - accuracy: 0.8649 - val_loss: 1.0696 - val_accuracy: 0.7385\n",
            "Epoch 386/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3224 - accuracy: 0.8880 - val_loss: 1.0698 - val_accuracy: 0.7692\n",
            "Epoch 387/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3083 - accuracy: 0.9035 - val_loss: 1.1284 - val_accuracy: 0.7538\n",
            "Epoch 388/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2996 - accuracy: 0.8958 - val_loss: 1.1634 - val_accuracy: 0.7231\n",
            "Epoch 389/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2872 - accuracy: 0.8958 - val_loss: 1.1531 - val_accuracy: 0.7231\n",
            "Epoch 390/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3037 - accuracy: 0.9073 - val_loss: 1.1274 - val_accuracy: 0.7385\n",
            "Epoch 391/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2924 - accuracy: 0.9112 - val_loss: 1.0887 - val_accuracy: 0.7385\n",
            "Epoch 392/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2831 - accuracy: 0.9228 - val_loss: 1.0839 - val_accuracy: 0.7385\n",
            "Epoch 393/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3066 - accuracy: 0.8958 - val_loss: 1.1162 - val_accuracy: 0.7385\n",
            "Epoch 394/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2877 - accuracy: 0.9189 - val_loss: 1.1442 - val_accuracy: 0.7231\n",
            "Epoch 395/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3052 - accuracy: 0.9112 - val_loss: 1.1561 - val_accuracy: 0.7231\n",
            "Epoch 396/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3150 - accuracy: 0.8996 - val_loss: 1.1811 - val_accuracy: 0.7077\n",
            "Epoch 397/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3292 - accuracy: 0.9035 - val_loss: 1.2307 - val_accuracy: 0.6923\n",
            "Epoch 398/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3229 - accuracy: 0.8880 - val_loss: 1.1871 - val_accuracy: 0.6923\n",
            "Epoch 399/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3108 - accuracy: 0.9035 - val_loss: 1.1505 - val_accuracy: 0.7385\n",
            "Epoch 400/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3069 - accuracy: 0.9112 - val_loss: 1.1342 - val_accuracy: 0.7385\n",
            "Epoch 401/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2927 - accuracy: 0.9073 - val_loss: 1.1401 - val_accuracy: 0.7077\n",
            "Epoch 402/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2971 - accuracy: 0.9151 - val_loss: 1.1389 - val_accuracy: 0.7077\n",
            "Epoch 403/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2947 - accuracy: 0.9266 - val_loss: 1.1475 - val_accuracy: 0.7385\n",
            "Epoch 404/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2976 - accuracy: 0.8919 - val_loss: 1.1818 - val_accuracy: 0.7231\n",
            "Epoch 405/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2982 - accuracy: 0.9228 - val_loss: 1.2207 - val_accuracy: 0.6923\n",
            "Epoch 406/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2881 - accuracy: 0.9073 - val_loss: 1.2298 - val_accuracy: 0.6923\n",
            "Epoch 407/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3167 - accuracy: 0.8958 - val_loss: 1.2160 - val_accuracy: 0.6923\n",
            "Epoch 408/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3342 - accuracy: 0.8842 - val_loss: 1.2248 - val_accuracy: 0.6769\n",
            "Epoch 409/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3353 - accuracy: 0.8958 - val_loss: 1.1807 - val_accuracy: 0.6923\n",
            "Epoch 410/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2986 - accuracy: 0.9151 - val_loss: 1.1644 - val_accuracy: 0.7077\n",
            "Epoch 411/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3085 - accuracy: 0.8919 - val_loss: 1.1398 - val_accuracy: 0.7077\n",
            "Epoch 412/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3260 - accuracy: 0.8996 - val_loss: 1.1511 - val_accuracy: 0.6923\n",
            "Epoch 413/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2911 - accuracy: 0.8958 - val_loss: 1.1746 - val_accuracy: 0.7231\n",
            "Epoch 414/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3033 - accuracy: 0.9073 - val_loss: 1.1609 - val_accuracy: 0.7231\n",
            "Epoch 415/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3121 - accuracy: 0.8919 - val_loss: 1.1562 - val_accuracy: 0.7077\n",
            "Epoch 416/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3086 - accuracy: 0.9112 - val_loss: 1.1557 - val_accuracy: 0.7077\n",
            "Epoch 417/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2912 - accuracy: 0.9305 - val_loss: 1.1577 - val_accuracy: 0.7077\n",
            "Epoch 418/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2846 - accuracy: 0.9112 - val_loss: 1.1683 - val_accuracy: 0.6923\n",
            "Epoch 419/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2910 - accuracy: 0.8958 - val_loss: 1.1958 - val_accuracy: 0.6923\n",
            "Epoch 420/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3001 - accuracy: 0.8919 - val_loss: 1.2098 - val_accuracy: 0.7231\n",
            "Epoch 421/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3069 - accuracy: 0.8880 - val_loss: 1.2052 - val_accuracy: 0.6923\n",
            "Epoch 422/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2973 - accuracy: 0.9073 - val_loss: 1.1518 - val_accuracy: 0.7538\n",
            "Epoch 423/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2853 - accuracy: 0.8958 - val_loss: 1.1857 - val_accuracy: 0.7385\n",
            "Epoch 424/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2955 - accuracy: 0.8880 - val_loss: 1.1955 - val_accuracy: 0.6769\n",
            "Epoch 425/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2837 - accuracy: 0.9228 - val_loss: 1.1873 - val_accuracy: 0.6923\n",
            "Epoch 426/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2840 - accuracy: 0.9305 - val_loss: 1.1723 - val_accuracy: 0.6923\n",
            "Epoch 427/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3007 - accuracy: 0.8958 - val_loss: 1.1768 - val_accuracy: 0.6769\n",
            "Epoch 428/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2910 - accuracy: 0.9112 - val_loss: 1.1925 - val_accuracy: 0.6769\n",
            "Epoch 429/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3178 - accuracy: 0.8958 - val_loss: 1.1716 - val_accuracy: 0.6923\n",
            "Epoch 430/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2922 - accuracy: 0.8880 - val_loss: 1.1373 - val_accuracy: 0.7077\n",
            "Epoch 431/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2958 - accuracy: 0.8958 - val_loss: 1.1052 - val_accuracy: 0.7385\n",
            "Epoch 432/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3056 - accuracy: 0.8996 - val_loss: 1.0899 - val_accuracy: 0.7385\n",
            "Epoch 433/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3045 - accuracy: 0.8919 - val_loss: 1.0992 - val_accuracy: 0.7077\n",
            "Epoch 434/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2770 - accuracy: 0.9189 - val_loss: 1.1326 - val_accuracy: 0.7077\n",
            "Epoch 435/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2795 - accuracy: 0.9228 - val_loss: 1.1567 - val_accuracy: 0.7077\n",
            "Epoch 436/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2991 - accuracy: 0.9073 - val_loss: 1.1860 - val_accuracy: 0.7231\n",
            "Epoch 437/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3149 - accuracy: 0.8842 - val_loss: 1.1963 - val_accuracy: 0.7231\n",
            "Epoch 438/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2970 - accuracy: 0.9151 - val_loss: 1.1642 - val_accuracy: 0.7231\n",
            "Epoch 439/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2954 - accuracy: 0.9073 - val_loss: 1.1660 - val_accuracy: 0.6923\n",
            "Epoch 440/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2875 - accuracy: 0.9073 - val_loss: 1.1876 - val_accuracy: 0.7231\n",
            "Epoch 441/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3037 - accuracy: 0.8803 - val_loss: 1.2062 - val_accuracy: 0.7385\n",
            "Epoch 442/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2859 - accuracy: 0.9151 - val_loss: 1.2106 - val_accuracy: 0.7385\n",
            "Epoch 443/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2923 - accuracy: 0.9151 - val_loss: 1.2138 - val_accuracy: 0.7385\n",
            "Epoch 444/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2907 - accuracy: 0.9151 - val_loss: 1.1540 - val_accuracy: 0.7385\n",
            "Epoch 445/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3041 - accuracy: 0.9073 - val_loss: 1.1390 - val_accuracy: 0.7385\n",
            "Epoch 446/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2853 - accuracy: 0.8919 - val_loss: 1.0931 - val_accuracy: 0.7385\n",
            "Epoch 447/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3080 - accuracy: 0.9112 - val_loss: 1.1455 - val_accuracy: 0.7231\n",
            "Epoch 448/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2979 - accuracy: 0.9112 - val_loss: 1.1738 - val_accuracy: 0.7231\n",
            "Epoch 449/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3063 - accuracy: 0.9151 - val_loss: 1.1725 - val_accuracy: 0.7231\n",
            "Epoch 450/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3131 - accuracy: 0.8958 - val_loss: 1.1310 - val_accuracy: 0.7538\n",
            "Epoch 451/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2914 - accuracy: 0.9112 - val_loss: 1.1101 - val_accuracy: 0.7538\n",
            "Epoch 452/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2957 - accuracy: 0.8996 - val_loss: 1.0962 - val_accuracy: 0.7385\n",
            "Epoch 453/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2990 - accuracy: 0.8880 - val_loss: 1.1063 - val_accuracy: 0.7231\n",
            "Epoch 454/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3019 - accuracy: 0.9035 - val_loss: 1.1340 - val_accuracy: 0.6923\n",
            "Epoch 455/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2981 - accuracy: 0.9151 - val_loss: 1.0538 - val_accuracy: 0.6923\n",
            "Epoch 456/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2948 - accuracy: 0.9151 - val_loss: 1.1003 - val_accuracy: 0.7231\n",
            "Epoch 457/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3096 - accuracy: 0.8880 - val_loss: 1.1267 - val_accuracy: 0.7077\n",
            "Epoch 458/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3022 - accuracy: 0.8880 - val_loss: 1.1628 - val_accuracy: 0.7077\n",
            "Epoch 459/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2637 - accuracy: 0.9266 - val_loss: 1.1797 - val_accuracy: 0.7077\n",
            "Epoch 460/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2691 - accuracy: 0.9228 - val_loss: 1.1731 - val_accuracy: 0.7077\n",
            "Epoch 461/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2913 - accuracy: 0.8996 - val_loss: 1.1456 - val_accuracy: 0.7077\n",
            "Epoch 462/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3036 - accuracy: 0.8996 - val_loss: 1.1451 - val_accuracy: 0.7077\n",
            "Epoch 463/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2957 - accuracy: 0.8958 - val_loss: 1.0900 - val_accuracy: 0.7077\n",
            "Epoch 464/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2804 - accuracy: 0.9151 - val_loss: 1.0770 - val_accuracy: 0.7231\n",
            "Epoch 465/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3176 - accuracy: 0.8919 - val_loss: 1.0913 - val_accuracy: 0.7385\n",
            "Epoch 466/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.3017 - accuracy: 0.9035 - val_loss: 1.1051 - val_accuracy: 0.7385\n",
            "Epoch 467/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2913 - accuracy: 0.9151 - val_loss: 1.0860 - val_accuracy: 0.7077\n",
            "Epoch 468/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2977 - accuracy: 0.9151 - val_loss: 1.0544 - val_accuracy: 0.6923\n",
            "Epoch 469/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2976 - accuracy: 0.9151 - val_loss: 1.0457 - val_accuracy: 0.6923\n",
            "Epoch 470/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2927 - accuracy: 0.9112 - val_loss: 1.0507 - val_accuracy: 0.7231\n",
            "Epoch 471/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2921 - accuracy: 0.8996 - val_loss: 1.0792 - val_accuracy: 0.7385\n",
            "Epoch 472/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2658 - accuracy: 0.9228 - val_loss: 1.1173 - val_accuracy: 0.7385\n",
            "Epoch 473/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2821 - accuracy: 0.9112 - val_loss: 1.1616 - val_accuracy: 0.7538\n",
            "Epoch 474/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3144 - accuracy: 0.9151 - val_loss: 1.1933 - val_accuracy: 0.6923\n",
            "Epoch 475/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2823 - accuracy: 0.9305 - val_loss: 1.1995 - val_accuracy: 0.7538\n",
            "Epoch 476/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3006 - accuracy: 0.9189 - val_loss: 1.2077 - val_accuracy: 0.7385\n",
            "Epoch 477/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2962 - accuracy: 0.8996 - val_loss: 1.2002 - val_accuracy: 0.7231\n",
            "Epoch 478/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.3105 - accuracy: 0.8958 - val_loss: 1.1904 - val_accuracy: 0.7231\n",
            "Epoch 479/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2887 - accuracy: 0.9112 - val_loss: 1.1176 - val_accuracy: 0.7231\n",
            "Epoch 480/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2962 - accuracy: 0.8958 - val_loss: 1.1354 - val_accuracy: 0.6923\n",
            "Epoch 481/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3142 - accuracy: 0.8726 - val_loss: 1.1642 - val_accuracy: 0.6923\n",
            "Epoch 482/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2911 - accuracy: 0.9073 - val_loss: 1.1562 - val_accuracy: 0.7231\n",
            "Epoch 483/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2717 - accuracy: 0.9305 - val_loss: 1.1224 - val_accuracy: 0.7231\n",
            "Epoch 484/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2943 - accuracy: 0.8996 - val_loss: 1.1420 - val_accuracy: 0.7231\n",
            "Epoch 485/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2818 - accuracy: 0.9112 - val_loss: 1.0934 - val_accuracy: 0.7231\n",
            "Epoch 486/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3000 - accuracy: 0.8958 - val_loss: 1.1060 - val_accuracy: 0.7231\n",
            "Epoch 487/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2723 - accuracy: 0.9151 - val_loss: 1.1403 - val_accuracy: 0.7077\n",
            "Epoch 488/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2769 - accuracy: 0.9228 - val_loss: 1.1454 - val_accuracy: 0.7385\n",
            "Epoch 489/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2624 - accuracy: 0.9305 - val_loss: 1.1589 - val_accuracy: 0.7385\n",
            "Epoch 490/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2827 - accuracy: 0.8996 - val_loss: 1.1651 - val_accuracy: 0.7231\n",
            "Epoch 491/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2966 - accuracy: 0.8919 - val_loss: 1.1504 - val_accuracy: 0.6769\n",
            "Epoch 492/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2879 - accuracy: 0.9112 - val_loss: 1.1728 - val_accuracy: 0.7077\n",
            "Epoch 493/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2887 - accuracy: 0.9073 - val_loss: 1.1663 - val_accuracy: 0.7385\n",
            "Epoch 494/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2944 - accuracy: 0.9112 - val_loss: 1.1220 - val_accuracy: 0.7692\n",
            "Epoch 495/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3028 - accuracy: 0.9035 - val_loss: 1.1237 - val_accuracy: 0.7385\n",
            "Epoch 496/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2747 - accuracy: 0.9073 - val_loss: 1.1415 - val_accuracy: 0.7538\n",
            "Epoch 497/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2778 - accuracy: 0.9189 - val_loss: 1.1615 - val_accuracy: 0.7385\n",
            "Epoch 498/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2789 - accuracy: 0.9035 - val_loss: 1.1549 - val_accuracy: 0.7385\n",
            "Epoch 499/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2779 - accuracy: 0.9189 - val_loss: 1.1613 - val_accuracy: 0.7077\n",
            "Epoch 500/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2825 - accuracy: 0.9112 - val_loss: 1.1775 - val_accuracy: 0.7385\n",
            "Epoch 501/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2899 - accuracy: 0.8880 - val_loss: 1.1942 - val_accuracy: 0.7385\n",
            "Epoch 502/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2920 - accuracy: 0.9151 - val_loss: 1.1486 - val_accuracy: 0.7385\n",
            "Epoch 503/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2827 - accuracy: 0.8880 - val_loss: 1.1183 - val_accuracy: 0.7385\n",
            "Epoch 504/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2820 - accuracy: 0.9035 - val_loss: 1.1037 - val_accuracy: 0.7231\n",
            "Epoch 505/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2835 - accuracy: 0.9228 - val_loss: 1.1251 - val_accuracy: 0.6769\n",
            "Epoch 506/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2754 - accuracy: 0.9189 - val_loss: 1.1341 - val_accuracy: 0.6923\n",
            "Epoch 507/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3029 - accuracy: 0.8958 - val_loss: 1.1362 - val_accuracy: 0.6769\n",
            "Epoch 508/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2866 - accuracy: 0.9112 - val_loss: 1.1171 - val_accuracy: 0.6923\n",
            "Epoch 509/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3169 - accuracy: 0.8764 - val_loss: 1.0834 - val_accuracy: 0.7231\n",
            "Epoch 510/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2725 - accuracy: 0.9305 - val_loss: 1.0944 - val_accuracy: 0.6923\n",
            "Epoch 511/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2767 - accuracy: 0.9112 - val_loss: 1.1154 - val_accuracy: 0.7231\n",
            "Epoch 512/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2818 - accuracy: 0.9073 - val_loss: 1.1368 - val_accuracy: 0.7385\n",
            "Epoch 513/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2822 - accuracy: 0.8919 - val_loss: 1.1725 - val_accuracy: 0.7385\n",
            "Epoch 514/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2861 - accuracy: 0.9189 - val_loss: 1.1901 - val_accuracy: 0.7231\n",
            "Epoch 515/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2778 - accuracy: 0.9305 - val_loss: 1.1791 - val_accuracy: 0.7231\n",
            "Epoch 516/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2662 - accuracy: 0.9266 - val_loss: 1.1343 - val_accuracy: 0.7385\n",
            "Epoch 517/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2817 - accuracy: 0.8996 - val_loss: 1.1334 - val_accuracy: 0.7385\n",
            "Epoch 518/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2847 - accuracy: 0.9266 - val_loss: 1.1562 - val_accuracy: 0.7231\n",
            "Epoch 519/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2838 - accuracy: 0.9073 - val_loss: 1.2147 - val_accuracy: 0.6923\n",
            "Epoch 520/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2844 - accuracy: 0.9305 - val_loss: 1.2096 - val_accuracy: 0.7077\n",
            "Epoch 521/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2739 - accuracy: 0.9305 - val_loss: 1.1991 - val_accuracy: 0.7077\n",
            "Epoch 522/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2777 - accuracy: 0.8996 - val_loss: 1.1998 - val_accuracy: 0.7231\n",
            "Epoch 523/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2765 - accuracy: 0.9073 - val_loss: 1.1913 - val_accuracy: 0.7077\n",
            "Epoch 524/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2864 - accuracy: 0.9035 - val_loss: 1.1843 - val_accuracy: 0.7077\n",
            "Epoch 525/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2878 - accuracy: 0.9151 - val_loss: 1.2070 - val_accuracy: 0.6923\n",
            "Epoch 526/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2754 - accuracy: 0.9189 - val_loss: 1.2963 - val_accuracy: 0.6923\n",
            "Epoch 527/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2803 - accuracy: 0.8958 - val_loss: 1.3067 - val_accuracy: 0.7077\n",
            "Epoch 528/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2777 - accuracy: 0.9035 - val_loss: 1.3096 - val_accuracy: 0.7077\n",
            "Epoch 529/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3082 - accuracy: 0.8919 - val_loss: 1.2977 - val_accuracy: 0.7231\n",
            "Epoch 530/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2850 - accuracy: 0.9073 - val_loss: 1.3007 - val_accuracy: 0.7231\n",
            "Epoch 531/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2836 - accuracy: 0.9151 - val_loss: 1.2978 - val_accuracy: 0.6923\n",
            "Epoch 532/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2775 - accuracy: 0.9266 - val_loss: 1.3203 - val_accuracy: 0.6923\n",
            "Epoch 533/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2860 - accuracy: 0.9305 - val_loss: 1.3064 - val_accuracy: 0.7077\n",
            "Epoch 534/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2680 - accuracy: 0.9151 - val_loss: 1.2886 - val_accuracy: 0.7538\n",
            "Epoch 535/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2950 - accuracy: 0.9228 - val_loss: 1.2585 - val_accuracy: 0.7231\n",
            "Epoch 536/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2577 - accuracy: 0.9305 - val_loss: 1.2722 - val_accuracy: 0.7385\n",
            "Epoch 537/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2655 - accuracy: 0.9073 - val_loss: 1.2864 - val_accuracy: 0.7231\n",
            "Epoch 538/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2704 - accuracy: 0.8996 - val_loss: 1.2803 - val_accuracy: 0.7231\n",
            "Epoch 539/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2772 - accuracy: 0.9228 - val_loss: 1.2803 - val_accuracy: 0.7077\n",
            "Epoch 540/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2985 - accuracy: 0.8996 - val_loss: 1.2297 - val_accuracy: 0.7077\n",
            "Epoch 541/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2709 - accuracy: 0.9305 - val_loss: 1.1764 - val_accuracy: 0.7231\n",
            "Epoch 542/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2948 - accuracy: 0.8958 - val_loss: 1.1582 - val_accuracy: 0.7077\n",
            "Epoch 543/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2874 - accuracy: 0.9189 - val_loss: 1.1710 - val_accuracy: 0.7077\n",
            "Epoch 544/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2755 - accuracy: 0.9112 - val_loss: 1.2142 - val_accuracy: 0.7231\n",
            "Epoch 545/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2779 - accuracy: 0.9151 - val_loss: 1.2306 - val_accuracy: 0.7692\n",
            "Epoch 546/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2961 - accuracy: 0.9035 - val_loss: 1.2507 - val_accuracy: 0.7077\n",
            "Epoch 547/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3055 - accuracy: 0.9189 - val_loss: 1.2468 - val_accuracy: 0.6923\n",
            "Epoch 548/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2778 - accuracy: 0.9151 - val_loss: 1.2497 - val_accuracy: 0.7077\n",
            "Epoch 549/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2608 - accuracy: 0.9189 - val_loss: 1.2391 - val_accuracy: 0.6923\n",
            "Epoch 550/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2657 - accuracy: 0.9344 - val_loss: 1.2425 - val_accuracy: 0.7077\n",
            "Epoch 551/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2681 - accuracy: 0.9305 - val_loss: 1.2511 - val_accuracy: 0.7077\n",
            "Epoch 552/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2648 - accuracy: 0.9344 - val_loss: 1.2545 - val_accuracy: 0.7077\n",
            "Epoch 553/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2747 - accuracy: 0.9151 - val_loss: 1.2528 - val_accuracy: 0.7077\n",
            "Epoch 554/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2865 - accuracy: 0.9035 - val_loss: 1.2445 - val_accuracy: 0.7077\n",
            "Epoch 555/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2710 - accuracy: 0.9035 - val_loss: 1.2137 - val_accuracy: 0.7385\n",
            "Epoch 556/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2653 - accuracy: 0.9305 - val_loss: 1.1760 - val_accuracy: 0.7385\n",
            "Epoch 557/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2733 - accuracy: 0.9189 - val_loss: 1.2005 - val_accuracy: 0.6923\n",
            "Epoch 558/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2867 - accuracy: 0.9035 - val_loss: 1.2227 - val_accuracy: 0.7385\n",
            "Epoch 559/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2842 - accuracy: 0.9073 - val_loss: 1.2386 - val_accuracy: 0.7385\n",
            "Epoch 560/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2878 - accuracy: 0.8958 - val_loss: 1.2350 - val_accuracy: 0.7385\n",
            "Epoch 561/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2800 - accuracy: 0.9266 - val_loss: 1.1887 - val_accuracy: 0.7538\n",
            "Epoch 562/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2866 - accuracy: 0.9035 - val_loss: 1.1903 - val_accuracy: 0.7385\n",
            "Epoch 563/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2615 - accuracy: 0.9421 - val_loss: 1.2259 - val_accuracy: 0.7077\n",
            "Epoch 564/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2956 - accuracy: 0.9035 - val_loss: 1.2469 - val_accuracy: 0.7385\n",
            "Epoch 565/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3036 - accuracy: 0.9035 - val_loss: 1.2110 - val_accuracy: 0.7385\n",
            "Epoch 566/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2695 - accuracy: 0.9151 - val_loss: 1.1825 - val_accuracy: 0.7385\n",
            "Epoch 567/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2697 - accuracy: 0.9266 - val_loss: 1.1876 - val_accuracy: 0.7692\n",
            "Epoch 568/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2533 - accuracy: 0.9305 - val_loss: 1.2029 - val_accuracy: 0.7538\n",
            "Epoch 569/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2782 - accuracy: 0.9189 - val_loss: 1.2519 - val_accuracy: 0.6923\n",
            "Epoch 570/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2860 - accuracy: 0.9151 - val_loss: 1.2520 - val_accuracy: 0.6923\n",
            "Epoch 571/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2893 - accuracy: 0.9151 - val_loss: 1.2590 - val_accuracy: 0.6769\n",
            "Epoch 572/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2831 - accuracy: 0.9035 - val_loss: 1.2445 - val_accuracy: 0.6923\n",
            "Epoch 573/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2828 - accuracy: 0.9266 - val_loss: 1.2059 - val_accuracy: 0.7385\n",
            "Epoch 574/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2824 - accuracy: 0.8996 - val_loss: 1.2036 - val_accuracy: 0.7385\n",
            "Epoch 575/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2654 - accuracy: 0.9151 - val_loss: 1.2222 - val_accuracy: 0.7385\n",
            "Epoch 576/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2854 - accuracy: 0.9073 - val_loss: 1.2435 - val_accuracy: 0.6923\n",
            "Epoch 577/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2763 - accuracy: 0.9112 - val_loss: 1.2633 - val_accuracy: 0.7077\n",
            "Epoch 578/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2742 - accuracy: 0.9151 - val_loss: 1.2659 - val_accuracy: 0.7077\n",
            "Epoch 579/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2774 - accuracy: 0.9073 - val_loss: 1.2167 - val_accuracy: 0.6923\n",
            "Epoch 580/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2845 - accuracy: 0.9112 - val_loss: 1.2308 - val_accuracy: 0.6923\n",
            "Epoch 581/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2821 - accuracy: 0.9073 - val_loss: 1.3904 - val_accuracy: 0.6769\n",
            "Epoch 582/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2939 - accuracy: 0.9151 - val_loss: 1.3213 - val_accuracy: 0.6769\n",
            "Epoch 583/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2654 - accuracy: 0.9189 - val_loss: 1.2133 - val_accuracy: 0.7077\n",
            "Epoch 584/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2987 - accuracy: 0.9035 - val_loss: 1.2471 - val_accuracy: 0.7077\n",
            "Epoch 585/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2960 - accuracy: 0.9112 - val_loss: 1.2829 - val_accuracy: 0.7077\n",
            "Epoch 586/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3029 - accuracy: 0.8919 - val_loss: 1.2624 - val_accuracy: 0.7077\n",
            "Epoch 587/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2802 - accuracy: 0.8996 - val_loss: 1.2304 - val_accuracy: 0.7385\n",
            "Epoch 588/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2643 - accuracy: 0.9421 - val_loss: 1.2386 - val_accuracy: 0.7385\n",
            "Epoch 589/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2659 - accuracy: 0.9073 - val_loss: 1.2504 - val_accuracy: 0.7385\n",
            "Epoch 590/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2684 - accuracy: 0.9305 - val_loss: 1.2385 - val_accuracy: 0.7385\n",
            "Epoch 591/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2627 - accuracy: 0.9305 - val_loss: 1.2296 - val_accuracy: 0.7077\n",
            "Epoch 592/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2683 - accuracy: 0.9189 - val_loss: 1.2399 - val_accuracy: 0.7077\n",
            "Epoch 593/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2598 - accuracy: 0.9266 - val_loss: 1.2193 - val_accuracy: 0.7077\n",
            "Epoch 594/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2669 - accuracy: 0.9112 - val_loss: 1.2176 - val_accuracy: 0.7077\n",
            "Epoch 595/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2909 - accuracy: 0.9151 - val_loss: 1.2025 - val_accuracy: 0.7077\n",
            "Epoch 596/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2635 - accuracy: 0.9151 - val_loss: 1.2128 - val_accuracy: 0.7077\n",
            "Epoch 597/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2799 - accuracy: 0.9112 - val_loss: 1.2164 - val_accuracy: 0.7077\n",
            "Epoch 598/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2589 - accuracy: 0.9266 - val_loss: 1.1807 - val_accuracy: 0.7385\n",
            "Epoch 599/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2642 - accuracy: 0.9344 - val_loss: 1.1814 - val_accuracy: 0.7385\n",
            "Epoch 600/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2608 - accuracy: 0.9151 - val_loss: 1.1883 - val_accuracy: 0.7385\n",
            "Epoch 601/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2836 - accuracy: 0.8958 - val_loss: 1.2021 - val_accuracy: 0.7077\n",
            "Epoch 602/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2701 - accuracy: 0.9189 - val_loss: 1.2359 - val_accuracy: 0.7077\n",
            "Epoch 603/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2864 - accuracy: 0.8996 - val_loss: 1.1952 - val_accuracy: 0.6923\n",
            "Epoch 604/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2710 - accuracy: 0.9305 - val_loss: 1.1753 - val_accuracy: 0.7077\n",
            "Epoch 605/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2764 - accuracy: 0.9073 - val_loss: 1.1910 - val_accuracy: 0.7077\n",
            "Epoch 606/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2692 - accuracy: 0.9228 - val_loss: 1.2065 - val_accuracy: 0.7385\n",
            "Epoch 607/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2570 - accuracy: 0.9228 - val_loss: 1.2226 - val_accuracy: 0.7385\n",
            "Epoch 608/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2532 - accuracy: 0.9344 - val_loss: 1.2412 - val_accuracy: 0.7385\n",
            "Epoch 609/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2711 - accuracy: 0.9151 - val_loss: 1.2412 - val_accuracy: 0.7385\n",
            "Epoch 610/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2777 - accuracy: 0.9305 - val_loss: 1.2300 - val_accuracy: 0.7538\n",
            "Epoch 611/1000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2584 - accuracy: 0.9266 - val_loss: 1.2400 - val_accuracy: 0.7385\n",
            "Epoch 612/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2651 - accuracy: 0.9151 - val_loss: 1.2749 - val_accuracy: 0.7077\n",
            "Epoch 613/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2953 - accuracy: 0.8958 - val_loss: 1.3018 - val_accuracy: 0.6923\n",
            "Epoch 614/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2819 - accuracy: 0.9151 - val_loss: 1.2594 - val_accuracy: 0.7077\n",
            "Epoch 615/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2731 - accuracy: 0.9035 - val_loss: 1.2165 - val_accuracy: 0.7077\n",
            "Epoch 616/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2915 - accuracy: 0.8996 - val_loss: 1.1985 - val_accuracy: 0.7231\n",
            "Epoch 617/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2721 - accuracy: 0.9305 - val_loss: 1.2169 - val_accuracy: 0.7385\n",
            "Epoch 618/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2856 - accuracy: 0.9073 - val_loss: 1.2248 - val_accuracy: 0.7385\n",
            "Epoch 619/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2520 - accuracy: 0.9344 - val_loss: 1.2444 - val_accuracy: 0.7385\n",
            "Epoch 620/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2835 - accuracy: 0.8958 - val_loss: 1.2358 - val_accuracy: 0.6923\n",
            "Epoch 621/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2719 - accuracy: 0.8996 - val_loss: 1.2303 - val_accuracy: 0.7077\n",
            "Epoch 622/1000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2581 - accuracy: 0.9266 - val_loss: 1.2403 - val_accuracy: 0.7231\n",
            "Epoch 623/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2764 - accuracy: 0.9189 - val_loss: 1.2896 - val_accuracy: 0.7077\n",
            "Epoch 624/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2525 - accuracy: 0.9344 - val_loss: 1.3153 - val_accuracy: 0.7077\n",
            "Epoch 625/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2554 - accuracy: 0.9421 - val_loss: 1.3194 - val_accuracy: 0.7077\n",
            "Epoch 626/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2745 - accuracy: 0.8919 - val_loss: 1.3265 - val_accuracy: 0.7538\n",
            "Epoch 627/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2535 - accuracy: 0.9189 - val_loss: 1.3166 - val_accuracy: 0.7231\n",
            "Epoch 628/1000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2808 - accuracy: 0.9112 - val_loss: 1.3111 - val_accuracy: 0.7538\n",
            "Epoch 629/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2859 - accuracy: 0.9189 - val_loss: 1.3003 - val_accuracy: 0.7385\n",
            "Epoch 630/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2506 - accuracy: 0.9151 - val_loss: 1.2911 - val_accuracy: 0.7231\n",
            "Epoch 631/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2859 - accuracy: 0.9035 - val_loss: 1.2812 - val_accuracy: 0.7231\n",
            "Epoch 632/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2772 - accuracy: 0.9151 - val_loss: 1.2764 - val_accuracy: 0.7385\n",
            "Epoch 633/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2710 - accuracy: 0.9112 - val_loss: 1.2766 - val_accuracy: 0.7385\n",
            "Epoch 634/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2738 - accuracy: 0.9035 - val_loss: 1.2795 - val_accuracy: 0.7385\n",
            "Epoch 635/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2716 - accuracy: 0.9035 - val_loss: 1.2629 - val_accuracy: 0.7231\n",
            "Epoch 636/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2556 - accuracy: 0.9189 - val_loss: 1.2734 - val_accuracy: 0.7385\n",
            "Epoch 637/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2551 - accuracy: 0.9344 - val_loss: 1.2720 - val_accuracy: 0.7077\n",
            "Epoch 638/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2634 - accuracy: 0.9228 - val_loss: 1.2668 - val_accuracy: 0.7077\n",
            "Epoch 639/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2416 - accuracy: 0.9382 - val_loss: 1.2597 - val_accuracy: 0.7077\n",
            "Epoch 640/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2687 - accuracy: 0.9151 - val_loss: 1.2571 - val_accuracy: 0.7077\n",
            "Epoch 641/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2479 - accuracy: 0.9189 - val_loss: 1.2811 - val_accuracy: 0.7077\n",
            "Epoch 642/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2626 - accuracy: 0.9112 - val_loss: 1.2701 - val_accuracy: 0.7077\n",
            "Epoch 643/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2662 - accuracy: 0.8996 - val_loss: 1.2608 - val_accuracy: 0.7077\n",
            "Epoch 644/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2755 - accuracy: 0.8958 - val_loss: 1.2649 - val_accuracy: 0.6923\n",
            "Epoch 645/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2669 - accuracy: 0.9266 - val_loss: 1.2590 - val_accuracy: 0.7077\n",
            "Epoch 646/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2580 - accuracy: 0.9266 - val_loss: 1.2552 - val_accuracy: 0.6923\n",
            "Epoch 647/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2636 - accuracy: 0.8958 - val_loss: 1.2297 - val_accuracy: 0.6923\n",
            "Epoch 648/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2845 - accuracy: 0.8996 - val_loss: 1.2189 - val_accuracy: 0.6923\n",
            "Epoch 649/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2626 - accuracy: 0.9228 - val_loss: 1.2265 - val_accuracy: 0.6615\n",
            "Epoch 650/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2501 - accuracy: 0.9305 - val_loss: 1.2369 - val_accuracy: 0.6615\n",
            "Epoch 651/1000\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.2857 - accuracy: 0.9035 - val_loss: 1.2339 - val_accuracy: 0.7231\n",
            "Epoch 652/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2734 - accuracy: 0.9266 - val_loss: 1.2492 - val_accuracy: 0.7385\n",
            "Epoch 653/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2516 - accuracy: 0.9344 - val_loss: 1.2333 - val_accuracy: 0.7385\n",
            "Epoch 654/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2701 - accuracy: 0.9266 - val_loss: 1.2559 - val_accuracy: 0.7077\n",
            "Epoch 655/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2961 - accuracy: 0.8996 - val_loss: 1.2762 - val_accuracy: 0.7077\n",
            "Epoch 656/1000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2656 - accuracy: 0.9228 - val_loss: 1.2044 - val_accuracy: 0.7077\n",
            "Epoch 657/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2518 - accuracy: 0.9305 - val_loss: 1.1941 - val_accuracy: 0.7538\n",
            "Epoch 658/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2682 - accuracy: 0.9151 - val_loss: 1.2206 - val_accuracy: 0.7538\n",
            "Epoch 659/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2588 - accuracy: 0.9073 - val_loss: 1.2228 - val_accuracy: 0.7385\n",
            "Epoch 660/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2719 - accuracy: 0.9228 - val_loss: 1.1909 - val_accuracy: 0.7538\n",
            "Epoch 661/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2492 - accuracy: 0.9266 - val_loss: 1.1829 - val_accuracy: 0.7538\n",
            "Epoch 662/1000\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.2486 - accuracy: 0.9189 - val_loss: 1.2038 - val_accuracy: 0.7231\n",
            "Epoch 663/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2615 - accuracy: 0.9344 - val_loss: 1.2102 - val_accuracy: 0.7385\n",
            "Epoch 664/1000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2608 - accuracy: 0.9073 - val_loss: 1.1850 - val_accuracy: 0.7231\n",
            "Epoch 665/1000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2725 - accuracy: 0.9305 - val_loss: 1.2205 - val_accuracy: 0.7231\n",
            "Epoch 666/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2587 - accuracy: 0.9382 - val_loss: 1.2494 - val_accuracy: 0.7077\n",
            "Epoch 667/1000\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.2686 - accuracy: 0.9228 - val_loss: 1.2624 - val_accuracy: 0.7077\n",
            "Epoch 668/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2787 - accuracy: 0.9073 - val_loss: 1.2468 - val_accuracy: 0.7077\n",
            "Epoch 669/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2400 - accuracy: 0.9266 - val_loss: 1.2475 - val_accuracy: 0.7385\n",
            "Epoch 670/1000\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.2805 - accuracy: 0.9189 - val_loss: 1.2692 - val_accuracy: 0.7385\n",
            "Epoch 671/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2735 - accuracy: 0.9151 - val_loss: 1.2665 - val_accuracy: 0.7231\n",
            "Epoch 672/1000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2712 - accuracy: 0.9189 - val_loss: 1.2846 - val_accuracy: 0.7077\n",
            "Epoch 673/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2666 - accuracy: 0.9151 - val_loss: 1.2918 - val_accuracy: 0.7077\n",
            "Epoch 674/1000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2798 - accuracy: 0.9189 - val_loss: 1.2609 - val_accuracy: 0.7077\n",
            "Epoch 675/1000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2668 - accuracy: 0.9073 - val_loss: 1.2851 - val_accuracy: 0.6923\n",
            "Epoch 676/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2685 - accuracy: 0.9035 - val_loss: 1.3436 - val_accuracy: 0.7077\n",
            "Epoch 677/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2747 - accuracy: 0.9189 - val_loss: 1.3368 - val_accuracy: 0.7077\n",
            "Epoch 678/1000\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 0.2764 - accuracy: 0.9151 - val_loss: 1.2840 - val_accuracy: 0.7385\n",
            "Epoch 679/1000\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.2470 - accuracy: 0.9151 - val_loss: 1.2559 - val_accuracy: 0.7385\n",
            "Epoch 680/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2870 - accuracy: 0.8880 - val_loss: 1.2068 - val_accuracy: 0.7385\n",
            "Epoch 681/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2434 - accuracy: 0.9344 - val_loss: 1.1925 - val_accuracy: 0.7385\n",
            "Epoch 682/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2767 - accuracy: 0.9151 - val_loss: 1.1740 - val_accuracy: 0.7385\n",
            "Epoch 683/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2916 - accuracy: 0.8996 - val_loss: 1.1933 - val_accuracy: 0.7231\n",
            "Epoch 684/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2835 - accuracy: 0.8842 - val_loss: 1.1956 - val_accuracy: 0.6923\n",
            "Epoch 685/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2664 - accuracy: 0.9151 - val_loss: 1.2247 - val_accuracy: 0.7077\n",
            "Epoch 686/1000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2716 - accuracy: 0.8958 - val_loss: 1.1923 - val_accuracy: 0.7385\n",
            "Epoch 687/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2838 - accuracy: 0.8958 - val_loss: 1.1322 - val_accuracy: 0.7538\n",
            "Epoch 688/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2835 - accuracy: 0.9073 - val_loss: 1.1553 - val_accuracy: 0.7231\n",
            "Epoch 689/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2840 - accuracy: 0.9035 - val_loss: 1.1756 - val_accuracy: 0.7231\n",
            "Epoch 690/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2755 - accuracy: 0.9151 - val_loss: 1.0848 - val_accuracy: 0.7077\n",
            "Epoch 691/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2978 - accuracy: 0.8842 - val_loss: 1.0396 - val_accuracy: 0.7077\n",
            "Epoch 692/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2906 - accuracy: 0.9073 - val_loss: 1.0609 - val_accuracy: 0.7385\n",
            "Epoch 693/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2601 - accuracy: 0.9228 - val_loss: 1.0711 - val_accuracy: 0.7385\n",
            "Epoch 694/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2820 - accuracy: 0.9035 - val_loss: 1.1366 - val_accuracy: 0.7385\n",
            "Epoch 695/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2634 - accuracy: 0.9344 - val_loss: 1.1691 - val_accuracy: 0.7385\n",
            "Epoch 696/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2688 - accuracy: 0.9151 - val_loss: 1.1693 - val_accuracy: 0.7385\n",
            "Epoch 697/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2817 - accuracy: 0.9035 - val_loss: 1.1579 - val_accuracy: 0.7538\n",
            "Epoch 698/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2646 - accuracy: 0.9073 - val_loss: 1.1828 - val_accuracy: 0.7385\n",
            "Epoch 699/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2627 - accuracy: 0.9073 - val_loss: 1.2093 - val_accuracy: 0.7077\n",
            "Epoch 700/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2706 - accuracy: 0.9151 - val_loss: 1.2007 - val_accuracy: 0.6923\n",
            "Epoch 701/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2539 - accuracy: 0.9228 - val_loss: 1.2148 - val_accuracy: 0.7077\n",
            "Epoch 702/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2449 - accuracy: 0.9189 - val_loss: 1.2296 - val_accuracy: 0.7385\n",
            "Epoch 703/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2515 - accuracy: 0.9228 - val_loss: 1.2262 - val_accuracy: 0.7385\n",
            "Epoch 704/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2643 - accuracy: 0.9073 - val_loss: 1.2208 - val_accuracy: 0.7385\n",
            "Epoch 705/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2443 - accuracy: 0.9305 - val_loss: 1.2066 - val_accuracy: 0.7692\n",
            "Epoch 706/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2723 - accuracy: 0.8996 - val_loss: 1.2165 - val_accuracy: 0.7385\n",
            "Epoch 707/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2625 - accuracy: 0.9189 - val_loss: 1.2372 - val_accuracy: 0.7077\n",
            "Epoch 708/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2625 - accuracy: 0.9228 - val_loss: 1.2178 - val_accuracy: 0.7077\n",
            "Epoch 709/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2697 - accuracy: 0.9112 - val_loss: 1.2049 - val_accuracy: 0.7231\n",
            "Epoch 710/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3018 - accuracy: 0.8958 - val_loss: 1.1974 - val_accuracy: 0.7077\n",
            "Epoch 711/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2605 - accuracy: 0.9151 - val_loss: 1.1869 - val_accuracy: 0.7385\n",
            "Epoch 712/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2633 - accuracy: 0.9189 - val_loss: 1.1896 - val_accuracy: 0.7385\n",
            "Epoch 713/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2781 - accuracy: 0.8996 - val_loss: 1.1785 - val_accuracy: 0.7385\n",
            "Epoch 714/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2464 - accuracy: 0.9266 - val_loss: 1.1687 - val_accuracy: 0.7385\n",
            "Epoch 715/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2460 - accuracy: 0.9305 - val_loss: 1.1737 - val_accuracy: 0.7538\n",
            "Epoch 716/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2659 - accuracy: 0.9266 - val_loss: 1.1757 - val_accuracy: 0.7077\n",
            "Epoch 717/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2607 - accuracy: 0.9189 - val_loss: 1.1846 - val_accuracy: 0.7077\n",
            "Epoch 718/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2767 - accuracy: 0.9073 - val_loss: 1.2034 - val_accuracy: 0.7077\n",
            "Epoch 719/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2581 - accuracy: 0.9151 - val_loss: 1.2037 - val_accuracy: 0.7231\n",
            "Epoch 720/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2592 - accuracy: 0.9228 - val_loss: 1.1837 - val_accuracy: 0.7231\n",
            "Epoch 721/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2548 - accuracy: 0.9305 - val_loss: 1.1875 - val_accuracy: 0.7385\n",
            "Epoch 722/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2808 - accuracy: 0.9112 - val_loss: 1.2039 - val_accuracy: 0.7385\n",
            "Epoch 723/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2624 - accuracy: 0.9035 - val_loss: 1.2288 - val_accuracy: 0.7385\n",
            "Epoch 724/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2686 - accuracy: 0.9228 - val_loss: 1.2516 - val_accuracy: 0.7385\n",
            "Epoch 725/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2603 - accuracy: 0.9073 - val_loss: 1.2659 - val_accuracy: 0.7385\n",
            "Epoch 726/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2564 - accuracy: 0.9382 - val_loss: 1.2619 - val_accuracy: 0.6923\n",
            "Epoch 727/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2510 - accuracy: 0.9266 - val_loss: 1.2693 - val_accuracy: 0.6923\n",
            "Epoch 728/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2575 - accuracy: 0.9189 - val_loss: 1.3071 - val_accuracy: 0.6923\n",
            "Epoch 729/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2510 - accuracy: 0.9189 - val_loss: 1.3587 - val_accuracy: 0.6923\n",
            "Epoch 730/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2688 - accuracy: 0.9151 - val_loss: 1.3451 - val_accuracy: 0.7231\n",
            "Epoch 731/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2803 - accuracy: 0.8958 - val_loss: 1.3364 - val_accuracy: 0.7231\n",
            "Epoch 732/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2655 - accuracy: 0.9189 - val_loss: 1.3402 - val_accuracy: 0.6769\n",
            "Epoch 733/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2619 - accuracy: 0.9035 - val_loss: 1.3449 - val_accuracy: 0.7077\n",
            "Epoch 734/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2526 - accuracy: 0.9189 - val_loss: 1.3207 - val_accuracy: 0.7077\n",
            "Epoch 735/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2382 - accuracy: 0.9305 - val_loss: 1.3093 - val_accuracy: 0.7077\n",
            "Epoch 736/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2479 - accuracy: 0.9228 - val_loss: 1.2915 - val_accuracy: 0.7077\n",
            "Epoch 737/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2605 - accuracy: 0.9073 - val_loss: 1.2958 - val_accuracy: 0.7077\n",
            "Epoch 738/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2641 - accuracy: 0.9189 - val_loss: 1.2866 - val_accuracy: 0.7385\n",
            "Epoch 739/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2486 - accuracy: 0.9228 - val_loss: 1.2991 - val_accuracy: 0.7385\n",
            "Epoch 740/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2540 - accuracy: 0.9344 - val_loss: 1.3216 - val_accuracy: 0.7077\n",
            "Epoch 741/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2609 - accuracy: 0.9112 - val_loss: 1.3110 - val_accuracy: 0.7077\n",
            "Epoch 742/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2386 - accuracy: 0.9228 - val_loss: 1.2929 - val_accuracy: 0.7077\n",
            "Epoch 743/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2417 - accuracy: 0.9305 - val_loss: 1.3007 - val_accuracy: 0.6923\n",
            "Epoch 744/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2665 - accuracy: 0.9151 - val_loss: 1.2817 - val_accuracy: 0.6923\n",
            "Epoch 745/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2516 - accuracy: 0.9189 - val_loss: 1.2383 - val_accuracy: 0.7385\n",
            "Epoch 746/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2456 - accuracy: 0.9344 - val_loss: 1.2424 - val_accuracy: 0.7385\n",
            "Epoch 747/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2377 - accuracy: 0.9228 - val_loss: 1.2570 - val_accuracy: 0.7077\n",
            "Epoch 748/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2548 - accuracy: 0.9189 - val_loss: 1.2741 - val_accuracy: 0.7077\n",
            "Epoch 749/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2650 - accuracy: 0.9228 - val_loss: 1.2741 - val_accuracy: 0.7077\n",
            "Epoch 750/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2931 - accuracy: 0.8919 - val_loss: 1.2084 - val_accuracy: 0.7385\n",
            "Epoch 751/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2549 - accuracy: 0.9266 - val_loss: 1.2073 - val_accuracy: 0.7385\n",
            "Epoch 752/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2652 - accuracy: 0.9112 - val_loss: 1.1862 - val_accuracy: 0.7077\n",
            "Epoch 753/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2577 - accuracy: 0.9073 - val_loss: 1.1831 - val_accuracy: 0.6923\n",
            "Epoch 754/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2642 - accuracy: 0.9189 - val_loss: 1.2105 - val_accuracy: 0.7385\n",
            "Epoch 755/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2655 - accuracy: 0.9189 - val_loss: 1.2381 - val_accuracy: 0.7385\n",
            "Epoch 756/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2505 - accuracy: 0.9228 - val_loss: 1.2467 - val_accuracy: 0.7231\n",
            "Epoch 757/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2596 - accuracy: 0.9228 - val_loss: 1.2270 - val_accuracy: 0.7385\n",
            "Epoch 758/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2470 - accuracy: 0.9228 - val_loss: 1.2323 - val_accuracy: 0.6923\n",
            "Epoch 759/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2605 - accuracy: 0.9266 - val_loss: 1.2135 - val_accuracy: 0.7077\n",
            "Epoch 760/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2609 - accuracy: 0.9035 - val_loss: 1.1816 - val_accuracy: 0.7385\n",
            "Epoch 761/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2825 - accuracy: 0.9035 - val_loss: 1.1891 - val_accuracy: 0.7538\n",
            "Epoch 762/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2567 - accuracy: 0.9112 - val_loss: 1.2268 - val_accuracy: 0.7385\n",
            "Epoch 763/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2391 - accuracy: 0.9305 - val_loss: 1.2557 - val_accuracy: 0.6923\n",
            "Epoch 764/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2645 - accuracy: 0.9151 - val_loss: 1.2592 - val_accuracy: 0.7077\n",
            "Epoch 765/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2651 - accuracy: 0.9189 - val_loss: 1.2585 - val_accuracy: 0.7077\n",
            "Epoch 766/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2372 - accuracy: 0.9228 - val_loss: 1.2558 - val_accuracy: 0.7077\n",
            "Epoch 767/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2613 - accuracy: 0.9151 - val_loss: 1.2649 - val_accuracy: 0.7077\n",
            "Epoch 768/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2554 - accuracy: 0.9189 - val_loss: 1.3044 - val_accuracy: 0.7385\n",
            "Epoch 769/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2625 - accuracy: 0.9151 - val_loss: 1.3074 - val_accuracy: 0.7385\n",
            "Epoch 770/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2552 - accuracy: 0.9266 - val_loss: 1.2827 - val_accuracy: 0.7077\n",
            "Epoch 771/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2481 - accuracy: 0.9151 - val_loss: 1.2562 - val_accuracy: 0.7385\n",
            "Epoch 772/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2386 - accuracy: 0.9228 - val_loss: 1.2845 - val_accuracy: 0.7385\n",
            "Epoch 773/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2575 - accuracy: 0.9035 - val_loss: 1.3089 - val_accuracy: 0.7231\n",
            "Epoch 774/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2549 - accuracy: 0.9228 - val_loss: 1.3036 - val_accuracy: 0.7385\n",
            "Epoch 775/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2376 - accuracy: 0.9305 - val_loss: 1.2884 - val_accuracy: 0.7077\n",
            "Epoch 776/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2417 - accuracy: 0.9305 - val_loss: 1.2838 - val_accuracy: 0.7077\n",
            "Epoch 777/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2455 - accuracy: 0.9305 - val_loss: 1.2908 - val_accuracy: 0.7077\n",
            "Epoch 778/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2613 - accuracy: 0.9189 - val_loss: 1.2907 - val_accuracy: 0.7385\n",
            "Epoch 779/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2388 - accuracy: 0.9151 - val_loss: 1.2777 - val_accuracy: 0.7385\n",
            "Epoch 780/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2624 - accuracy: 0.9112 - val_loss: 1.2490 - val_accuracy: 0.7385\n",
            "Epoch 781/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2399 - accuracy: 0.9266 - val_loss: 1.2375 - val_accuracy: 0.7385\n",
            "Epoch 782/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2395 - accuracy: 0.9266 - val_loss: 1.2530 - val_accuracy: 0.7385\n",
            "Epoch 783/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2450 - accuracy: 0.9266 - val_loss: 1.2501 - val_accuracy: 0.7385\n",
            "Epoch 784/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2510 - accuracy: 0.9151 - val_loss: 1.2706 - val_accuracy: 0.7385\n",
            "Epoch 785/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2631 - accuracy: 0.9035 - val_loss: 1.2595 - val_accuracy: 0.7385\n",
            "Epoch 786/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2408 - accuracy: 0.9189 - val_loss: 1.2489 - val_accuracy: 0.7077\n",
            "Epoch 787/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2481 - accuracy: 0.9189 - val_loss: 1.2548 - val_accuracy: 0.7385\n",
            "Epoch 788/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2545 - accuracy: 0.8996 - val_loss: 1.2822 - val_accuracy: 0.7538\n",
            "Epoch 789/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2594 - accuracy: 0.9189 - val_loss: 1.2333 - val_accuracy: 0.7538\n",
            "Epoch 790/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2467 - accuracy: 0.9266 - val_loss: 1.2265 - val_accuracy: 0.7385\n",
            "Epoch 791/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2523 - accuracy: 0.9266 - val_loss: 1.2410 - val_accuracy: 0.7385\n",
            "Epoch 792/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2555 - accuracy: 0.9228 - val_loss: 1.2723 - val_accuracy: 0.7077\n",
            "Epoch 793/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2358 - accuracy: 0.9382 - val_loss: 1.2628 - val_accuracy: 0.7077\n",
            "Epoch 794/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2319 - accuracy: 0.9498 - val_loss: 1.2637 - val_accuracy: 0.7385\n",
            "Epoch 795/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2445 - accuracy: 0.9266 - val_loss: 1.3419 - val_accuracy: 0.7231\n",
            "Epoch 796/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2381 - accuracy: 0.9382 - val_loss: 1.3701 - val_accuracy: 0.7231\n",
            "Epoch 797/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2522 - accuracy: 0.9228 - val_loss: 1.3520 - val_accuracy: 0.7077\n",
            "Epoch 798/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2667 - accuracy: 0.9112 - val_loss: 1.3009 - val_accuracy: 0.7077\n",
            "Epoch 799/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2453 - accuracy: 0.9073 - val_loss: 1.2930 - val_accuracy: 0.6923\n",
            "Epoch 800/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2427 - accuracy: 0.9189 - val_loss: 1.2962 - val_accuracy: 0.7231\n",
            "Epoch 801/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2383 - accuracy: 0.9189 - val_loss: 1.3070 - val_accuracy: 0.7385\n",
            "Epoch 802/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2407 - accuracy: 0.9266 - val_loss: 1.3329 - val_accuracy: 0.7385\n",
            "Epoch 803/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2688 - accuracy: 0.8919 - val_loss: 1.3344 - val_accuracy: 0.7385\n",
            "Epoch 804/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2595 - accuracy: 0.9073 - val_loss: 1.2770 - val_accuracy: 0.7385\n",
            "Epoch 805/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2675 - accuracy: 0.9073 - val_loss: 1.2513 - val_accuracy: 0.7385\n",
            "Epoch 806/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2521 - accuracy: 0.9151 - val_loss: 1.2721 - val_accuracy: 0.6923\n",
            "Epoch 807/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2517 - accuracy: 0.9151 - val_loss: 1.2911 - val_accuracy: 0.6923\n",
            "Epoch 808/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2400 - accuracy: 0.9228 - val_loss: 1.2736 - val_accuracy: 0.6923\n",
            "Epoch 809/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2491 - accuracy: 0.9344 - val_loss: 1.3096 - val_accuracy: 0.6923\n",
            "Epoch 810/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2588 - accuracy: 0.9189 - val_loss: 1.3126 - val_accuracy: 0.7077\n",
            "Epoch 811/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2499 - accuracy: 0.9266 - val_loss: 1.2718 - val_accuracy: 0.7692\n",
            "Epoch 812/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2726 - accuracy: 0.8996 - val_loss: 1.2638 - val_accuracy: 0.7692\n",
            "Epoch 813/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2781 - accuracy: 0.9073 - val_loss: 1.2542 - val_accuracy: 0.7538\n",
            "Epoch 814/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2496 - accuracy: 0.9189 - val_loss: 1.2656 - val_accuracy: 0.7077\n",
            "Epoch 815/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2852 - accuracy: 0.9189 - val_loss: 1.2583 - val_accuracy: 0.7077\n",
            "Epoch 816/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2713 - accuracy: 0.9266 - val_loss: 1.2418 - val_accuracy: 0.7077\n",
            "Epoch 817/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2387 - accuracy: 0.9344 - val_loss: 1.2535 - val_accuracy: 0.7385\n",
            "Epoch 818/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2448 - accuracy: 0.9228 - val_loss: 1.2315 - val_accuracy: 0.7385\n",
            "Epoch 819/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2474 - accuracy: 0.9228 - val_loss: 1.2356 - val_accuracy: 0.7385\n",
            "Epoch 820/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2454 - accuracy: 0.9073 - val_loss: 1.2364 - val_accuracy: 0.7385\n",
            "Epoch 821/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2546 - accuracy: 0.9189 - val_loss: 1.2464 - val_accuracy: 0.7385\n",
            "Epoch 822/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2646 - accuracy: 0.9189 - val_loss: 1.2453 - val_accuracy: 0.6923\n",
            "Epoch 823/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2540 - accuracy: 0.9151 - val_loss: 1.2505 - val_accuracy: 0.6923\n",
            "Epoch 824/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2449 - accuracy: 0.9266 - val_loss: 1.2650 - val_accuracy: 0.7385\n",
            "Epoch 825/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2529 - accuracy: 0.9112 - val_loss: 1.2434 - val_accuracy: 0.7385\n",
            "Epoch 826/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2234 - accuracy: 0.9382 - val_loss: 1.2390 - val_accuracy: 0.7385\n",
            "Epoch 827/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2356 - accuracy: 0.9228 - val_loss: 1.2518 - val_accuracy: 0.7385\n",
            "Epoch 828/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2414 - accuracy: 0.9382 - val_loss: 1.2325 - val_accuracy: 0.7385\n",
            "Epoch 829/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2591 - accuracy: 0.9151 - val_loss: 1.1883 - val_accuracy: 0.7385\n",
            "Epoch 830/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2223 - accuracy: 0.9305 - val_loss: 1.1832 - val_accuracy: 0.7385\n",
            "Epoch 831/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2269 - accuracy: 0.9305 - val_loss: 1.2029 - val_accuracy: 0.7385\n",
            "Epoch 832/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2191 - accuracy: 0.9266 - val_loss: 1.2265 - val_accuracy: 0.6923\n",
            "Epoch 833/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2536 - accuracy: 0.9073 - val_loss: 1.2251 - val_accuracy: 0.7077\n",
            "Epoch 834/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2612 - accuracy: 0.9073 - val_loss: 1.2505 - val_accuracy: 0.7231\n",
            "Epoch 835/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2566 - accuracy: 0.9112 - val_loss: 1.2711 - val_accuracy: 0.7077\n",
            "Epoch 836/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2544 - accuracy: 0.9151 - val_loss: 1.2534 - val_accuracy: 0.7385\n",
            "Epoch 837/1000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2308 - accuracy: 0.9266 - val_loss: 1.2363 - val_accuracy: 0.7385\n",
            "Epoch 838/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2479 - accuracy: 0.9228 - val_loss: 1.2555 - val_accuracy: 0.7077\n",
            "Epoch 839/1000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2497 - accuracy: 0.9266 - val_loss: 1.2914 - val_accuracy: 0.7077\n",
            "Epoch 840/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2357 - accuracy: 0.9344 - val_loss: 1.3055 - val_accuracy: 0.6923\n",
            "Epoch 841/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2278 - accuracy: 0.9305 - val_loss: 1.2858 - val_accuracy: 0.7385\n",
            "Epoch 842/1000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2460 - accuracy: 0.9382 - val_loss: 1.2657 - val_accuracy: 0.7385\n",
            "Epoch 843/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2303 - accuracy: 0.9228 - val_loss: 1.2844 - val_accuracy: 0.7385\n",
            "Epoch 844/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2346 - accuracy: 0.9189 - val_loss: 1.2688 - val_accuracy: 0.6923\n",
            "Epoch 845/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2462 - accuracy: 0.9344 - val_loss: 1.2492 - val_accuracy: 0.7385\n",
            "Epoch 846/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2605 - accuracy: 0.9228 - val_loss: 1.2466 - val_accuracy: 0.7231\n",
            "Epoch 847/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2422 - accuracy: 0.9344 - val_loss: 1.2425 - val_accuracy: 0.7231\n",
            "Epoch 848/1000\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.2293 - accuracy: 0.9266 - val_loss: 1.2425 - val_accuracy: 0.6923\n",
            "Epoch 849/1000\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 0.2342 - accuracy: 0.9266 - val_loss: 1.2415 - val_accuracy: 0.7231\n",
            "Epoch 850/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2535 - accuracy: 0.9266 - val_loss: 1.2621 - val_accuracy: 0.7385\n",
            "Epoch 851/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2373 - accuracy: 0.9266 - val_loss: 1.2614 - val_accuracy: 0.7385\n",
            "Epoch 852/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2329 - accuracy: 0.9459 - val_loss: 1.2719 - val_accuracy: 0.7231\n",
            "Epoch 853/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2718 - accuracy: 0.9035 - val_loss: 1.2896 - val_accuracy: 0.7231\n",
            "Epoch 854/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2386 - accuracy: 0.9189 - val_loss: 1.2926 - val_accuracy: 0.6923\n",
            "Epoch 855/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2395 - accuracy: 0.9073 - val_loss: 1.2833 - val_accuracy: 0.7077\n",
            "Epoch 856/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2412 - accuracy: 0.9344 - val_loss: 1.2897 - val_accuracy: 0.7077\n",
            "Epoch 857/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2385 - accuracy: 0.9228 - val_loss: 1.2585 - val_accuracy: 0.7385\n",
            "Epoch 858/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2779 - accuracy: 0.8958 - val_loss: 1.2738 - val_accuracy: 0.7385\n",
            "Epoch 859/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2362 - accuracy: 0.9421 - val_loss: 1.2760 - val_accuracy: 0.7385\n",
            "Epoch 860/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2424 - accuracy: 0.9305 - val_loss: 1.2885 - val_accuracy: 0.7385\n",
            "Epoch 861/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2626 - accuracy: 0.9151 - val_loss: 1.2344 - val_accuracy: 0.7077\n",
            "Epoch 862/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2540 - accuracy: 0.9112 - val_loss: 1.1782 - val_accuracy: 0.7385\n",
            "Epoch 863/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2514 - accuracy: 0.9189 - val_loss: 1.2249 - val_accuracy: 0.7385\n",
            "Epoch 864/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2558 - accuracy: 0.9151 - val_loss: 1.2702 - val_accuracy: 0.6923\n",
            "Epoch 865/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2309 - accuracy: 0.9344 - val_loss: 1.2998 - val_accuracy: 0.7077\n",
            "Epoch 866/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2382 - accuracy: 0.9344 - val_loss: 1.3242 - val_accuracy: 0.7077\n",
            "Epoch 867/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2599 - accuracy: 0.9305 - val_loss: 1.3130 - val_accuracy: 0.7077\n",
            "Epoch 868/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2495 - accuracy: 0.9151 - val_loss: 1.3074 - val_accuracy: 0.7077\n",
            "Epoch 869/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2370 - accuracy: 0.9073 - val_loss: 1.3191 - val_accuracy: 0.7077\n",
            "Epoch 870/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2519 - accuracy: 0.9112 - val_loss: 1.3291 - val_accuracy: 0.7231\n",
            "Epoch 871/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2559 - accuracy: 0.9151 - val_loss: 1.3024 - val_accuracy: 0.7077\n",
            "Epoch 872/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2646 - accuracy: 0.8996 - val_loss: 1.2477 - val_accuracy: 0.7385\n",
            "Epoch 873/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2548 - accuracy: 0.9112 - val_loss: 1.2441 - val_accuracy: 0.7231\n",
            "Epoch 874/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2497 - accuracy: 0.9189 - val_loss: 1.2728 - val_accuracy: 0.7077\n",
            "Epoch 875/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2346 - accuracy: 0.9344 - val_loss: 1.2334 - val_accuracy: 0.7077\n",
            "Epoch 876/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2536 - accuracy: 0.9189 - val_loss: 1.1838 - val_accuracy: 0.7077\n",
            "Epoch 877/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2523 - accuracy: 0.9266 - val_loss: 1.1831 - val_accuracy: 0.7385\n",
            "Epoch 878/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2381 - accuracy: 0.9228 - val_loss: 1.2095 - val_accuracy: 0.7385\n",
            "Epoch 879/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2275 - accuracy: 0.9189 - val_loss: 1.2440 - val_accuracy: 0.7385\n",
            "Epoch 880/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2373 - accuracy: 0.9266 - val_loss: 1.2724 - val_accuracy: 0.7385\n",
            "Epoch 881/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2291 - accuracy: 0.9344 - val_loss: 1.2619 - val_accuracy: 0.7385\n",
            "Epoch 882/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2678 - accuracy: 0.9073 - val_loss: 1.3076 - val_accuracy: 0.7385\n",
            "Epoch 883/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2334 - accuracy: 0.9382 - val_loss: 1.2998 - val_accuracy: 0.7385\n",
            "Epoch 884/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2386 - accuracy: 0.9228 - val_loss: 1.3007 - val_accuracy: 0.7385\n",
            "Epoch 885/1000\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.2394 - accuracy: 0.9266 - val_loss: 1.2858 - val_accuracy: 0.7385\n",
            "Epoch 886/1000\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.2437 - accuracy: 0.9151 - val_loss: 1.2873 - val_accuracy: 0.7385\n",
            "Epoch 887/1000\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.2387 - accuracy: 0.9151 - val_loss: 1.3010 - val_accuracy: 0.7231\n",
            "Epoch 888/1000\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 0.2527 - accuracy: 0.9228 - val_loss: 1.3452 - val_accuracy: 0.7385\n",
            "Epoch 889/1000\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.2537 - accuracy: 0.9421 - val_loss: 1.3084 - val_accuracy: 0.7538\n",
            "Epoch 890/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2515 - accuracy: 0.9228 - val_loss: 1.3041 - val_accuracy: 0.7538\n",
            "Epoch 891/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2396 - accuracy: 0.9073 - val_loss: 1.3046 - val_accuracy: 0.7538\n",
            "Epoch 892/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2512 - accuracy: 0.9112 - val_loss: 1.2784 - val_accuracy: 0.7538\n",
            "Epoch 893/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2474 - accuracy: 0.9228 - val_loss: 1.2539 - val_accuracy: 0.7538\n",
            "Epoch 894/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2391 - accuracy: 0.9151 - val_loss: 1.2536 - val_accuracy: 0.7538\n",
            "Epoch 895/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2414 - accuracy: 0.9266 - val_loss: 1.2707 - val_accuracy: 0.7538\n",
            "Epoch 896/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2501 - accuracy: 0.9073 - val_loss: 1.2973 - val_accuracy: 0.7538\n",
            "Epoch 897/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2420 - accuracy: 0.9228 - val_loss: 1.2722 - val_accuracy: 0.7385\n",
            "Epoch 898/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2428 - accuracy: 0.9189 - val_loss: 1.2828 - val_accuracy: 0.7231\n",
            "Epoch 899/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2667 - accuracy: 0.9035 - val_loss: 1.2754 - val_accuracy: 0.7385\n",
            "Epoch 900/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2450 - accuracy: 0.9344 - val_loss: 1.1680 - val_accuracy: 0.7538\n",
            "Epoch 901/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2692 - accuracy: 0.9151 - val_loss: 1.1800 - val_accuracy: 0.7385\n",
            "Epoch 902/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2544 - accuracy: 0.9151 - val_loss: 1.2204 - val_accuracy: 0.7231\n",
            "Epoch 903/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2734 - accuracy: 0.9189 - val_loss: 1.2476 - val_accuracy: 0.7077\n",
            "Epoch 904/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2571 - accuracy: 0.8958 - val_loss: 1.2546 - val_accuracy: 0.7385\n",
            "Epoch 905/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2571 - accuracy: 0.9189 - val_loss: 1.2421 - val_accuracy: 0.7231\n",
            "Epoch 906/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2460 - accuracy: 0.9228 - val_loss: 1.2702 - val_accuracy: 0.7077\n",
            "Epoch 907/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2451 - accuracy: 0.9035 - val_loss: 1.2664 - val_accuracy: 0.7538\n",
            "Epoch 908/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2233 - accuracy: 0.9421 - val_loss: 1.2536 - val_accuracy: 0.7385\n",
            "Epoch 909/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2460 - accuracy: 0.9344 - val_loss: 1.2739 - val_accuracy: 0.7385\n",
            "Epoch 910/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2444 - accuracy: 0.9112 - val_loss: 1.2983 - val_accuracy: 0.7077\n",
            "Epoch 911/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2573 - accuracy: 0.9073 - val_loss: 1.2370 - val_accuracy: 0.7385\n",
            "Epoch 912/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2501 - accuracy: 0.9305 - val_loss: 1.1702 - val_accuracy: 0.7385\n",
            "Epoch 913/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2834 - accuracy: 0.8880 - val_loss: 1.2156 - val_accuracy: 0.7385\n",
            "Epoch 914/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2522 - accuracy: 0.9151 - val_loss: 1.2653 - val_accuracy: 0.7385\n",
            "Epoch 915/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2406 - accuracy: 0.9228 - val_loss: 1.2823 - val_accuracy: 0.6923\n",
            "Epoch 916/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2606 - accuracy: 0.9112 - val_loss: 1.2906 - val_accuracy: 0.7077\n",
            "Epoch 917/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2333 - accuracy: 0.9266 - val_loss: 1.2651 - val_accuracy: 0.6923\n",
            "Epoch 918/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2691 - accuracy: 0.8996 - val_loss: 1.2279 - val_accuracy: 0.7385\n",
            "Epoch 919/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2297 - accuracy: 0.9305 - val_loss: 1.2072 - val_accuracy: 0.7385\n",
            "Epoch 920/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2441 - accuracy: 0.9189 - val_loss: 1.1876 - val_accuracy: 0.7385\n",
            "Epoch 921/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2518 - accuracy: 0.9305 - val_loss: 1.2041 - val_accuracy: 0.7385\n",
            "Epoch 922/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2391 - accuracy: 0.9228 - val_loss: 1.2456 - val_accuracy: 0.7385\n",
            "Epoch 923/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2159 - accuracy: 0.9421 - val_loss: 1.2779 - val_accuracy: 0.7385\n",
            "Epoch 924/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2405 - accuracy: 0.9305 - val_loss: 1.2669 - val_accuracy: 0.7385\n",
            "Epoch 925/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2478 - accuracy: 0.9189 - val_loss: 1.2021 - val_accuracy: 0.7077\n",
            "Epoch 926/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2449 - accuracy: 0.9266 - val_loss: 1.1390 - val_accuracy: 0.6769\n",
            "Epoch 927/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2552 - accuracy: 0.9266 - val_loss: 1.1546 - val_accuracy: 0.6769\n",
            "Epoch 928/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2680 - accuracy: 0.9112 - val_loss: 1.1538 - val_accuracy: 0.7077\n",
            "Epoch 929/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2919 - accuracy: 0.9112 - val_loss: 1.0606 - val_accuracy: 0.7077\n",
            "Epoch 930/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2688 - accuracy: 0.8996 - val_loss: 1.0130 - val_accuracy: 0.6923\n",
            "Epoch 931/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2665 - accuracy: 0.9189 - val_loss: 1.0427 - val_accuracy: 0.7077\n",
            "Epoch 932/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2440 - accuracy: 0.9266 - val_loss: 1.0891 - val_accuracy: 0.7077\n",
            "Epoch 933/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2403 - accuracy: 0.9382 - val_loss: 1.1225 - val_accuracy: 0.7231\n",
            "Epoch 934/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2658 - accuracy: 0.9035 - val_loss: 1.1939 - val_accuracy: 0.7231\n",
            "Epoch 935/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2484 - accuracy: 0.9228 - val_loss: 1.2172 - val_accuracy: 0.7077\n",
            "Epoch 936/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2439 - accuracy: 0.9189 - val_loss: 1.2183 - val_accuracy: 0.7385\n",
            "Epoch 937/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2410 - accuracy: 0.9228 - val_loss: 1.2213 - val_accuracy: 0.6923\n",
            "Epoch 938/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2348 - accuracy: 0.9189 - val_loss: 1.2293 - val_accuracy: 0.7077\n",
            "Epoch 939/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2267 - accuracy: 0.9228 - val_loss: 1.2282 - val_accuracy: 0.7231\n",
            "Epoch 940/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2260 - accuracy: 0.9459 - val_loss: 1.2300 - val_accuracy: 0.7538\n",
            "Epoch 941/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2347 - accuracy: 0.9266 - val_loss: 1.1939 - val_accuracy: 0.7538\n",
            "Epoch 942/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2295 - accuracy: 0.9305 - val_loss: 1.2082 - val_accuracy: 0.7385\n",
            "Epoch 943/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2454 - accuracy: 0.9189 - val_loss: 1.2505 - val_accuracy: 0.7231\n",
            "Epoch 944/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2515 - accuracy: 0.9112 - val_loss: 1.2603 - val_accuracy: 0.7231\n",
            "Epoch 945/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2350 - accuracy: 0.9421 - val_loss: 1.2440 - val_accuracy: 0.7231\n",
            "Epoch 946/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2348 - accuracy: 0.9382 - val_loss: 1.1865 - val_accuracy: 0.7385\n",
            "Epoch 947/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2440 - accuracy: 0.9228 - val_loss: 1.1828 - val_accuracy: 0.7385\n",
            "Epoch 948/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2539 - accuracy: 0.9189 - val_loss: 1.2304 - val_accuracy: 0.6923\n",
            "Epoch 949/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2331 - accuracy: 0.9228 - val_loss: 1.2628 - val_accuracy: 0.7385\n",
            "Epoch 950/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2529 - accuracy: 0.9189 - val_loss: 1.2744 - val_accuracy: 0.7385\n",
            "Epoch 951/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2438 - accuracy: 0.9305 - val_loss: 1.1618 - val_accuracy: 0.7231\n",
            "Epoch 952/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2602 - accuracy: 0.9073 - val_loss: 1.1342 - val_accuracy: 0.7231\n",
            "Epoch 953/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2618 - accuracy: 0.9344 - val_loss: 1.1746 - val_accuracy: 0.7231\n",
            "Epoch 954/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2505 - accuracy: 0.9151 - val_loss: 1.1929 - val_accuracy: 0.6923\n",
            "Epoch 955/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2379 - accuracy: 0.9344 - val_loss: 1.2013 - val_accuracy: 0.7077\n",
            "Epoch 956/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2415 - accuracy: 0.9228 - val_loss: 1.2039 - val_accuracy: 0.7077\n",
            "Epoch 957/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2495 - accuracy: 0.9112 - val_loss: 1.2596 - val_accuracy: 0.7077\n",
            "Epoch 958/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2277 - accuracy: 0.9266 - val_loss: 1.3059 - val_accuracy: 0.7077\n",
            "Epoch 959/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2523 - accuracy: 0.9189 - val_loss: 1.3218 - val_accuracy: 0.7385\n",
            "Epoch 960/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2780 - accuracy: 0.8996 - val_loss: 1.2917 - val_accuracy: 0.7385\n",
            "Epoch 961/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2363 - accuracy: 0.9344 - val_loss: 1.2753 - val_accuracy: 0.7077\n",
            "Epoch 962/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2332 - accuracy: 0.9228 - val_loss: 1.2619 - val_accuracy: 0.7231\n",
            "Epoch 963/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2233 - accuracy: 0.9421 - val_loss: 1.2525 - val_accuracy: 0.6923\n",
            "Epoch 964/1000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2634 - accuracy: 0.9073 - val_loss: 1.2490 - val_accuracy: 0.7077\n",
            "Epoch 965/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2317 - accuracy: 0.9344 - val_loss: 1.2416 - val_accuracy: 0.7077\n",
            "Epoch 966/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2433 - accuracy: 0.9228 - val_loss: 1.2211 - val_accuracy: 0.7385\n",
            "Epoch 967/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2367 - accuracy: 0.9266 - val_loss: 1.1754 - val_accuracy: 0.7231\n",
            "Epoch 968/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2334 - accuracy: 0.9305 - val_loss: 1.1753 - val_accuracy: 0.7231\n",
            "Epoch 969/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2540 - accuracy: 0.9228 - val_loss: 1.1972 - val_accuracy: 0.7231\n",
            "Epoch 970/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2427 - accuracy: 0.9228 - val_loss: 1.2253 - val_accuracy: 0.7385\n",
            "Epoch 971/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2321 - accuracy: 0.9382 - val_loss: 1.2287 - val_accuracy: 0.6923\n",
            "Epoch 972/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2570 - accuracy: 0.9151 - val_loss: 1.2125 - val_accuracy: 0.6923\n",
            "Epoch 973/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2480 - accuracy: 0.9112 - val_loss: 1.2546 - val_accuracy: 0.7385\n",
            "Epoch 974/1000\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.2552 - accuracy: 0.9344 - val_loss: 1.3678 - val_accuracy: 0.7385\n",
            "Epoch 975/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2458 - accuracy: 0.9151 - val_loss: 1.4080 - val_accuracy: 0.7385\n",
            "Epoch 976/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2862 - accuracy: 0.9151 - val_loss: 1.4032 - val_accuracy: 0.6769\n",
            "Epoch 977/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2532 - accuracy: 0.9035 - val_loss: 1.3655 - val_accuracy: 0.6769\n",
            "Epoch 978/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2437 - accuracy: 0.9189 - val_loss: 1.3393 - val_accuracy: 0.6923\n",
            "Epoch 979/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2786 - accuracy: 0.8996 - val_loss: 1.3273 - val_accuracy: 0.7385\n",
            "Epoch 980/1000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2497 - accuracy: 0.9189 - val_loss: 1.2290 - val_accuracy: 0.7385\n",
            "Epoch 981/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2675 - accuracy: 0.9073 - val_loss: 1.2247 - val_accuracy: 0.7385\n",
            "Epoch 982/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2558 - accuracy: 0.9073 - val_loss: 1.2731 - val_accuracy: 0.7231\n",
            "Epoch 983/1000\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.2286 - accuracy: 0.9305 - val_loss: 1.2808 - val_accuracy: 0.7231\n",
            "Epoch 984/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2285 - accuracy: 0.9266 - val_loss: 1.2939 - val_accuracy: 0.7231\n",
            "Epoch 985/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2524 - accuracy: 0.9073 - val_loss: 1.3050 - val_accuracy: 0.7231\n",
            "Epoch 986/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2437 - accuracy: 0.9344 - val_loss: 1.3133 - val_accuracy: 0.7231\n",
            "Epoch 987/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2429 - accuracy: 0.9266 - val_loss: 1.3300 - val_accuracy: 0.6923\n",
            "Epoch 988/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2523 - accuracy: 0.9266 - val_loss: 1.3149 - val_accuracy: 0.6923\n",
            "Epoch 989/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2517 - accuracy: 0.8996 - val_loss: 1.3054 - val_accuracy: 0.7077\n",
            "Epoch 990/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2664 - accuracy: 0.9073 - val_loss: 1.2779 - val_accuracy: 0.6923\n",
            "Epoch 991/1000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2408 - accuracy: 0.9305 - val_loss: 1.2834 - val_accuracy: 0.6923\n",
            "Epoch 992/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2346 - accuracy: 0.9305 - val_loss: 1.2951 - val_accuracy: 0.6923\n",
            "Epoch 993/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2359 - accuracy: 0.9266 - val_loss: 1.2985 - val_accuracy: 0.6923\n",
            "Epoch 994/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2404 - accuracy: 0.9151 - val_loss: 1.2729 - val_accuracy: 0.6769\n",
            "Epoch 995/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2424 - accuracy: 0.9189 - val_loss: 1.2450 - val_accuracy: 0.7077\n",
            "Epoch 996/1000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2427 - accuracy: 0.9344 - val_loss: 1.2404 - val_accuracy: 0.7385\n",
            "Epoch 997/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2441 - accuracy: 0.9189 - val_loss: 1.2595 - val_accuracy: 0.7538\n",
            "Epoch 998/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2594 - accuracy: 0.9228 - val_loss: 1.2882 - val_accuracy: 0.7538\n",
            "Epoch 999/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2463 - accuracy: 0.9151 - val_loss: 1.2976 - val_accuracy: 0.7385\n",
            "Epoch 1000/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2499 - accuracy: 0.9189 - val_loss: 1.2992 - val_accuracy: 0.7385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Final loss: {loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZ7oVf5QPkiA",
        "outputId": "ca1b7efc-fe85-4835-cb57-878e677cd020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step - loss: 0.7741 - accuracy: 0.8025\n",
            "Final loss: [0.7741213440895081, 0.8024691343307495]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_data_dict = {\n",
        "    'Brand': ['Realme'],\n",
        "    'Model': ['Narzo 50 Pro 5G'],\n",
        "    'Storage': ['128 GB'],\n",
        "    'RAM': ['6 GB'],\n",
        "    'Screen_Size_(inches)': [6.5],\n",
        "    'Camera_(MP)': [48],\n",
        "    'Battery_Capacity_(mAh)':[5000]\n",
        "}\n",
        "\n",
        "new_data = pd.DataFrame(new_data_dict)\n",
        "\n",
        "new_data['Brand'] = label_encoders['Brand'].transform(new_data['Brand'])\n",
        "new_data['Model'] = label_encoders['Model'].transform(new_data['Model'])\n",
        "\n",
        "new_data['Storage'] = new_data['Storage'].apply(convert_memory_size)\n",
        "new_data['RAM'] = new_data['RAM'].apply(convert_memory_size)\n",
        "\n",
        "new_data_normalized = scaler.transform(new_data)\n",
        "\n",
        "predicted_log_price = model.predict(new_data_normalized)\n",
        "# predicted_price = np.expm1(predicted_log_price)\n",
        "y_pred_class = np.argmax(predicted_log_price, axis=1)\n",
        "\n",
        "print(predicted_log_price)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gttQUcjdP5y4",
        "outputId": "31583304-4c83-46c5-953c-75dac17b10a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "[[9.2967134e-03 9.7468215e-01 1.5462394e-02 5.5878988e-04]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(q2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5-siqUAk9f_",
        "outputId": "8ea2abaa-76f7-45f0-9633-258a22803dd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "299.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T1y4zrj-ldIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Price_($)'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvJk14v9R1ZA",
        "outputId": "1cb4d590-40fd-492b-f894-64d96703a780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     407.000000\n",
              "mean      408.314496\n",
              "std       299.684768\n",
              "min        99.000000\n",
              "25%       199.000000\n",
              "50%       299.000000\n",
              "75%       499.000000\n",
              "max      1999.000000\n",
              "Name: Price_($), dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#bersihin kolom\n",
        "# data.columns = data.columns.str.strip()\n",
        "# data.columns = data.columns.str.replace(' ', '_')"
      ],
      "metadata": {
        "id": "cku0wKoZS2Zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data[\"Camera_(MP)\"] = data[\"Camera_(MP)\"].str.replace(\"MP\",\"\")\n",
        "# data[\"Camera_(MP)\"] = data[\"Camera_(MP)\"].str.replace(\"D\",\"\")"
      ],
      "metadata": {
        "id": "-kZSPvB0T0kO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data[\"Camera_(MP)\"] = data[\"Camera_(MP)\"].str.split(\"+\")"
      ],
      "metadata": {
        "id": "O0qTK8mvT95l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data = data.drop(['Model'], axis=1)"
      ],
      "metadata": {
        "id": "fn_zshB3xy4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "4nRpalHVx6P1",
        "outputId": "78dd78fe-64ec-4367-a5bb-c329c17fb986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Brand  Model  Storage  RAM Screen_Size_(inches)              Camera_(MP)  \\\n",
              "0        0    232      128    6                  6.1         [12 ,  12 ,  12]   \n",
              "1       12    100      256   12                  6.8  [108 ,  10 ,  10 ,  12]   \n",
              "2        9     19      128    8                  6.7     [48 ,  50 ,  8 ,  2]   \n",
              "3       15    178      128    6                 6.67      [64 ,  8 ,  5 ,  2]   \n",
              "4        4    162      128    8                  6.4             [50 ,  12.2]   \n",
              "..     ...    ...      ...  ...                  ...                      ...   \n",
              "402     12     95      128    8                  6.7             [12, 64, 12]   \n",
              "403     15    111      128    6                 6.57            [48, 8, 2, 2]   \n",
              "404      0    229      128    6                  6.7             [12, 12, 12]   \n",
              "405     10    188      128    8                  6.4           [48, 13, 8, 2]   \n",
              "406     12     96      128    6                  6.7              [48, 12, 5]   \n",
              "\n",
              "     Battery_Capacity_(mAh) Price_($)  \n",
              "0                      3095       999  \n",
              "1                      5000      1199  \n",
              "2                      4500       899  \n",
              "3                      5020       279  \n",
              "4                      4614       799  \n",
              "..                      ...       ...  \n",
              "402                    4300      1049  \n",
              "403                    4160       349  \n",
              "404                    3687      1099  \n",
              "405                    4025       429  \n",
              "406                    4500       649  \n",
              "\n",
              "[407 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c28e8f49-d4e8-4788-8097-d2b028b9301a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Brand</th>\n",
              "      <th>Model</th>\n",
              "      <th>Storage</th>\n",
              "      <th>RAM</th>\n",
              "      <th>Screen_Size_(inches)</th>\n",
              "      <th>Camera_(MP)</th>\n",
              "      <th>Battery_Capacity_(mAh)</th>\n",
              "      <th>Price_($)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>232</td>\n",
              "      <td>128</td>\n",
              "      <td>6</td>\n",
              "      <td>6.1</td>\n",
              "      <td>[12 ,  12 ,  12]</td>\n",
              "      <td>3095</td>\n",
              "      <td>999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12</td>\n",
              "      <td>100</td>\n",
              "      <td>256</td>\n",
              "      <td>12</td>\n",
              "      <td>6.8</td>\n",
              "      <td>[108 ,  10 ,  10 ,  12]</td>\n",
              "      <td>5000</td>\n",
              "      <td>1199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>19</td>\n",
              "      <td>128</td>\n",
              "      <td>8</td>\n",
              "      <td>6.7</td>\n",
              "      <td>[48 ,  50 ,  8 ,  2]</td>\n",
              "      <td>4500</td>\n",
              "      <td>899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15</td>\n",
              "      <td>178</td>\n",
              "      <td>128</td>\n",
              "      <td>6</td>\n",
              "      <td>6.67</td>\n",
              "      <td>[64 ,  8 ,  5 ,  2]</td>\n",
              "      <td>5020</td>\n",
              "      <td>279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>162</td>\n",
              "      <td>128</td>\n",
              "      <td>8</td>\n",
              "      <td>6.4</td>\n",
              "      <td>[50 ,  12.2]</td>\n",
              "      <td>4614</td>\n",
              "      <td>799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>12</td>\n",
              "      <td>95</td>\n",
              "      <td>128</td>\n",
              "      <td>8</td>\n",
              "      <td>6.7</td>\n",
              "      <td>[12, 64, 12]</td>\n",
              "      <td>4300</td>\n",
              "      <td>1049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>403</th>\n",
              "      <td>15</td>\n",
              "      <td>111</td>\n",
              "      <td>128</td>\n",
              "      <td>6</td>\n",
              "      <td>6.57</td>\n",
              "      <td>[48, 8, 2, 2]</td>\n",
              "      <td>4160</td>\n",
              "      <td>349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404</th>\n",
              "      <td>0</td>\n",
              "      <td>229</td>\n",
              "      <td>128</td>\n",
              "      <td>6</td>\n",
              "      <td>6.7</td>\n",
              "      <td>[12, 12, 12]</td>\n",
              "      <td>3687</td>\n",
              "      <td>1099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405</th>\n",
              "      <td>10</td>\n",
              "      <td>188</td>\n",
              "      <td>128</td>\n",
              "      <td>8</td>\n",
              "      <td>6.4</td>\n",
              "      <td>[48, 13, 8, 2]</td>\n",
              "      <td>4025</td>\n",
              "      <td>429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>406</th>\n",
              "      <td>12</td>\n",
              "      <td>96</td>\n",
              "      <td>128</td>\n",
              "      <td>6</td>\n",
              "      <td>6.7</td>\n",
              "      <td>[48, 12, 5]</td>\n",
              "      <td>4500</td>\n",
              "      <td>649</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>407 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c28e8f49-d4e8-4788-8097-d2b028b9301a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c28e8f49-d4e8-4788-8097-d2b028b9301a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c28e8f49-d4e8-4788-8097-d2b028b9301a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-003404a0-4d64-40ac-8247-8c2043cf0e66\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-003404a0-4d64-40ac-8247-8c2043cf0e66')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-003404a0-4d64-40ac-8247-8c2043cf0e66 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 407,\n  \"fields\": [\n    {\n      \"column\": \"Brand\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0,\n          12,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 70,\n        \"min\": 0,\n        \"max\": 238,\n        \"num_unique_values\": 239,\n        \"samples\": [\n          179,\n          104,\n          199\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Storage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 64,\n        \"min\": 32,\n        \"max\": 512,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          256,\n          512,\n          64\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RAM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 2,\n        \"max\": 16,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          12,\n          2,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Screen_Size_(inches)\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 41,\n        \"samples\": [\n          \"5.5\",\n          \"6.6\",\n          \"6.5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Camera_(MP)\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Battery_Capacity_(mAh)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 797,\n        \"min\": 1821,\n        \"max\": 7000,\n        \"num_unique_values\": 48,\n        \"samples\": [\n          5050,\n          3174,\n          4950\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price_($)\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 89,\n        \"samples\": [\n          \"$319 \",\n          \"$139 \",\n          \"1299\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data = data.drop(['Camera_1_MP', 'Camera_2_MP', 'Camera_3_MP', 'Camera_4_MP'], axis=1)"
      ],
      "metadata": {
        "id": "ZF7m_s7rUfZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data = data[~(data[\"Screen_Size_(inches)\"] == \"7.6 (unfolded)\")]\n",
        "# data = data[~(data[\"Screen_Size_(inches)\"] == \"6.8 + 3.9\")]\n",
        "# data[\"Screen_Size_(inches)\"] = data[\"Screen_Size_(inches)\"].astype(\"float64\")"
      ],
      "metadata": {
        "id": "XyrUF7xcUSwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# listx = []\n",
        "# for i in data.index:\n",
        "#     listx.append(data[\"Camera_(MP)\"][i][0])\n",
        "\n",
        "# data[\"Camera_(MP)\"] = listx\n",
        "# data[\"Camera_(MP)\"] = data[\"Camera_(MP)\"].astype(\"float64\")"
      ],
      "metadata": {
        "id": "YoOZONREUHWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1i5WZOoU0u-",
        "outputId": "e92b0423-3b41-4853-c23f-bf8c4bc425a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 405 entries, 0 to 406\n",
            "Data columns (total 8 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   Brand                   405 non-null    int64  \n",
            " 1   Model                   405 non-null    int64  \n",
            " 2   Storage                 405 non-null    int64  \n",
            " 3   RAM                     405 non-null    int64  \n",
            " 4   Screen_Size_(inches)    405 non-null    float64\n",
            " 5   Camera_(MP)             405 non-null    float64\n",
            " 6   Battery_Capacity_(mAh)  405 non-null    int64  \n",
            " 7   Price_($)               405 non-null    object \n",
            "dtypes: float64(2), int64(5), object(1)\n",
            "memory usage: 44.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data['Price_($)'] = data['Price_($)'].str.replace('$','')"
      ],
      "metadata": {
        "id": "0hD5lOJrWJ1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data['Brand'] = data['Brand'].astype(\"float64\")"
      ],
      "metadata": {
        "id": "lUBvF-EKWT6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data['Storage'] = data['Storage'].astype(\"float64\")"
      ],
      "metadata": {
        "id": "kzgKCe7KXrE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data['RAM'] = data['RAM'].astype(\"float64\")"
      ],
      "metadata": {
        "id": "DlLIzvZlXuSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data['Battery_Capacity_(mAh)'] = data['Battery_Capacity_(mAh)'].astype(\"float64\")"
      ],
      "metadata": {
        "id": "o7gihA1kYFom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data['Price_($)'] = data['Price_($)'].str.replace(',','')"
      ],
      "metadata": {
        "id": "_eNuXNevYZhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data['Price_($)'] = data['Price_($)'].astype(\"float64\")"
      ],
      "metadata": {
        "id": "lGgP16aqYKwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "RNMUGtCmXlE3",
        "outputId": "1f594997-97e0-4df3-9723-0e82688785d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Brand  Model  Storage   RAM  Screen_Size_(inches)  Camera_(MP)  \\\n",
              "0      0.0    232    128.0   6.0                  6.10         12.0   \n",
              "1     12.0    100    256.0  12.0                  6.80        108.0   \n",
              "2      9.0     19    128.0   8.0                  6.70         48.0   \n",
              "3     15.0    178    128.0   6.0                  6.67         64.0   \n",
              "4      4.0    162    128.0   8.0                  6.40         50.0   \n",
              "..     ...    ...      ...   ...                   ...          ...   \n",
              "402   12.0     95    128.0   8.0                  6.70         12.0   \n",
              "403   15.0    111    128.0   6.0                  6.57         48.0   \n",
              "404    0.0    229    128.0   6.0                  6.70         12.0   \n",
              "405   10.0    188    128.0   8.0                  6.40         48.0   \n",
              "406   12.0     96    128.0   6.0                  6.70         48.0   \n",
              "\n",
              "     Battery_Capacity_(mAh)  Price_($)  \n",
              "0                    3095.0      999.0  \n",
              "1                    5000.0     1199.0  \n",
              "2                    4500.0      899.0  \n",
              "3                    5020.0      279.0  \n",
              "4                    4614.0      799.0  \n",
              "..                      ...        ...  \n",
              "402                  4300.0     1049.0  \n",
              "403                  4160.0      349.0  \n",
              "404                  3687.0     1099.0  \n",
              "405                  4025.0      429.0  \n",
              "406                  4500.0      649.0  \n",
              "\n",
              "[405 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d5bfb0a-04e5-4b13-9100-01a13dffd882\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Brand</th>\n",
              "      <th>Model</th>\n",
              "      <th>Storage</th>\n",
              "      <th>RAM</th>\n",
              "      <th>Screen_Size_(inches)</th>\n",
              "      <th>Camera_(MP)</th>\n",
              "      <th>Battery_Capacity_(mAh)</th>\n",
              "      <th>Price_($)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>232</td>\n",
              "      <td>128.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.10</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3095.0</td>\n",
              "      <td>999.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12.0</td>\n",
              "      <td>100</td>\n",
              "      <td>256.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>6.80</td>\n",
              "      <td>108.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>1199.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.0</td>\n",
              "      <td>19</td>\n",
              "      <td>128.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.70</td>\n",
              "      <td>48.0</td>\n",
              "      <td>4500.0</td>\n",
              "      <td>899.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15.0</td>\n",
              "      <td>178</td>\n",
              "      <td>128.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.67</td>\n",
              "      <td>64.0</td>\n",
              "      <td>5020.0</td>\n",
              "      <td>279.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>162</td>\n",
              "      <td>128.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.40</td>\n",
              "      <td>50.0</td>\n",
              "      <td>4614.0</td>\n",
              "      <td>799.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>12.0</td>\n",
              "      <td>95</td>\n",
              "      <td>128.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.70</td>\n",
              "      <td>12.0</td>\n",
              "      <td>4300.0</td>\n",
              "      <td>1049.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>403</th>\n",
              "      <td>15.0</td>\n",
              "      <td>111</td>\n",
              "      <td>128.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.57</td>\n",
              "      <td>48.0</td>\n",
              "      <td>4160.0</td>\n",
              "      <td>349.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404</th>\n",
              "      <td>0.0</td>\n",
              "      <td>229</td>\n",
              "      <td>128.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.70</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3687.0</td>\n",
              "      <td>1099.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405</th>\n",
              "      <td>10.0</td>\n",
              "      <td>188</td>\n",
              "      <td>128.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.40</td>\n",
              "      <td>48.0</td>\n",
              "      <td>4025.0</td>\n",
              "      <td>429.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>406</th>\n",
              "      <td>12.0</td>\n",
              "      <td>96</td>\n",
              "      <td>128.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.70</td>\n",
              "      <td>48.0</td>\n",
              "      <td>4500.0</td>\n",
              "      <td>649.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>405 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d5bfb0a-04e5-4b13-9100-01a13dffd882')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2d5bfb0a-04e5-4b13-9100-01a13dffd882 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2d5bfb0a-04e5-4b13-9100-01a13dffd882');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2c45543f-f912-401b-bda3-9472121a900e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2c45543f-f912-401b-bda3-9472121a900e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2c45543f-f912-401b-bda3-9472121a900e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 405,\n  \"fields\": [\n    {\n      \"column\": \"Brand\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.1842204495075315,\n        \"min\": 0.0,\n        \"max\": 15.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.0,\n          12.0,\n          10.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 70,\n        \"min\": 0,\n        \"max\": 238,\n        \"num_unique_values\": 237,\n        \"samples\": [\n          84,\n          119,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Storage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 64.44504836407594,\n        \"min\": 32.0,\n        \"max\": 512.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          256.0,\n          512.0,\n          64.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RAM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.4161579703093308,\n        \"min\": 2.0,\n        \"max\": 16.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          12.0,\n          2.0,\n          6.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Screen_Size_(inches)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3159461337287799,\n        \"min\": 4.5,\n        \"max\": 6.9,\n        \"num_unique_values\": 39,\n        \"samples\": [\n          6.49,\n          6.47,\n          6.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Camera_(MP)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24.659402888904385,\n        \"min\": 8.0,\n        \"max\": 108.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          13.0,\n          12.0,\n          40.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Battery_Capacity_(mAh)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 798.4044616320672,\n        \"min\": 1821.0,\n        \"max\": 7000.0,\n        \"num_unique_values\": 48,\n        \"samples\": [\n          5050.0,\n          3174.0,\n          4950.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price_($)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 288.27032367815264,\n        \"min\": 99.0,\n        \"max\": 1399.0,\n        \"num_unique_values\": 56,\n        \"samples\": [\n          999.0,\n          249.0,\n          269.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# features = data.drop(columns=['Price_($)'])\n",
        "# target = data['Price_($)']"
      ],
      "metadata": {
        "id": "a7b69wOMV9cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scaler = StandardScaler()\n",
        "# features = scaler.fit_transform(features)"
      ],
      "metadata": {
        "id": "SvUj-Z9RWM5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# target_log = np.log1p(target)"
      ],
      "metadata": {
        "id": "aqZ6OJnFcQwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "# features_poly = poly.fit_transform(features)"
      ],
      "metadata": {
        "id": "gnD7Mk_q1lNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(features, target_log, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "mCL0ysltWPO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = Sequential([\n",
        "#     Dense(128, input_dim=X_train.shape[1], activation='relu', kernel_regularizer=l2(0.001)),\n",
        "#     Dropout(0.2),\n",
        "#     Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "#     Dropout(0.2),\n",
        "#     Dense(32, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "#     Dropout(0.2),\n",
        "#     Dense(1)\n",
        "# ])"
      ],
      "metadata": {
        "id": "jJtKM3fUWQwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(data['Model'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QRq3dQM3bZy",
        "outputId": "a3598d1d-9fbd-4c9f-ea8a-aefcd1fa1af0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "238"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
      ],
      "metadata": {
        "id": "NfaIn26GWSUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm-dpWw_3jTN",
        "outputId": "fadc5efb-018b-4016-c1cf-a11a4e955057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 40)                320       \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 40)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 20)                820       \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 20)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1161 (4.54 KB)\n",
            "Trainable params: 1161 (4.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "dZnmjreTcZVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# history = model.fit(X_train, y_train, epochs=200, validation_split=0.2, batch_size=32, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEmEkRDVcZTN",
        "outputId": "944caa94-9271-4ca0-8f80-38c0af56f17f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "9/9 [==============================] - 1s 27ms/step - loss: 30.9887 - mae: 5.5032 - val_loss: 25.9618 - val_mae: 5.0393\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 23.2667 - mae: 4.7379 - val_loss: 17.6829 - val_mae: 4.1132\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.4293 - mae: 3.6221 - val_loss: 8.3959 - val_mae: 2.6709\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.5880 - mae: 2.3887 - val_loss: 3.2058 - val_mae: 1.3217\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.6364 - mae: 1.8327 - val_loss: 2.9396 - val_mae: 1.3476\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.5794 - mae: 1.6792 - val_loss: 2.4286 - val_mae: 1.1938\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7046 - mae: 1.6612 - val_loss: 2.3634 - val_mae: 1.1850\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.7101 - mae: 1.5723 - val_loss: 2.0346 - val_mae: 1.0621\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.5426 - mae: 1.5100 - val_loss: 1.7984 - val_mae: 0.9864\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.0631 - mae: 1.3445 - val_loss: 1.6347 - val_mae: 0.9254\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.1624 - mae: 1.3999 - val_loss: 1.4696 - val_mae: 0.8589\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.1910 - mae: 1.3303 - val_loss: 1.3493 - val_mae: 0.8017\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.6589 - mae: 1.3165 - val_loss: 1.3961 - val_mae: 0.8312\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.6919 - mae: 1.3146 - val_loss: 1.3665 - val_mae: 0.8299\n",
            "Epoch 15/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.6407 - mae: 1.3016 - val_loss: 0.9925 - val_mae: 0.6840\n",
            "Epoch 16/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4181 - mae: 1.1961 - val_loss: 0.9298 - val_mae: 0.6717\n",
            "Epoch 17/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1583 - mae: 1.1326 - val_loss: 0.9425 - val_mae: 0.6586\n",
            "Epoch 18/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.8009 - mae: 1.0141 - val_loss: 0.9195 - val_mae: 0.6598\n",
            "Epoch 19/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.9559 - mae: 1.0615 - val_loss: 0.8796 - val_mae: 0.6335\n",
            "Epoch 20/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.9356 - mae: 1.0521 - val_loss: 0.8957 - val_mae: 0.6333\n",
            "Epoch 21/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.9782 - mae: 1.0584 - val_loss: 0.8245 - val_mae: 0.5988\n",
            "Epoch 22/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.0429 - mae: 1.0909 - val_loss: 0.7570 - val_mae: 0.5742\n",
            "Epoch 23/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.9698 - mae: 1.0269 - val_loss: 0.7818 - val_mae: 0.5928\n",
            "Epoch 24/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.7249 - mae: 0.9983 - val_loss: 0.7491 - val_mae: 0.5757\n",
            "Epoch 25/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.7579 - mae: 1.0466 - val_loss: 0.7091 - val_mae: 0.5557\n",
            "Epoch 26/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0644 - mae: 1.0947 - val_loss: 0.8090 - val_mae: 0.6063\n",
            "Epoch 27/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.7850 - mae: 1.0111 - val_loss: 0.6925 - val_mae: 0.5532\n",
            "Epoch 28/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.6461 - mae: 0.9894 - val_loss: 0.6580 - val_mae: 0.5409\n",
            "Epoch 29/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.6794 - mae: 0.9814 - val_loss: 0.6438 - val_mae: 0.5327\n",
            "Epoch 30/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.6720 - mae: 0.9698 - val_loss: 0.6400 - val_mae: 0.5352\n",
            "Epoch 31/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.6031 - mae: 0.9761 - val_loss: 0.5951 - val_mae: 0.4860\n",
            "Epoch 32/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.7891 - mae: 0.9760 - val_loss: 0.5789 - val_mae: 0.4859\n",
            "Epoch 33/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.6673 - mae: 0.9927 - val_loss: 0.6347 - val_mae: 0.5413\n",
            "Epoch 34/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.6332 - mae: 0.9645 - val_loss: 0.8355 - val_mae: 0.7016\n",
            "Epoch 35/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.5434 - mae: 0.9283 - val_loss: 0.5896 - val_mae: 0.5090\n",
            "Epoch 36/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.4331 - mae: 0.9256 - val_loss: 0.5672 - val_mae: 0.5020\n",
            "Epoch 37/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.3940 - mae: 0.8764 - val_loss: 0.5402 - val_mae: 0.4768\n",
            "Epoch 38/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.3951 - mae: 0.8862 - val_loss: 0.5121 - val_mae: 0.4501\n",
            "Epoch 39/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.3414 - mae: 0.8743 - val_loss: 0.5174 - val_mae: 0.4509\n",
            "Epoch 40/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.1734 - mae: 0.8005 - val_loss: 0.4883 - val_mae: 0.4379\n",
            "Epoch 41/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2857 - mae: 0.8510 - val_loss: 0.4751 - val_mae: 0.4283\n",
            "Epoch 42/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.4488 - mae: 0.9091 - val_loss: 0.5373 - val_mae: 0.4815\n",
            "Epoch 43/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.1731 - mae: 0.8104 - val_loss: 0.4803 - val_mae: 0.4581\n",
            "Epoch 44/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.4108 - mae: 0.9045 - val_loss: 0.4860 - val_mae: 0.4665\n",
            "Epoch 45/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.1201 - mae: 0.7707 - val_loss: 0.4931 - val_mae: 0.4508\n",
            "Epoch 46/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.5413 - mae: 0.9527 - val_loss: 0.6908 - val_mae: 0.6017\n",
            "Epoch 47/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.4338 - mae: 0.9106 - val_loss: 0.4920 - val_mae: 0.4520\n",
            "Epoch 48/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2510 - mae: 0.8233 - val_loss: 0.4203 - val_mae: 0.3960\n",
            "Epoch 49/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.3840 - mae: 0.8896 - val_loss: 0.6292 - val_mae: 0.5301\n",
            "Epoch 50/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3530 - mae: 0.8624 - val_loss: 0.4170 - val_mae: 0.3733\n",
            "Epoch 51/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2891 - mae: 0.8267 - val_loss: 0.3772 - val_mae: 0.3730\n",
            "Epoch 52/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0534 - mae: 0.7700 - val_loss: 0.4453 - val_mae: 0.4451\n",
            "Epoch 53/200\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.1783 - mae: 0.8133 - val_loss: 0.3854 - val_mae: 0.3774\n",
            "Epoch 54/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1239 - mae: 0.7935 - val_loss: 0.3845 - val_mae: 0.3730\n",
            "Epoch 55/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 1.1298 - mae: 0.8159 - val_loss: 0.4125 - val_mae: 0.3951\n",
            "Epoch 56/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1.1408 - mae: 0.8231 - val_loss: 0.3601 - val_mae: 0.3587\n",
            "Epoch 57/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2774 - mae: 0.8411 - val_loss: 0.3770 - val_mae: 0.3855\n",
            "Epoch 58/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0875 - mae: 0.7891 - val_loss: 0.4233 - val_mae: 0.4358\n",
            "Epoch 59/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.3163 - mae: 0.8852 - val_loss: 0.3376 - val_mae: 0.3334\n",
            "Epoch 60/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.0156 - mae: 0.7449 - val_loss: 0.4503 - val_mae: 0.4546\n",
            "Epoch 61/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2361 - mae: 0.8290 - val_loss: 0.4780 - val_mae: 0.4678\n",
            "Epoch 62/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.1499 - mae: 0.8047 - val_loss: 0.4135 - val_mae: 0.4252\n",
            "Epoch 63/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.1149 - mae: 0.7934 - val_loss: 0.3731 - val_mae: 0.3985\n",
            "Epoch 64/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.1374 - mae: 0.7963 - val_loss: 0.4019 - val_mae: 0.4235\n",
            "Epoch 65/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.1861 - mae: 0.8059 - val_loss: 0.5021 - val_mae: 0.5012\n",
            "Epoch 66/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.1070 - mae: 0.7910 - val_loss: 0.4414 - val_mae: 0.4060\n",
            "Epoch 67/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0836 - mae: 0.7879 - val_loss: 0.3160 - val_mae: 0.3248\n",
            "Epoch 68/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.0432 - mae: 0.7600 - val_loss: 0.4311 - val_mae: 0.4389\n",
            "Epoch 69/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.1543 - mae: 0.7980 - val_loss: 0.3747 - val_mae: 0.3925\n",
            "Epoch 70/200\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.0178 - mae: 0.7555 - val_loss: 0.4263 - val_mae: 0.4370\n",
            "Epoch 71/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0193 - mae: 0.7462 - val_loss: 0.3121 - val_mae: 0.3285\n",
            "Epoch 72/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.0626 - mae: 0.7778 - val_loss: 0.3389 - val_mae: 0.3409\n",
            "Epoch 73/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0594 - mae: 0.7826 - val_loss: 0.3471 - val_mae: 0.3495\n",
            "Epoch 74/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0171 - mae: 0.7518 - val_loss: 0.3406 - val_mae: 0.3440\n",
            "Epoch 75/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.2110 - mae: 0.8081 - val_loss: 0.3312 - val_mae: 0.3333\n",
            "Epoch 76/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.9184 - mae: 0.7060 - val_loss: 0.2996 - val_mae: 0.3121\n",
            "Epoch 77/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.0519 - mae: 0.7799 - val_loss: 0.3152 - val_mae: 0.3160\n",
            "Epoch 78/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.9196 - mae: 0.6937 - val_loss: 0.3772 - val_mae: 0.3820\n",
            "Epoch 79/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.9645 - mae: 0.7062 - val_loss: 0.3626 - val_mae: 0.3767\n",
            "Epoch 80/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.9872 - mae: 0.7480 - val_loss: 0.3949 - val_mae: 0.4253\n",
            "Epoch 81/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.0622 - mae: 0.7476 - val_loss: 0.3054 - val_mae: 0.3068\n",
            "Epoch 82/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1608 - mae: 0.7807 - val_loss: 0.4138 - val_mae: 0.4538\n",
            "Epoch 83/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.0894 - mae: 0.7869 - val_loss: 0.3421 - val_mae: 0.3501\n",
            "Epoch 84/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0509 - mae: 0.7543 - val_loss: 0.2918 - val_mae: 0.2927\n",
            "Epoch 85/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.9926 - mae: 0.7307 - val_loss: 0.2982 - val_mae: 0.3024\n",
            "Epoch 86/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.9237 - mae: 0.6965 - val_loss: 0.4719 - val_mae: 0.5065\n",
            "Epoch 87/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.0258 - mae: 0.7501 - val_loss: 0.2750 - val_mae: 0.2877\n",
            "Epoch 88/200\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.9306 - mae: 0.7117 - val_loss: 0.2872 - val_mae: 0.3054\n",
            "Epoch 89/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.1806 - mae: 0.7740 - val_loss: 0.3299 - val_mae: 0.3317\n",
            "Epoch 90/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.8850 - mae: 0.6877 - val_loss: 0.2845 - val_mae: 0.2841\n",
            "Epoch 91/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.0320 - mae: 0.7257 - val_loss: 0.3134 - val_mae: 0.3477\n",
            "Epoch 92/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.8970 - mae: 0.7132 - val_loss: 0.2670 - val_mae: 0.2998\n",
            "Epoch 93/200\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.9392 - mae: 0.7182 - val_loss: 0.3532 - val_mae: 0.3950\n",
            "Epoch 94/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.2425 - mae: 0.8225 - val_loss: 0.4443 - val_mae: 0.4763\n",
            "Epoch 95/200\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.0627 - mae: 0.7527 - val_loss: 0.2609 - val_mae: 0.2912\n",
            "Epoch 96/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0503 - mae: 0.7757 - val_loss: 0.2751 - val_mae: 0.2998\n",
            "Epoch 97/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.0143 - mae: 0.7285 - val_loss: 0.3826 - val_mae: 0.4273\n",
            "Epoch 98/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.9594 - mae: 0.7163 - val_loss: 0.2592 - val_mae: 0.2666\n",
            "Epoch 99/200\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.8928 - mae: 0.7016 - val_loss: 0.2900 - val_mae: 0.2887\n",
            "Epoch 100/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.1085 - mae: 0.7956 - val_loss: 0.2867 - val_mae: 0.3150\n",
            "Epoch 101/200\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.0467 - mae: 0.7443 - val_loss: 0.2778 - val_mae: 0.3031\n",
            "Epoch 102/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9944 - mae: 0.7714 - val_loss: 0.3251 - val_mae: 0.3431\n",
            "Epoch 103/200\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.8073 - mae: 0.6674 - val_loss: 0.2486 - val_mae: 0.2502\n",
            "Epoch 104/200\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.9575 - mae: 0.7145 - val_loss: 0.3134 - val_mae: 0.3350\n",
            "Epoch 105/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1259 - mae: 0.7712 - val_loss: 0.2745 - val_mae: 0.3079\n",
            "Epoch 106/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9638 - mae: 0.7357 - val_loss: 0.2590 - val_mae: 0.2822\n",
            "Epoch 107/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9397 - mae: 0.7272 - val_loss: 0.2562 - val_mae: 0.2788\n",
            "Epoch 108/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.0083 - mae: 0.7266 - val_loss: 0.2266 - val_mae: 0.2330\n",
            "Epoch 109/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9425 - mae: 0.7267 - val_loss: 0.3982 - val_mae: 0.4369\n",
            "Epoch 110/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8221 - mae: 0.6637 - val_loss: 0.2784 - val_mae: 0.3008\n",
            "Epoch 111/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8347 - mae: 0.6747 - val_loss: 0.2670 - val_mae: 0.2947\n",
            "Epoch 112/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9703 - mae: 0.7269 - val_loss: 0.2703 - val_mae: 0.2984\n",
            "Epoch 113/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.8675 - mae: 0.6893 - val_loss: 0.2884 - val_mae: 0.3189\n",
            "Epoch 114/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9942 - mae: 0.7367 - val_loss: 0.3790 - val_mae: 0.4168\n",
            "Epoch 115/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.0903 - mae: 0.7586 - val_loss: 0.2535 - val_mae: 0.2715\n",
            "Epoch 116/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8529 - mae: 0.6994 - val_loss: 0.2364 - val_mae: 0.2595\n",
            "Epoch 117/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9576 - mae: 0.7305 - val_loss: 0.2774 - val_mae: 0.3110\n",
            "Epoch 118/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9324 - mae: 0.7302 - val_loss: 0.3361 - val_mae: 0.3844\n",
            "Epoch 119/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9273 - mae: 0.7371 - val_loss: 0.2234 - val_mae: 0.2407\n",
            "Epoch 120/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9751 - mae: 0.7048 - val_loss: 0.2419 - val_mae: 0.2477\n",
            "Epoch 121/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.0055 - mae: 0.7397 - val_loss: 0.2886 - val_mae: 0.3216\n",
            "Epoch 122/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7969 - mae: 0.6534 - val_loss: 0.2289 - val_mae: 0.2403\n",
            "Epoch 123/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8715 - mae: 0.6796 - val_loss: 0.2967 - val_mae: 0.3286\n",
            "Epoch 124/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8383 - mae: 0.6791 - val_loss: 0.2255 - val_mae: 0.2299\n",
            "Epoch 125/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.8603 - mae: 0.6775 - val_loss: 0.2440 - val_mae: 0.2719\n",
            "Epoch 126/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.9025 - mae: 0.6976 - val_loss: 0.2920 - val_mae: 0.3270\n",
            "Epoch 127/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9345 - mae: 0.7055 - val_loss: 0.2337 - val_mae: 0.2488\n",
            "Epoch 128/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0045 - mae: 0.7281 - val_loss: 0.2971 - val_mae: 0.3254\n",
            "Epoch 129/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8258 - mae: 0.6420 - val_loss: 0.2095 - val_mae: 0.2249\n",
            "Epoch 130/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.8237 - mae: 0.6588 - val_loss: 0.2818 - val_mae: 0.3412\n",
            "Epoch 131/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.9277 - mae: 0.7275 - val_loss: 0.2167 - val_mae: 0.2465\n",
            "Epoch 132/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.8647 - mae: 0.6804 - val_loss: 0.2310 - val_mae: 0.2528\n",
            "Epoch 133/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9062 - mae: 0.6948 - val_loss: 0.2375 - val_mae: 0.2573\n",
            "Epoch 134/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.9147 - mae: 0.7289 - val_loss: 0.3444 - val_mae: 0.3663\n",
            "Epoch 135/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8140 - mae: 0.6801 - val_loss: 0.2146 - val_mae: 0.2357\n",
            "Epoch 136/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9319 - mae: 0.7129 - val_loss: 0.2282 - val_mae: 0.2621\n",
            "Epoch 137/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7551 - mae: 0.6360 - val_loss: 0.2903 - val_mae: 0.3535\n",
            "Epoch 138/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7840 - mae: 0.6410 - val_loss: 0.2077 - val_mae: 0.2356\n",
            "Epoch 139/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6909 - mae: 0.6135 - val_loss: 0.2125 - val_mae: 0.2300\n",
            "Epoch 140/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9365 - mae: 0.7229 - val_loss: 0.2466 - val_mae: 0.2671\n",
            "Epoch 141/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8770 - mae: 0.6887 - val_loss: 0.2289 - val_mae: 0.2463\n",
            "Epoch 142/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8694 - mae: 0.6757 - val_loss: 0.2272 - val_mae: 0.2384\n",
            "Epoch 143/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8251 - mae: 0.6736 - val_loss: 0.2250 - val_mae: 0.2561\n",
            "Epoch 144/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7816 - mae: 0.6527 - val_loss: 0.2519 - val_mae: 0.2950\n",
            "Epoch 145/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7759 - mae: 0.6573 - val_loss: 0.2073 - val_mae: 0.2331\n",
            "Epoch 146/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8979 - mae: 0.6837 - val_loss: 0.2456 - val_mae: 0.2717\n",
            "Epoch 147/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8355 - mae: 0.6547 - val_loss: 0.2729 - val_mae: 0.3068\n",
            "Epoch 148/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9402 - mae: 0.7203 - val_loss: 0.2527 - val_mae: 0.2805\n",
            "Epoch 149/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8711 - mae: 0.7181 - val_loss: 0.3193 - val_mae: 0.3621\n",
            "Epoch 150/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.8301 - mae: 0.6820 - val_loss: 0.2285 - val_mae: 0.2505\n",
            "Epoch 151/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8468 - mae: 0.6936 - val_loss: 0.2305 - val_mae: 0.2538\n",
            "Epoch 152/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8130 - mae: 0.6605 - val_loss: 0.2314 - val_mae: 0.2649\n",
            "Epoch 153/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8257 - mae: 0.6591 - val_loss: 0.2209 - val_mae: 0.2467\n",
            "Epoch 154/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7919 - mae: 0.6441 - val_loss: 0.2230 - val_mae: 0.2504\n",
            "Epoch 155/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8490 - mae: 0.6817 - val_loss: 0.2294 - val_mae: 0.2526\n",
            "Epoch 156/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8244 - mae: 0.6647 - val_loss: 0.2190 - val_mae: 0.2563\n",
            "Epoch 157/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7468 - mae: 0.6324 - val_loss: 0.1858 - val_mae: 0.2116\n",
            "Epoch 158/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7602 - mae: 0.6400 - val_loss: 0.1979 - val_mae: 0.2232\n",
            "Epoch 159/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.8020 - mae: 0.6851 - val_loss: 0.1923 - val_mae: 0.2178\n",
            "Epoch 160/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8574 - mae: 0.6831 - val_loss: 0.2139 - val_mae: 0.2475\n",
            "Epoch 161/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.8567 - mae: 0.6791 - val_loss: 0.2408 - val_mae: 0.2671\n",
            "Epoch 162/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8301 - mae: 0.6826 - val_loss: 0.3530 - val_mae: 0.4053\n",
            "Epoch 163/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8317 - mae: 0.6719 - val_loss: 0.2069 - val_mae: 0.2258\n",
            "Epoch 164/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8009 - mae: 0.6582 - val_loss: 0.2802 - val_mae: 0.3274\n",
            "Epoch 165/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6809 - mae: 0.5955 - val_loss: 0.1972 - val_mae: 0.2213\n",
            "Epoch 166/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8122 - mae: 0.6519 - val_loss: 0.3250 - val_mae: 0.3742\n",
            "Epoch 167/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8063 - mae: 0.6630 - val_loss: 0.2196 - val_mae: 0.2542\n",
            "Epoch 168/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8631 - mae: 0.7032 - val_loss: 0.2721 - val_mae: 0.3123\n",
            "Epoch 169/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7748 - mae: 0.6600 - val_loss: 0.2528 - val_mae: 0.2852\n",
            "Epoch 170/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8041 - mae: 0.6805 - val_loss: 0.2571 - val_mae: 0.2886\n",
            "Epoch 171/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7997 - mae: 0.6711 - val_loss: 0.1876 - val_mae: 0.2100\n",
            "Epoch 172/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8656 - mae: 0.6821 - val_loss: 0.2001 - val_mae: 0.2247\n",
            "Epoch 173/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.7476 - mae: 0.6371 - val_loss: 0.1971 - val_mae: 0.2169\n",
            "Epoch 174/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.7440 - mae: 0.6131 - val_loss: 0.2270 - val_mae: 0.2607\n",
            "Epoch 175/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.7749 - mae: 0.6386 - val_loss: 0.1993 - val_mae: 0.2281\n",
            "Epoch 176/200\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.7561 - mae: 0.6271 - val_loss: 0.2096 - val_mae: 0.2508\n",
            "Epoch 177/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.8115 - mae: 0.6723 - val_loss: 0.1766 - val_mae: 0.2088\n",
            "Epoch 178/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.8832 - mae: 0.6993 - val_loss: 0.3024 - val_mae: 0.3490\n",
            "Epoch 179/200\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.7640 - mae: 0.6355 - val_loss: 0.2078 - val_mae: 0.2220\n",
            "Epoch 180/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.8651 - mae: 0.7097 - val_loss: 0.2067 - val_mae: 0.2265\n",
            "Epoch 181/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.7464 - mae: 0.6378 - val_loss: 0.2257 - val_mae: 0.2705\n",
            "Epoch 182/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7537 - mae: 0.6267 - val_loss: 0.1989 - val_mae: 0.2362\n",
            "Epoch 183/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6611 - mae: 0.6001 - val_loss: 0.1868 - val_mae: 0.2078\n",
            "Epoch 184/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7523 - mae: 0.6255 - val_loss: 0.2327 - val_mae: 0.2791\n",
            "Epoch 185/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7946 - mae: 0.6543 - val_loss: 0.2352 - val_mae: 0.2829\n",
            "Epoch 186/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7839 - mae: 0.6735 - val_loss: 0.1652 - val_mae: 0.1871\n",
            "Epoch 187/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.8083 - mae: 0.6665 - val_loss: 0.3406 - val_mae: 0.4155\n",
            "Epoch 188/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7629 - mae: 0.6489 - val_loss: 0.1855 - val_mae: 0.2070\n",
            "Epoch 189/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8177 - mae: 0.6764 - val_loss: 0.1911 - val_mae: 0.2145\n",
            "Epoch 190/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7863 - mae: 0.6529 - val_loss: 0.2060 - val_mae: 0.2355\n",
            "Epoch 191/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7822 - mae: 0.6581 - val_loss: 0.2609 - val_mae: 0.3059\n",
            "Epoch 192/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9229 - mae: 0.7155 - val_loss: 0.1950 - val_mae: 0.2263\n",
            "Epoch 193/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8026 - mae: 0.6836 - val_loss: 0.2063 - val_mae: 0.2426\n",
            "Epoch 194/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7262 - mae: 0.6050 - val_loss: 0.2193 - val_mae: 0.2630\n",
            "Epoch 195/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7995 - mae: 0.6603 - val_loss: 0.1827 - val_mae: 0.1910\n",
            "Epoch 196/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7030 - mae: 0.6150 - val_loss: 0.2080 - val_mae: 0.2431\n",
            "Epoch 197/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7087 - mae: 0.6284 - val_loss: 0.2173 - val_mae: 0.2568\n",
            "Epoch 198/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7749 - mae: 0.6421 - val_loss: 0.1946 - val_mae: 0.2188\n",
            "Epoch 199/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8618 - mae: 0.7183 - val_loss: 0.2114 - val_mae: 0.2444\n",
            "Epoch 200/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7337 - mae: 0.6298 - val_loss: 0.2448 - val_mae: 0.2961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Final loss: {loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLwk8eAlZAcE",
        "outputId": "104b98e7-3bae-4867-851d-d7169927f27d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step - loss: 0.2796 - mae: 0.3277\n",
            "Final loss: [0.27962037920951843, 0.3277122378349304]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Fc4p0TWo_ec0",
        "outputId": "a5c4167e-94f0-4857-c6a2-292166795c4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_log = model.predict(X_test)\n",
        "y_pred = np.expm1(y_pred_log)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6pkG9LHcpQN",
        "outputId": "8d23624a-9ef1-405a-ebd9-0cdb7e4ece6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sA1t5OvYd6vr",
        "outputId": "01f57e92-c813-4089-e738-65ddcc639fd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Brand', 'Model', 'Storage', 'RAM', 'Screen_Size_(inches)',\n",
              "       'Camera_(MP)', 'Battery_Capacity_(mAh)', 'Price_($)'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Misalkan target adalah array atau seri dari target Anda\n",
        "plt.hist(target, bins=30)\n",
        "plt.xlabel('Target Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Target')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "gBIFoXSVokuR",
        "outputId": "7ccf9476-100c-4ef4-a436-62c04bbeedf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import skew\n",
        "\n",
        "# Menghitung skewness\n",
        "target_skewness = skew(target)\n",
        "print(f'Skewness of target: {target_skewness}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFf5431Tpjah",
        "outputId": "e78c10d4-0d57-4548-e16a-0fdfaf26c31a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skewness of target: 1.437602187927131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_data_dict = {\n",
        "    'Brand': ['Asus'],\n",
        "    'Model': ['Zenfone 8 Flip'],\n",
        "    'Storage': ['256 GB'],\n",
        "    'RAM': ['8 GB'],\n",
        "    'Screen_Size_(inches)': [6.67],\n",
        "    'Camera_(MP)': [64],\n",
        "    'Battery_Capacity_(mAh)':[5000]\n",
        "}\n",
        "\n",
        "new_data = pd.DataFrame(new_data_dict)\n",
        "\n",
        "new_data['Brand'] = label_encoders['Brand'].transform(new_data['Brand'])\n",
        "new_data['Model'] = label_encoders['Model'].transform(new_data['Model'])\n",
        "\n",
        "new_data['Storage'] = new_data['Storage'].apply(convert_memory_size)\n",
        "new_data['RAM'] = new_data['RAM'].apply(convert_memory_size)\n",
        "\n",
        "new_data_normalized = scaler.transform(new_data)\n",
        "\n",
        "predicted_log_price = model.predict(new_data_normalized)\n",
        "predicted_price = np.expm1(predicted_log_price)\n",
        "\n",
        "print(f'Predicted price: {predicted_price[0][0]}')"
      ],
      "metadata": {
        "id": "iRoz15tvcvbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# new_data = pd.DataFrame(new_data_dict)"
      ],
      "metadata": {
        "id": "dbZKz1O9dlkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# new_data['Brand'] = label_encoders['Brand'].transform(new_data['Brand'])\n",
        "# new_data['Model'] = label_encoders['Model'].transform(new_data['Model'])"
      ],
      "metadata": {
        "id": "YQb7F3Vndqhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# new_data['Storage'] = new_data['Storage'].apply(convert_memory_size)\n",
        "# new_data['RAM'] = new_data['RAM'].apply(convert_memory_size)"
      ],
      "metadata": {
        "id": "Z-oPrneIdtkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# new_data_normalized = scaler.transform(new_data)"
      ],
      "metadata": {
        "id": "r1Nzu2Zkdvbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hJ0jQzkA2JDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicted_log_price = model.predict(new_data_normalized)\n",
        "# predicted_price = np.expm1(predicted_log_price)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq5IgMU6efX7",
        "outputId": "e91d8517-fb6f-43f2-91e4-d2838e1510cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f'Predicted price: {predicted_price[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gsxfHHpeg38",
        "outputId": "a8dd94ab-3a67-4e58-abf6-be24ebdbc67c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted price: 595.2063598632812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-SNRxQkASFa",
        "outputId": "3ec4550f-bc85-413a-82cc-555ddb10bb37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [[151.889  ]\n",
            " [213.56593]\n",
            " [326.3517 ]\n",
            " [224.8072 ]\n",
            " [149.2234 ]\n",
            " [321.50934]\n",
            " [333.8423 ]\n",
            " [287.91208]\n",
            " [181.11902]\n",
            " [250.1716 ]\n",
            " [642.9204 ]\n",
            " [326.3517 ]\n",
            " [123.35556]\n",
            " [163.18567]\n",
            " [156.1041 ]\n",
            " [119.00773]\n",
            " [275.6083 ]\n",
            " [432.81677]\n",
            " [657.635  ]\n",
            " [211.5443 ]\n",
            " [163.78113]\n",
            " [476.73715]\n",
            " [233.23459]\n",
            " [143.94669]\n",
            " [502.47293]\n",
            " [154.82138]\n",
            " [575.8034 ]\n",
            " [207.65924]\n",
            " [219.03978]\n",
            " [305.84045]\n",
            " [291.78683]\n",
            " [247.92113]\n",
            " [422.36752]\n",
            " [193.8621 ]\n",
            " [218.41376]\n",
            " [309.1381 ]\n",
            " [163.18567]\n",
            " [801.47314]\n",
            " [344.5478 ]\n",
            " [437.43347]\n",
            " [139.19478]\n",
            " [317.85202]\n",
            " [115.03202]\n",
            " [575.5864 ]\n",
            " [655.03314]\n",
            " [502.43622]\n",
            " [299.2625 ]\n",
            " [322.96417]\n",
            " [241.60187]\n",
            " [231.5796 ]\n",
            " [127.14865]\n",
            " [204.15656]\n",
            " [207.65924]\n",
            " [276.35876]\n",
            " [336.07834]\n",
            " [253.42418]\n",
            " [307.4697 ]\n",
            " [325.40918]\n",
            " [281.52563]\n",
            " [546.55054]\n",
            " [788.97205]\n",
            " [227.08568]\n",
            " [289.12515]\n",
            " [182.81252]\n",
            " [235.98856]\n",
            " [213.3747 ]\n",
            " [314.5141 ]\n",
            " [110.24742]\n",
            " [174.19894]\n",
            " [225.82312]\n",
            " [100.30241]\n",
            " [238.3745 ]\n",
            " [143.94669]\n",
            " [167.04892]\n",
            " [207.51712]\n",
            " [321.50934]\n",
            " [332.9363 ]\n",
            " [295.82745]\n",
            " [ 95.31555]\n",
            " [287.59128]\n",
            " [471.63605]]\n",
            "Actual: [[0.00000000e+000 5.70584279e+100 3.88770841e+055 ... 1.62753791e+005\n",
            "              inf             inf]\n",
            " [1.62753791e+005 2.68811714e+043 1.51142767e+111 ... 8.01316426e+046\n",
            "              inf             inf]\n",
            " [8.10208393e+003 1.78482300e+008 3.88770841e+055 ... 7.01673591e+020\n",
            "              inf             inf]\n",
            " ...\n",
            " [0.00000000e+000 2.84077185e+099 3.88770841e+055 ... 1.62753791e+005\n",
            "              inf             inf]\n",
            " [2.20254658e+004 4.43979173e+081 3.88770841e+055 ... 7.01673591e+020\n",
            "              inf 2.05273429e+186]\n",
            " [1.62753791e+005 4.92345829e+041 3.88770841e+055 ... 7.01673591e+020\n",
            "              inf 7.19645734e+281]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-141-c1858f19a102>:3: RuntimeWarning: overflow encountered in expm1\n",
            "  print(\"Actual:\", np.expm1(data.values))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STOP**"
      ],
      "metadata": {
        "id": "t4s9Ku7D6sZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#bersihin kolom\n",
        "df.columns = df.columns.str.strip()\n",
        "df.columns = df.columns.str.replace(' ', '_')"
      ],
      "metadata": {
        "id": "bRwzShQJsdWB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "af11a0c9-0127-44c5-b603-d7f93cf9e175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-44abfa252d3c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#bersihin kolom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Brand'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXShGtXIsc7Y",
        "outputId": "194a49d7-18dc-45d2-d262-9cb97803d402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Brand\n",
              "Samsung       79\n",
              "Xiaomi        67\n",
              "Oppo          56\n",
              "Realme        43\n",
              "Vivo          35\n",
              "Apple         30\n",
              "Nokia         28\n",
              "Motorola      23\n",
              "OnePlus       15\n",
              "Huawei        12\n",
              "Google         7\n",
              "Asus           4\n",
              "LG             3\n",
              "Blackberry     3\n",
              "Sony           1\n",
              "CAT            1\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arLSocast2MI",
        "outputId": "a9e1522c-416c-4364-8201-3dc890fe219f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "hzxb1aBRuOzn",
        "outputId": "96e2573f-5660-4f92-dd49-cd0bd05002fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Brand              Model Storage    RAM Screen_Size_(inches)  \\\n",
              "0      Apple      iPhone 13 Pro  128 GB   6 GB                  6.1   \n",
              "1    Samsung   Galaxy S21 Ultra  256 GB  12 GB                  6.8   \n",
              "2    OnePlus              9 Pro  128 GB   8 GB                  6.7   \n",
              "3     Xiaomi  Redmi Note 10 Pro  128 GB   6 GB                 6.67   \n",
              "4     Google            Pixel 6  128 GB   8 GB                  6.4   \n",
              "..       ...                ...     ...    ...                  ...   \n",
              "402  Samsung   Galaxy Note20 5G     128      8                  6.7   \n",
              "403   Xiaomi      Mi 10 Lite 5G     128      6                 6.57   \n",
              "404    Apple  iPhone 12 Pro Max     128      6                  6.7   \n",
              "405     Oppo              Reno3     128      8                  6.4   \n",
              "406  Samsung    Galaxy S10 Lite     128      6                  6.7   \n",
              "\n",
              "            Camera_(MP)  Battery_Capacity_(mAh) Price_($)  \n",
              "0          12 + 12 + 12                    3095       999  \n",
              "1    108 + 10 + 10 + 12                    5000      1199  \n",
              "2       48 + 50 + 8 + 2                    4500       899  \n",
              "3        64 + 8 + 5 + 2                    5020       279  \n",
              "4             50 + 12.2                    4614       799  \n",
              "..                  ...                     ...       ...  \n",
              "402            12+64+12                    4300      1049  \n",
              "403            48+8+2+2                    4160       349  \n",
              "404            12+12+12                    3687      1099  \n",
              "405           48+13+8+2                    4025       429  \n",
              "406             48+12+5                    4500       649  \n",
              "\n",
              "[407 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29a5de51-eef6-4c89-9ad3-de14c971a49e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Brand</th>\n",
              "      <th>Model</th>\n",
              "      <th>Storage</th>\n",
              "      <th>RAM</th>\n",
              "      <th>Screen_Size_(inches)</th>\n",
              "      <th>Camera_(MP)</th>\n",
              "      <th>Battery_Capacity_(mAh)</th>\n",
              "      <th>Price_($)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Apple</td>\n",
              "      <td>iPhone 13 Pro</td>\n",
              "      <td>128 GB</td>\n",
              "      <td>6 GB</td>\n",
              "      <td>6.1</td>\n",
              "      <td>12 + 12 + 12</td>\n",
              "      <td>3095</td>\n",
              "      <td>999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Samsung</td>\n",
              "      <td>Galaxy S21 Ultra</td>\n",
              "      <td>256 GB</td>\n",
              "      <td>12 GB</td>\n",
              "      <td>6.8</td>\n",
              "      <td>108 + 10 + 10 + 12</td>\n",
              "      <td>5000</td>\n",
              "      <td>1199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>OnePlus</td>\n",
              "      <td>9 Pro</td>\n",
              "      <td>128 GB</td>\n",
              "      <td>8 GB</td>\n",
              "      <td>6.7</td>\n",
              "      <td>48 + 50 + 8 + 2</td>\n",
              "      <td>4500</td>\n",
              "      <td>899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Xiaomi</td>\n",
              "      <td>Redmi Note 10 Pro</td>\n",
              "      <td>128 GB</td>\n",
              "      <td>6 GB</td>\n",
              "      <td>6.67</td>\n",
              "      <td>64 + 8 + 5 + 2</td>\n",
              "      <td>5020</td>\n",
              "      <td>279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Google</td>\n",
              "      <td>Pixel 6</td>\n",
              "      <td>128 GB</td>\n",
              "      <td>8 GB</td>\n",
              "      <td>6.4</td>\n",
              "      <td>50 + 12.2</td>\n",
              "      <td>4614</td>\n",
              "      <td>799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>Samsung</td>\n",
              "      <td>Galaxy Note20 5G</td>\n",
              "      <td>128</td>\n",
              "      <td>8</td>\n",
              "      <td>6.7</td>\n",
              "      <td>12+64+12</td>\n",
              "      <td>4300</td>\n",
              "      <td>1049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>403</th>\n",
              "      <td>Xiaomi</td>\n",
              "      <td>Mi 10 Lite 5G</td>\n",
              "      <td>128</td>\n",
              "      <td>6</td>\n",
              "      <td>6.57</td>\n",
              "      <td>48+8+2+2</td>\n",
              "      <td>4160</td>\n",
              "      <td>349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404</th>\n",
              "      <td>Apple</td>\n",
              "      <td>iPhone 12 Pro Max</td>\n",
              "      <td>128</td>\n",
              "      <td>6</td>\n",
              "      <td>6.7</td>\n",
              "      <td>12+12+12</td>\n",
              "      <td>3687</td>\n",
              "      <td>1099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405</th>\n",
              "      <td>Oppo</td>\n",
              "      <td>Reno3</td>\n",
              "      <td>128</td>\n",
              "      <td>8</td>\n",
              "      <td>6.4</td>\n",
              "      <td>48+13+8+2</td>\n",
              "      <td>4025</td>\n",
              "      <td>429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>406</th>\n",
              "      <td>Samsung</td>\n",
              "      <td>Galaxy S10 Lite</td>\n",
              "      <td>128</td>\n",
              "      <td>6</td>\n",
              "      <td>6.7</td>\n",
              "      <td>48+12+5</td>\n",
              "      <td>4500</td>\n",
              "      <td>649</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>407 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29a5de51-eef6-4c89-9ad3-de14c971a49e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-29a5de51-eef6-4c89-9ad3-de14c971a49e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-29a5de51-eef6-4c89-9ad3-de14c971a49e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e39ead84-f713-48d4-b06f-81ddfc8a8de5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e39ead84-f713-48d4-b06f-81ddfc8a8de5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e39ead84-f713-48d4-b06f-81ddfc8a8de5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 407,\n  \"fields\": [\n    {\n      \"column\": \"Brand\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"Apple\",\n          \"Samsung\",\n          \"Oppo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 239,\n        \"samples\": [\n          \"Redmi Note 10 Pro Max\",\n          \"Galaxy Z Flip3\",\n          \"Velvet 5G\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Storage\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"512\",\n          \"64\",\n          \"128 GB\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RAM\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"6 GB\",\n          \"4\",\n          \"6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Screen_Size_(inches)\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 41,\n        \"samples\": [\n          \"5.5\",\n          \"6.6\",\n          \"6.5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Camera_(MP)\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 143,\n        \"samples\": [\n          \"50+8+16+2\",\n          \"108 + 8 + 5 + 2\",\n          \"48MP + 5MP + 2MP + 2MP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Battery_Capacity_(mAh)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 797,\n        \"min\": 1821,\n        \"max\": 7000,\n        \"num_unique_values\": 48,\n        \"samples\": [\n          5050,\n          3174,\n          4950\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price_($)\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 89,\n        \"samples\": [\n          \"$319 \",\n          \"$139 \",\n          \"1299\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baris_duplikat = df[df.duplicated()]\n",
        "print(baris_duplikat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyHOhghLufaf",
        "outputId": "263cdd56-f412-4bff-c075-9e13bf39cc50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Brand                  Model Storage   RAM Screen_Size_(inches)  \\\n",
            "45      Apple         iPhone 12 Mini   64 GB  4 GB                  5.4   \n",
            "61     Xiaomi         Poco M3 Pro 5G   64 GB  4 GB                  6.5   \n",
            "132     Nokia                   XR20   128GB   6GB                 6.67   \n",
            "170  Motorola       Moto G Stylus 5G   128GB   5GB                  6.8   \n",
            "195      Oppo                 A74 5G   128GB   6GB                  6.5   \n",
            "221      Vivo                   Y12s    32GB   3GB                 6.51   \n",
            "229    Xiaomi  Redmi Note 10 Pro Max   128GB   8GB                 6.67   \n",
            "240     Nokia               C20 Plus    32GB   3GB                  6.5   \n",
            "246    Xiaomi            Poco X3 Pro   128GB   6GB                 6.67   \n",
            "248      Oppo                    A16    32GB   3GB                 6.52   \n",
            "260      Vivo                   Y12s    32GB   3GB                 6.51   \n",
            "282   Samsung             Galaxy A12    64GB   4GB                  6.5   \n",
            "331    Xiaomi            Poco X3 Pro     128     6                 6.67   \n",
            "332    Google                Pixel 5     128     8                    6   \n",
            "333     Apple       iPhone SE (2020)      64     3                  4.7   \n",
            "353     Nokia                 8.3 5G     128     8                 6.81   \n",
            "356   Samsung             Galaxy A12     128     4                  6.5   \n",
            "357      Oppo                 A94 5G     128     8                 6.43   \n",
            "365     Nokia                    5.4      64     4                 6.39   \n",
            "377   Samsung       Galaxy S20 FE 5G     128     6                  6.5   \n",
            "381   Samsung          Galaxy A32 5G     128     4                  6.5   \n",
            "382   OnePlus            Nord N10 5G     128     6                 6.49   \n",
            "389    Xiaomi               Redmi 9T     128     4                 6.53   \n",
            "390    Google                Pixel 5     128     8                    6   \n",
            "398   Samsung          Galaxy A52 5G     128     6                  6.5   \n",
            "406   Samsung        Galaxy S10 Lite     128     6                  6.7   \n",
            "\n",
            "                 Camera_(MP)  Battery_Capacity_(mAh) Price_($)  \n",
            "45                   12 + 12                    2227       699  \n",
            "61                48 + 2 + 2                    5000       199  \n",
            "132              48MP + 13MP                    4630     $549   \n",
            "170         48MP + 8MP + 5MP                    5000     $399   \n",
            "195         48MP + 2MP + 2MP                    5000     $299   \n",
            "221               13MP + 2MP                    5000     $149   \n",
            "229  108MP + 8MP + 5MP + 2MP                    5020     $329   \n",
            "240                8MP + 2MP                    4950      $99   \n",
            "246   48MP + 8MP + 2MP + 2MP                    5160     $249   \n",
            "248         13MP + 2MP + 2MP                    5000     $149   \n",
            "260               13MP + 2MP                    5000     $149   \n",
            "282   48MP + 5MP + 2MP + 2MP                    5000     $179   \n",
            "331                 48+8+2+2                    5160       249  \n",
            "332                  12.2+16                    4080       699  \n",
            "333                       12                    1821       399  \n",
            "353                64+12+2+2                    4500       499  \n",
            "356                 48+5+2+2                    5000       179  \n",
            "357                 48+8+2+2                    4310       399  \n",
            "365                 48+5+2+2                    4000       179  \n",
            "377                  12+12+8                    4500       699  \n",
            "381                 48+8+5+2                    5000       279  \n",
            "382                 64+8+2+2                    4300       299  \n",
            "389                 48+8+2+2                    6000       199  \n",
            "390                  12.2+16                    4080       699  \n",
            "398                64+12+5+5                    4500       449  \n",
            "406                  48+12+5                    4500       649  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isna().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk0Ko34cunSX",
        "outputId": "463fbcd0-2afe-4cac-dbb8-c747f0884dcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brand                     0\n",
            "Model                     0\n",
            "Storage                   0\n",
            "RAM                       0\n",
            "Screen_Size_(inches)      0\n",
            "Camera_(MP)               0\n",
            "Battery_Capacity_(mAh)    0\n",
            "Price_($)                 0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_wLMg0jvgyW",
        "outputId": "c59aa4d2-0a9f-43d8-f923-7eaf7b365945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Brand                     object\n",
              "Model                     object\n",
              "Storage                   object\n",
              "RAM                       object\n",
              "Screen_Size_(inches)      object\n",
              "Camera_(MP)               object\n",
              "Battery_Capacity_(mAh)     int64\n",
              "Price_($)                 object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Storage'] = df['Storage'].str.replace('GB','')"
      ],
      "metadata": {
        "id": "pIICcb4Fv4Xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['RAM'] = df['RAM'].str.replace('GB','')"
      ],
      "metadata": {
        "id": "ESwf-bKkvtKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Storage'].tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIBCrbhzv-YW",
        "outputId": "63857c63-9254-43fb-8944-adc3f0c0560c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "402    128\n",
              "403    128\n",
              "404    128\n",
              "405    128\n",
              "406    128\n",
              "Name: Storage, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Camera_(MP)\"] = df[\"Camera_(MP)\"].str.replace(\"MP\",\"\")\n",
        "df[\"Camera_(MP)\"] = df[\"Camera_(MP)\"].str.replace(\"D\",\"\")"
      ],
      "metadata": {
        "id": "rtuc7zTzwB8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['Camera_(MP)'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Vl2d4mQws8A",
        "outputId": "061254e2-c3ba-45cb-c5ad-a31100814665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0            12 + 12 + 12\n",
            "1      108 + 10 + 10 + 12\n",
            "2         48 + 50 + 8 + 2\n",
            "3          64 + 8 + 5 + 2\n",
            "4               50 + 12.2\n",
            "              ...        \n",
            "402              12+64+12\n",
            "403              48+8+2+2\n",
            "404              12+12+12\n",
            "405             48+13+8+2\n",
            "406               48+12+5\n",
            "Name: Camera_(MP), Length: 407, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Camera_(MP)\"] = df[\"Camera_(MP)\"].str.split(\"+\")"
      ],
      "metadata": {
        "id": "aeSy83R3woq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['Camera_(MP)'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GCe0OMBwzW2",
        "outputId": "3169578d-7a3d-4854-c84b-162daafddc30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0             [12 ,  12 ,  12]\n",
            "1      [108 ,  10 ,  10 ,  12]\n",
            "2         [48 ,  50 ,  8 ,  2]\n",
            "3          [64 ,  8 ,  5 ,  2]\n",
            "4                 [50 ,  12.2]\n",
            "                ...           \n",
            "402               [12, 64, 12]\n",
            "403              [48, 8, 2, 2]\n",
            "404               [12, 12, 12]\n",
            "405             [48, 13, 8, 2]\n",
            "406                [48, 12, 5]\n",
            "Name: Camera_(MP), Length: 407, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "listx = []\n",
        "for i in df.index:\n",
        "    listx.append(df[\"Camera_(MP)\"][i][0])\n",
        "\n",
        "df[\"Camera_(MP)\"] = listx\n",
        "df[\"Camera_(MP)\"] = df[\"Camera_(MP)\"].astype(\"float64\")"
      ],
      "metadata": {
        "id": "-T0yBfpaw0hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Camera_(MP)\"] = listx\n"
      ],
      "metadata": {
        "id": "GXvzpGMnxRPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Camera_(MP)\"] = df[\"Camera_(MP)\"].astype(\"float64\")"
      ],
      "metadata": {
        "id": "8BzRMNwhxSat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Screen_Size_(inches)'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAs_6Hs7xT5u",
        "outputId": "499a239e-e8ff-44b4-bdfd-181d84216bb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['6.1', '6.8', '6.7', '6.67', '6.4', '6.55', '6.78', '6.43', '6.5',\n",
              "       '6.62', '5.4', '6.2', '6.51', '6.6', '4.7', '6.58', '6.52', '6.44',\n",
              "       '6.53', '6.56', '6.8 + 3.9', '4.5', '6.39', '5.9', '5.5', '6.81',\n",
              "       '5.99', '6.82', '6.3', '6.22', '6', '6.35', '6.9', '6.76', '6.49',\n",
              "       '6.72', '5.7', '6.47', '7.6 (unfolded)', '6.15', '6.57'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "tGiIvdj7xlFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h9LOKqNuVJHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GbMzB_ypVJE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[~(df[\"Screen_Size_(inches)\"] == \"6.8 + 3.9\")]\n"
      ],
      "metadata": {
        "id": "5_4IHq3Mxnrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Screen_Size_(inches)\"] = df[\"Screen_Size_(inches)\"].astype(\"float64\")\n"
      ],
      "metadata": {
        "id": "ThL2wBVJxo63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Price_($)'] = pd.to_numeric(df['Price_($)'] , errors='coerce')\n"
      ],
      "metadata": {
        "id": "lFcV8849xqzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Storage'] = pd.to_numeric(df['Storage'] , errors='coerce')\n"
      ],
      "metadata": {
        "id": "nTB0NNZ6xr7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['RAM'] = pd.to_numeric(df['RAM'] , errors='coerce')\n"
      ],
      "metadata": {
        "id": "mVW9qgwVxtQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qrsy_kExvS_",
        "outputId": "eecd6ae0-4085-49f2-eed5-1f42f4c755d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 405 entries, 0 to 406\n",
            "Data columns (total 8 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   Brand                   405 non-null    object \n",
            " 1   Model                   405 non-null    object \n",
            " 2   Storage                 405 non-null    int64  \n",
            " 3   RAM                     405 non-null    int64  \n",
            " 4   Screen_Size_(inches)    405 non-null    float64\n",
            " 5   Camera_(MP)             405 non-null    float64\n",
            " 6   Battery_Capacity_(mAh)  405 non-null    int64  \n",
            " 7   Price_($)               196 non-null    float64\n",
            "dtypes: float64(3), int64(3), object(2)\n",
            "memory usage: 28.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fsg2w0Xsxwf2",
        "outputId": "0207c471-8b4b-468b-cf00-5ab413dcf380"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(405, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Mean_Price = df['Price_($)'].mean()\n",
        "df['Price_($)'] = df['Price_($)'].fillna(Mean_Price)\n",
        "df['Price_($)'].isnull().sum()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yDaqkiAyAE2",
        "outputId": "792cc615-ebf6-44e3-dfb9-61fc93e142b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "G0dfJ-ccGwNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()"
      ],
      "metadata": {
        "id": "-27xqf0CyLU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Brand = LabelEncoder()\n",
        "Model = LabelEncoder()"
      ],
      "metadata": {
        "id": "hpdO5Za2yOou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Brand'] = Brand.fit_transform(df['Brand'])"
      ],
      "metadata": {
        "id": "Ll-HJh8pya8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Brand'].value_counts()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whPcTK_eyenO",
        "outputId": "7e844af0-ca45-4836-f9d3-1b04f0d1c081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Brand\n",
              "12    78\n",
              "15    67\n",
              "10    56\n",
              "11    43\n",
              "14    35\n",
              "0     30\n",
              "8     28\n",
              "7     23\n",
              "9     15\n",
              "5     12\n",
              "4      7\n",
              "1      4\n",
              "2      3\n",
              "6      2\n",
              "13     1\n",
              "3      1\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Model'] = Model.fit_transform(df['Model'])\n"
      ],
      "metadata": {
        "id": "lZaUtN8Oyf7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(df['Model'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2BGPzOgymZe",
        "outputId": "54d01b51-2ab2-4da1-946c-0096bc7d4d56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "236"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('Price_($)', axis=1)\n",
        "y = df['Price_($)']"
      ],
      "metadata": {
        "id": "zpeczmBQy4XG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "JtsQYn61zCCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xz7xtyTvzFEV",
        "outputId": "32accfa2-ef5a-476f-c146-a1799d5421f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(324, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sSYkg78zH5W",
        "outputId": "d03de59a-9001-4512-aaf6-6b7a8f9b78b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(81, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import kurtosis, skew\n",
        "print(\"Kurtosis:\", kurtosis(df))\n",
        "print(\"Skewness:\", skew(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMBv63T6EcUQ",
        "outputId": "7f8dbd1f-41ad-41f6-e518-8c88716dd185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kurtosis: [ 0.4791262  -1.28235289  9.1229469   0.93762237 18.416921    0.23605118\n",
            "  2.07434686  2.7735876 ]\n",
            "Skewness: [-1.03626745  0.03654801  2.11751345  0.96202142 -3.82247646  0.39728616\n",
            " -0.82255507  1.29805625]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "ro_scaler = RobustScaler()\n",
        "x_train = ro_scaler.fit_transform(X_train)\n",
        "x_test = ro_scaler.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "w5sQXa2HzMFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LroF_em13TT",
        "outputId": "df82ee93-ee8d-48f0-ffab-9b06c60d4da4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.23529412 -0.38589212  0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.94117647  0.48547718  0.         ...  0.24489796  0.\n",
            "   1.44927536]\n",
            " [ 0.94117647  0.52697095  0.         ...  1.3877551   0.31372549\n",
            "   0.02898551]\n",
            " ...\n",
            " [-0.23529412 -0.69294606 -1.         ...  0.08163265 -0.68627451\n",
            "   0.        ]\n",
            " [-0.94117647  0.17842324 -1.         ... -0.81632653 -0.62745098\n",
            "   0.        ]\n",
            " [-0.47058824 -0.78423237  2.         ...  1.63265306  0.\n",
            "  -0.72463768]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=64, input_shape=[X_train.shape[1]], activation='relu'),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "model.fit(X_train, y_train, epochs=1000, batch_size=32, verbose=1, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "sXMNBnh5zerF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c6328936-68d7-4cf6-d9f0-aa0521db43c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "11/11 [==============================] - 2s 23ms/step - loss: 808973.8750 - mae: 782.7282 - val_loss: 93202.0859 - val_mae: 219.8547\n",
            "Epoch 2/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 78725.7266 - mae: 224.9619 - val_loss: 92796.3750 - val_mae: 253.2857\n",
            "Epoch 3/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 71912.7188 - mae: 192.6902 - val_loss: 84282.2500 - val_mae: 203.7842\n",
            "Epoch 4/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 61219.4922 - mae: 165.9338 - val_loss: 77794.4844 - val_mae: 197.0870\n",
            "Epoch 5/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 60044.9492 - mae: 162.3006 - val_loss: 77953.9375 - val_mae: 189.6384\n",
            "Epoch 6/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 59945.9648 - mae: 161.7371 - val_loss: 77049.2344 - val_mae: 188.5699\n",
            "Epoch 7/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 59724.1562 - mae: 164.3644 - val_loss: 76052.2188 - val_mae: 192.5097\n",
            "Epoch 8/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 58698.7109 - mae: 160.7762 - val_loss: 76947.2422 - val_mae: 189.3429\n",
            "Epoch 9/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 58470.8086 - mae: 160.3662 - val_loss: 74544.7031 - val_mae: 187.1525\n",
            "Epoch 10/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 58343.8438 - mae: 161.5816 - val_loss: 74516.9297 - val_mae: 186.2929\n",
            "Epoch 11/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 57666.7656 - mae: 160.7317 - val_loss: 73462.5938 - val_mae: 185.4950\n",
            "Epoch 12/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 59338.2891 - mae: 167.1431 - val_loss: 73251.9531 - val_mae: 185.2162\n",
            "Epoch 13/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 56836.1367 - mae: 160.9860 - val_loss: 71879.6875 - val_mae: 186.1737\n",
            "Epoch 14/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 57039.5352 - mae: 161.4725 - val_loss: 71561.6094 - val_mae: 184.1975\n",
            "Epoch 15/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 58473.5508 - mae: 169.7901 - val_loss: 71526.7266 - val_mae: 183.9512\n",
            "Epoch 16/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 57091.5078 - mae: 164.0169 - val_loss: 69987.8359 - val_mae: 187.2568\n",
            "Epoch 17/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 58859.1367 - mae: 178.1922 - val_loss: 69917.2969 - val_mae: 182.6041\n",
            "Epoch 18/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 55676.8594 - mae: 162.9257 - val_loss: 67038.1406 - val_mae: 188.4457\n",
            "Epoch 19/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 54346.2266 - mae: 162.0532 - val_loss: 68996.9141 - val_mae: 183.1225\n",
            "Epoch 20/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 54539.2656 - mae: 163.1925 - val_loss: 64588.3438 - val_mae: 179.8708\n",
            "Epoch 21/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 51554.0625 - mae: 156.5851 - val_loss: 62764.3086 - val_mae: 178.9408\n",
            "Epoch 22/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 50059.3633 - mae: 155.9702 - val_loss: 61254.0625 - val_mae: 176.3757\n",
            "Epoch 23/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 51218.8750 - mae: 160.8664 - val_loss: 60835.4062 - val_mae: 185.4648\n",
            "Epoch 24/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 49621.9023 - mae: 158.3691 - val_loss: 58793.3203 - val_mae: 174.2275\n",
            "Epoch 25/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 48322.7578 - mae: 156.3651 - val_loss: 59101.7461 - val_mae: 173.8392\n",
            "Epoch 26/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 48350.6680 - mae: 156.0742 - val_loss: 56699.1602 - val_mae: 172.0858\n",
            "Epoch 27/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 47556.0938 - mae: 155.4393 - val_loss: 58905.2227 - val_mae: 175.2147\n",
            "Epoch 28/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 47583.5391 - mae: 161.0490 - val_loss: 54017.9922 - val_mae: 172.8986\n",
            "Epoch 29/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 45500.4492 - mae: 155.8286 - val_loss: 52795.8398 - val_mae: 169.2073\n",
            "Epoch 30/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 44817.0820 - mae: 153.7347 - val_loss: 51780.3945 - val_mae: 168.3572\n",
            "Epoch 31/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 45165.3945 - mae: 155.4130 - val_loss: 50871.1797 - val_mae: 167.3416\n",
            "Epoch 32/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 43970.8164 - mae: 154.7334 - val_loss: 50081.9336 - val_mae: 166.9638\n",
            "Epoch 33/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 43168.8516 - mae: 153.2993 - val_loss: 49292.8594 - val_mae: 165.8303\n",
            "Epoch 34/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 43010.9180 - mae: 153.6579 - val_loss: 54271.8320 - val_mae: 185.3781\n",
            "Epoch 35/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 44892.6562 - mae: 157.8202 - val_loss: 54734.0430 - val_mae: 187.7120\n",
            "Epoch 36/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 54230.7852 - mae: 179.0488 - val_loss: 49431.4062 - val_mae: 165.9331\n",
            "Epoch 37/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 48448.3984 - mae: 171.4774 - val_loss: 67530.7656 - val_mae: 203.6265\n",
            "Epoch 38/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 50510.3750 - mae: 174.6656 - val_loss: 47155.1836 - val_mae: 164.4220\n",
            "Epoch 39/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 45362.9219 - mae: 162.6444 - val_loss: 54358.0117 - val_mae: 188.4329\n",
            "Epoch 40/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 45251.3594 - mae: 164.5298 - val_loss: 46892.5938 - val_mae: 162.9333\n",
            "Epoch 41/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 47058.3555 - mae: 167.3327 - val_loss: 53378.8594 - val_mae: 175.4387\n",
            "Epoch 42/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 44273.1836 - mae: 161.6463 - val_loss: 47804.7031 - val_mae: 164.4969\n",
            "Epoch 43/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 43501.5039 - mae: 159.3882 - val_loss: 48723.8008 - val_mae: 173.2785\n",
            "Epoch 44/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 41786.5234 - mae: 155.9525 - val_loss: 45799.6680 - val_mae: 161.6648\n",
            "Epoch 45/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 41964.2578 - mae: 155.9747 - val_loss: 50582.8867 - val_mae: 170.9475\n",
            "Epoch 46/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 42673.9258 - mae: 158.1847 - val_loss: 44693.6992 - val_mae: 161.2420\n",
            "Epoch 47/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 40047.5547 - mae: 152.2328 - val_loss: 45691.4805 - val_mae: 161.5390\n",
            "Epoch 48/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 41800.0430 - mae: 157.0371 - val_loss: 46553.4922 - val_mae: 168.4740\n",
            "Epoch 49/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 41606.4648 - mae: 154.8213 - val_loss: 43694.4336 - val_mae: 160.0876\n",
            "Epoch 50/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 41247.5703 - mae: 154.4115 - val_loss: 43854.8594 - val_mae: 160.8482\n",
            "Epoch 51/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 40287.4766 - mae: 153.2726 - val_loss: 46322.5273 - val_mae: 163.7465\n",
            "Epoch 52/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 45094.9648 - mae: 166.2374 - val_loss: 55591.3945 - val_mae: 195.1208\n",
            "Epoch 53/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 41601.0703 - mae: 161.0844 - val_loss: 43782.2852 - val_mae: 159.2521\n",
            "Epoch 54/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 39390.0938 - mae: 151.7588 - val_loss: 42913.2266 - val_mae: 158.3449\n",
            "Epoch 55/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 40043.8750 - mae: 152.7690 - val_loss: 49238.8398 - val_mae: 171.4083\n",
            "Epoch 56/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 47913.5820 - mae: 172.5156 - val_loss: 43094.1445 - val_mae: 160.2593\n",
            "Epoch 57/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 40646.4844 - mae: 156.0047 - val_loss: 46089.3086 - val_mae: 170.2939\n",
            "Epoch 58/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 39397.0508 - mae: 150.8640 - val_loss: 42447.6914 - val_mae: 157.8163\n",
            "Epoch 59/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 38462.4844 - mae: 150.5762 - val_loss: 43441.0430 - val_mae: 158.7722\n",
            "Epoch 60/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 42792.7930 - mae: 162.0161 - val_loss: 42551.1914 - val_mae: 157.6173\n",
            "Epoch 61/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 45995.9336 - mae: 167.5063 - val_loss: 44159.9297 - val_mae: 164.3404\n",
            "Epoch 62/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 40000.1406 - mae: 153.1768 - val_loss: 46715.8047 - val_mae: 172.8307\n",
            "Epoch 63/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 40141.5742 - mae: 155.5535 - val_loss: 42661.5781 - val_mae: 159.6113\n",
            "Epoch 64/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 43783.6055 - mae: 162.8759 - val_loss: 42965.1797 - val_mae: 158.4359\n",
            "Epoch 65/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 44815.5625 - mae: 168.3767 - val_loss: 52791.2148 - val_mae: 180.7591\n",
            "Epoch 66/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 44481.8438 - mae: 163.0408 - val_loss: 43887.5078 - val_mae: 160.4803\n",
            "Epoch 67/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 39546.4414 - mae: 157.0894 - val_loss: 47681.6484 - val_mae: 174.4559\n",
            "Epoch 68/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 40721.7734 - mae: 156.3367 - val_loss: 42035.6406 - val_mae: 157.3896\n",
            "Epoch 69/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 38689.4180 - mae: 150.8741 - val_loss: 43463.8320 - val_mae: 163.8148\n",
            "Epoch 70/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 41635.0625 - mae: 158.4868 - val_loss: 39952.9375 - val_mae: 153.8112\n",
            "Epoch 71/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 36982.0352 - mae: 146.4613 - val_loss: 39777.1367 - val_mae: 154.6227\n",
            "Epoch 72/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 36559.5000 - mae: 145.9034 - val_loss: 39665.1680 - val_mae: 153.7841\n",
            "Epoch 73/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 36802.5508 - mae: 145.3698 - val_loss: 39082.4766 - val_mae: 153.7022\n",
            "Epoch 74/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 37430.9492 - mae: 148.7686 - val_loss: 38812.2656 - val_mae: 152.9423\n",
            "Epoch 75/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 36539.2148 - mae: 145.4471 - val_loss: 43008.4570 - val_mae: 161.3114\n",
            "Epoch 76/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 37950.8750 - mae: 147.9987 - val_loss: 38228.7852 - val_mae: 151.7411\n",
            "Epoch 77/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 36037.6016 - mae: 145.3726 - val_loss: 38140.7148 - val_mae: 152.3088\n",
            "Epoch 78/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 35735.7422 - mae: 145.8368 - val_loss: 37883.1992 - val_mae: 150.0913\n",
            "Epoch 79/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 35997.7578 - mae: 145.8470 - val_loss: 37978.1367 - val_mae: 150.7155\n",
            "Epoch 80/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 39126.8906 - mae: 154.7454 - val_loss: 39523.3594 - val_mae: 153.9968\n",
            "Epoch 81/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 37770.7148 - mae: 149.1232 - val_loss: 39767.6758 - val_mae: 154.4518\n",
            "Epoch 82/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 36726.0977 - mae: 148.1824 - val_loss: 37283.8164 - val_mae: 150.0722\n",
            "Epoch 83/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 36694.5742 - mae: 148.7152 - val_loss: 40577.7852 - val_mae: 157.0713\n",
            "Epoch 84/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 37344.3516 - mae: 146.9719 - val_loss: 38119.1367 - val_mae: 151.4251\n",
            "Epoch 85/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 35482.8477 - mae: 145.5058 - val_loss: 38295.7266 - val_mae: 152.6247\n",
            "Epoch 86/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 36341.8438 - mae: 147.3490 - val_loss: 40266.4805 - val_mae: 155.6093\n",
            "Epoch 87/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 37508.1289 - mae: 150.1727 - val_loss: 37295.0859 - val_mae: 149.3140\n",
            "Epoch 88/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 38347.9688 - mae: 149.3062 - val_loss: 39360.1602 - val_mae: 153.1304\n",
            "Epoch 89/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 36620.3984 - mae: 144.3780 - val_loss: 38099.8125 - val_mae: 150.0857\n",
            "Epoch 90/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 35287.9336 - mae: 141.9323 - val_loss: 37511.0742 - val_mae: 148.8975\n",
            "Epoch 91/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 38112.3320 - mae: 153.6005 - val_loss: 46558.6719 - val_mae: 173.8842\n",
            "Epoch 92/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 38014.5430 - mae: 152.5452 - val_loss: 37566.3281 - val_mae: 149.3610\n",
            "Epoch 93/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 35505.1914 - mae: 143.9256 - val_loss: 37056.1094 - val_mae: 149.8072\n",
            "Epoch 94/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 35327.3906 - mae: 142.8819 - val_loss: 37121.7617 - val_mae: 147.9588\n",
            "Epoch 95/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 34644.9062 - mae: 141.9977 - val_loss: 38036.2734 - val_mae: 151.5138\n",
            "Epoch 96/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 35025.1406 - mae: 143.1100 - val_loss: 37156.3203 - val_mae: 147.7807\n",
            "Epoch 97/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 35070.2422 - mae: 144.4622 - val_loss: 37240.1094 - val_mae: 149.3153\n",
            "Epoch 98/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 34550.8164 - mae: 140.2506 - val_loss: 39998.9180 - val_mae: 155.2579\n",
            "Epoch 99/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 37028.4883 - mae: 146.4195 - val_loss: 37146.1992 - val_mae: 148.0001\n",
            "Epoch 100/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 34517.3594 - mae: 142.8410 - val_loss: 39728.0312 - val_mae: 155.5483\n",
            "Epoch 101/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 35074.0820 - mae: 143.3017 - val_loss: 37782.9688 - val_mae: 148.9044\n",
            "Epoch 102/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 36876.8203 - mae: 146.3354 - val_loss: 37532.4023 - val_mae: 148.1481\n",
            "Epoch 103/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 35917.1641 - mae: 143.3946 - val_loss: 41968.4258 - val_mae: 163.3395\n",
            "Epoch 104/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 36987.2695 - mae: 151.4498 - val_loss: 36029.6719 - val_mae: 147.2028\n",
            "Epoch 105/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 36105.8828 - mae: 146.7746 - val_loss: 36441.0039 - val_mae: 147.2347\n",
            "Epoch 106/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 34415.5586 - mae: 140.7375 - val_loss: 36722.7969 - val_mae: 146.6277\n",
            "Epoch 107/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 36805.9023 - mae: 147.4494 - val_loss: 37280.6602 - val_mae: 149.2958\n",
            "Epoch 108/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 36906.9258 - mae: 147.9017 - val_loss: 38028.3750 - val_mae: 149.2420\n",
            "Epoch 109/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 34354.6836 - mae: 140.2789 - val_loss: 36004.9180 - val_mae: 145.6827\n",
            "Epoch 110/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 34134.2656 - mae: 141.0869 - val_loss: 36256.1484 - val_mae: 146.0433\n",
            "Epoch 111/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 34220.7852 - mae: 139.1674 - val_loss: 36469.5469 - val_mae: 145.7105\n",
            "Epoch 112/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 34585.9922 - mae: 143.8635 - val_loss: 38260.9336 - val_mae: 155.6124\n",
            "Epoch 113/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 34679.7930 - mae: 142.7204 - val_loss: 36321.7227 - val_mae: 145.3212\n",
            "Epoch 114/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 37090.3359 - mae: 151.0250 - val_loss: 37800.8008 - val_mae: 149.3867\n",
            "Epoch 115/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 34291.0625 - mae: 141.8083 - val_loss: 37557.1094 - val_mae: 149.7461\n",
            "Epoch 116/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 37621.2266 - mae: 148.2290 - val_loss: 39457.3789 - val_mae: 155.3892\n",
            "Epoch 117/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 37982.1836 - mae: 148.0412 - val_loss: 36630.6836 - val_mae: 148.8576\n",
            "Epoch 118/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 34338.3555 - mae: 142.2607 - val_loss: 38218.2227 - val_mae: 154.9570\n",
            "Epoch 119/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 35807.2422 - mae: 147.4704 - val_loss: 36643.0234 - val_mae: 145.8571\n",
            "Epoch 120/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 34023.8945 - mae: 140.2015 - val_loss: 36679.7422 - val_mae: 148.4518\n",
            "Epoch 121/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 34602.7266 - mae: 142.1493 - val_loss: 36769.0938 - val_mae: 145.6677\n",
            "Epoch 122/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 35602.0469 - mae: 146.2630 - val_loss: 43259.7969 - val_mae: 168.2133\n",
            "Epoch 123/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 37671.7305 - mae: 151.3683 - val_loss: 35798.3984 - val_mae: 143.8856\n",
            "Epoch 124/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 33948.6055 - mae: 139.1809 - val_loss: 35411.6680 - val_mae: 143.7769\n",
            "Epoch 125/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 33496.1211 - mae: 140.4746 - val_loss: 36610.0391 - val_mae: 147.8954\n",
            "Epoch 126/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 36162.7422 - mae: 148.0804 - val_loss: 38538.7344 - val_mae: 149.1510\n",
            "Epoch 127/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 37463.5664 - mae: 149.3452 - val_loss: 34841.8984 - val_mae: 143.8735\n",
            "Epoch 128/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34783.3242 - mae: 143.0051 - val_loss: 35296.8750 - val_mae: 144.3563\n",
            "Epoch 129/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34347.4922 - mae: 140.8283 - val_loss: 39066.3750 - val_mae: 152.3711\n",
            "Epoch 130/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 37963.2461 - mae: 149.3805 - val_loss: 36843.4375 - val_mae: 144.4433\n",
            "Epoch 131/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 33404.9180 - mae: 138.2670 - val_loss: 35409.8594 - val_mae: 148.1256\n",
            "Epoch 132/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 35059.1680 - mae: 145.5173 - val_loss: 35259.4805 - val_mae: 145.1197\n",
            "Epoch 133/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 38058.4336 - mae: 157.7249 - val_loss: 44254.8398 - val_mae: 166.0514\n",
            "Epoch 134/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 38667.6211 - mae: 152.1512 - val_loss: 37151.2852 - val_mae: 146.5916\n",
            "Epoch 135/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 40596.0742 - mae: 154.1104 - val_loss: 37692.9922 - val_mae: 150.8694\n",
            "Epoch 136/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 35710.3906 - mae: 140.9261 - val_loss: 34129.2266 - val_mae: 143.5078\n",
            "Epoch 137/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 33934.2031 - mae: 142.9526 - val_loss: 34794.9375 - val_mae: 142.6195\n",
            "Epoch 138/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33231.9023 - mae: 136.4581 - val_loss: 35215.2266 - val_mae: 145.5946\n",
            "Epoch 139/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 33465.7969 - mae: 138.9984 - val_loss: 34671.2773 - val_mae: 141.8522\n",
            "Epoch 140/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33555.6641 - mae: 140.0217 - val_loss: 34985.3750 - val_mae: 141.7157\n",
            "Epoch 141/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34046.3828 - mae: 144.8379 - val_loss: 33761.7539 - val_mae: 143.8736\n",
            "Epoch 142/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34334.7266 - mae: 140.2670 - val_loss: 35694.6484 - val_mae: 142.7446\n",
            "Epoch 143/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 33808.5039 - mae: 138.2851 - val_loss: 33998.6484 - val_mae: 141.9924\n",
            "Epoch 144/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33120.7227 - mae: 139.1917 - val_loss: 34187.0000 - val_mae: 141.2615\n",
            "Epoch 145/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32724.8496 - mae: 138.9452 - val_loss: 35772.2656 - val_mae: 143.8158\n",
            "Epoch 146/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 36393.3906 - mae: 149.4318 - val_loss: 34433.4492 - val_mae: 142.0888\n",
            "Epoch 147/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34893.1602 - mae: 140.5578 - val_loss: 36272.6367 - val_mae: 150.9057\n",
            "Epoch 148/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33137.0312 - mae: 138.5734 - val_loss: 35712.2148 - val_mae: 144.5850\n",
            "Epoch 149/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 34321.4492 - mae: 143.3443 - val_loss: 34266.6250 - val_mae: 142.0659\n",
            "Epoch 150/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33102.6523 - mae: 140.6089 - val_loss: 35294.0508 - val_mae: 143.7018\n",
            "Epoch 151/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34215.9453 - mae: 141.1756 - val_loss: 34234.4258 - val_mae: 140.1642\n",
            "Epoch 152/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32574.3633 - mae: 134.7428 - val_loss: 35358.6445 - val_mae: 149.0695\n",
            "Epoch 153/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 35282.2656 - mae: 147.1509 - val_loss: 34001.1719 - val_mae: 140.6291\n",
            "Epoch 154/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33077.6836 - mae: 137.3240 - val_loss: 34824.9375 - val_mae: 139.8614\n",
            "Epoch 155/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33125.8750 - mae: 134.7305 - val_loss: 34487.4336 - val_mae: 145.7889\n",
            "Epoch 156/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34423.3320 - mae: 148.5744 - val_loss: 37474.4141 - val_mae: 146.9336\n",
            "Epoch 157/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 35934.0000 - mae: 149.8476 - val_loss: 37997.2461 - val_mae: 147.6792\n",
            "Epoch 158/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34020.0469 - mae: 141.1591 - val_loss: 33863.7148 - val_mae: 140.9526\n",
            "Epoch 159/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32713.4941 - mae: 136.8616 - val_loss: 35230.8633 - val_mae: 149.2446\n",
            "Epoch 160/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33913.7812 - mae: 141.2691 - val_loss: 34132.6836 - val_mae: 139.3311\n",
            "Epoch 161/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 32766.1953 - mae: 135.8047 - val_loss: 33582.3906 - val_mae: 139.1458\n",
            "Epoch 162/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 32414.2344 - mae: 137.2768 - val_loss: 33299.4570 - val_mae: 139.1936\n",
            "Epoch 163/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 32666.5742 - mae: 138.3538 - val_loss: 33623.9727 - val_mae: 139.0648\n",
            "Epoch 164/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32773.1523 - mae: 137.1243 - val_loss: 33440.6992 - val_mae: 141.0337\n",
            "Epoch 165/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32640.2246 - mae: 136.8222 - val_loss: 33716.3398 - val_mae: 140.2567\n",
            "Epoch 166/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 32461.1953 - mae: 137.5691 - val_loss: 34609.8398 - val_mae: 139.2352\n",
            "Epoch 167/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32873.0859 - mae: 133.8160 - val_loss: 34198.4922 - val_mae: 138.8218\n",
            "Epoch 168/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 32009.8770 - mae: 135.0002 - val_loss: 33131.1328 - val_mae: 142.1368\n",
            "Epoch 169/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32395.0703 - mae: 137.4594 - val_loss: 33883.5664 - val_mae: 142.6267\n",
            "Epoch 170/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 34610.7500 - mae: 146.2798 - val_loss: 42561.0273 - val_mae: 157.9670\n",
            "Epoch 171/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34905.9375 - mae: 144.5618 - val_loss: 35188.8633 - val_mae: 143.0981\n",
            "Epoch 172/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 36187.0547 - mae: 147.3635 - val_loss: 34055.2422 - val_mae: 143.0008\n",
            "Epoch 173/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 34362.5234 - mae: 139.3522 - val_loss: 37302.9336 - val_mae: 157.5138\n",
            "Epoch 174/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33410.2578 - mae: 142.6045 - val_loss: 37101.7695 - val_mae: 143.8404\n",
            "Epoch 175/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33857.6445 - mae: 140.6145 - val_loss: 33756.0703 - val_mae: 138.1696\n",
            "Epoch 176/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 32891.2148 - mae: 139.6699 - val_loss: 33557.2344 - val_mae: 139.9143\n",
            "Epoch 177/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 31913.6875 - mae: 135.6798 - val_loss: 35080.9492 - val_mae: 138.8460\n",
            "Epoch 178/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 32677.8730 - mae: 133.0381 - val_loss: 34173.3516 - val_mae: 141.5037\n",
            "Epoch 179/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 31747.3184 - mae: 137.9523 - val_loss: 40447.7109 - val_mae: 153.1797\n",
            "Epoch 180/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 36800.1992 - mae: 149.7991 - val_loss: 36376.7422 - val_mae: 152.2977\n",
            "Epoch 181/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 34447.9688 - mae: 137.4737 - val_loss: 33690.1992 - val_mae: 138.4512\n",
            "Epoch 182/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33139.1484 - mae: 137.7157 - val_loss: 32980.8438 - val_mae: 140.7233\n",
            "Epoch 183/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32426.6855 - mae: 138.7750 - val_loss: 35041.4609 - val_mae: 142.1714\n",
            "Epoch 184/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 32441.4414 - mae: 136.6035 - val_loss: 33693.3164 - val_mae: 140.9503\n",
            "Epoch 185/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 31609.3125 - mae: 135.3725 - val_loss: 34764.7109 - val_mae: 139.4448\n",
            "Epoch 186/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 32492.8203 - mae: 134.1709 - val_loss: 33835.8398 - val_mae: 138.8286\n",
            "Epoch 187/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32147.0215 - mae: 133.7756 - val_loss: 32955.6094 - val_mae: 138.7869\n",
            "Epoch 188/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 32403.1445 - mae: 135.7680 - val_loss: 33682.7969 - val_mae: 144.6427\n",
            "Epoch 189/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 31896.5625 - mae: 135.4324 - val_loss: 33002.4805 - val_mae: 137.1260\n",
            "Epoch 190/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 32114.1602 - mae: 137.2119 - val_loss: 35776.5039 - val_mae: 138.9227\n",
            "Epoch 191/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32099.0527 - mae: 133.0961 - val_loss: 33174.9414 - val_mae: 141.4985\n",
            "Epoch 192/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32235.5371 - mae: 137.9931 - val_loss: 32630.5742 - val_mae: 138.2379\n",
            "Epoch 193/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 32754.8340 - mae: 137.3673 - val_loss: 34185.4141 - val_mae: 137.0544\n",
            "Epoch 194/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 32909.2891 - mae: 141.4997 - val_loss: 35525.7734 - val_mae: 144.7115\n",
            "Epoch 195/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 32716.7012 - mae: 136.4841 - val_loss: 33543.9023 - val_mae: 140.4959\n",
            "Epoch 196/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 32377.2012 - mae: 136.0898 - val_loss: 32605.3770 - val_mae: 137.3445\n",
            "Epoch 197/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 32648.6973 - mae: 138.3098 - val_loss: 34196.6172 - val_mae: 138.3475\n",
            "Epoch 198/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 33807.8281 - mae: 138.3196 - val_loss: 39695.2422 - val_mae: 163.5799\n",
            "Epoch 199/1000\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 34557.7656 - mae: 143.1662 - val_loss: 34237.8477 - val_mae: 137.9323\n",
            "Epoch 200/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 34130.8203 - mae: 144.8268 - val_loss: 33946.0156 - val_mae: 140.7521\n",
            "Epoch 201/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 31755.8145 - mae: 136.2930 - val_loss: 33928.2617 - val_mae: 141.6625\n",
            "Epoch 202/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 32526.5000 - mae: 137.7371 - val_loss: 33879.9219 - val_mae: 141.1113\n",
            "Epoch 203/1000\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 33021.0312 - mae: 142.5051 - val_loss: 33838.5078 - val_mae: 141.4113\n",
            "Epoch 204/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 33116.3086 - mae: 138.7785 - val_loss: 34585.2148 - val_mae: 141.1965\n",
            "Epoch 205/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 33619.6562 - mae: 135.2642 - val_loss: 36620.3281 - val_mae: 155.1271\n",
            "Epoch 206/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 35012.5547 - mae: 146.9513 - val_loss: 33867.5938 - val_mae: 137.7175\n",
            "Epoch 207/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 33799.1836 - mae: 143.8812 - val_loss: 35007.7070 - val_mae: 141.2872\n",
            "Epoch 208/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 31827.3867 - mae: 136.6876 - val_loss: 33056.9766 - val_mae: 138.2987\n",
            "Epoch 209/1000\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 31370.6445 - mae: 134.9861 - val_loss: 35335.0039 - val_mae: 141.0759\n",
            "Epoch 210/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 33357.1797 - mae: 138.5105 - val_loss: 33268.4766 - val_mae: 138.1483\n",
            "Epoch 211/1000\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 32718.5742 - mae: 135.7488 - val_loss: 33930.4062 - val_mae: 142.1416\n",
            "Epoch 212/1000\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 31436.5957 - mae: 131.9709 - val_loss: 33404.8711 - val_mae: 139.1630\n",
            "Epoch 213/1000\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 32447.1758 - mae: 135.6039 - val_loss: 34405.1289 - val_mae: 137.7335\n",
            "Epoch 214/1000\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 31255.6484 - mae: 132.6101 - val_loss: 33084.4492 - val_mae: 139.2148\n",
            "Epoch 215/1000\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 32360.4824 - mae: 136.8005 - val_loss: 34755.6250 - val_mae: 149.6163\n",
            "Epoch 216/1000\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 32147.0254 - mae: 137.9735 - val_loss: 37894.7891 - val_mae: 146.1326\n",
            "Epoch 217/1000\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 33815.8906 - mae: 142.8364 - val_loss: 32473.3086 - val_mae: 140.0829\n",
            "Epoch 218/1000\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 31637.6445 - mae: 133.8805 - val_loss: 33235.4336 - val_mae: 136.9214\n",
            "Epoch 219/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 31122.8359 - mae: 132.9032 - val_loss: 32900.1055 - val_mae: 139.2087\n",
            "Epoch 220/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 30997.3398 - mae: 132.8056 - val_loss: 33199.8945 - val_mae: 136.8995\n",
            "Epoch 221/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 31600.0918 - mae: 137.6978 - val_loss: 33804.6836 - val_mae: 140.9716\n",
            "Epoch 222/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 31477.6328 - mae: 135.2245 - val_loss: 33531.4375 - val_mae: 139.2015\n",
            "Epoch 223/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 31866.2168 - mae: 131.6279 - val_loss: 33406.0938 - val_mae: 138.3902\n",
            "Epoch 224/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 31649.2539 - mae: 133.8203 - val_loss: 32552.9883 - val_mae: 137.0909\n",
            "Epoch 225/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 31306.0527 - mae: 136.8488 - val_loss: 32725.7754 - val_mae: 136.6963\n",
            "Epoch 226/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 31368.4688 - mae: 135.4291 - val_loss: 33196.5859 - val_mae: 137.1153\n",
            "Epoch 227/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 31377.8086 - mae: 135.7103 - val_loss: 32665.7773 - val_mae: 137.9008\n",
            "Epoch 228/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 31291.5098 - mae: 133.5275 - val_loss: 32277.2285 - val_mae: 138.1040\n",
            "Epoch 229/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 31163.2598 - mae: 134.9281 - val_loss: 32890.3359 - val_mae: 140.3774\n",
            "Epoch 230/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 33350.1523 - mae: 140.7738 - val_loss: 35131.4805 - val_mae: 139.2119\n",
            "Epoch 231/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 32132.9590 - mae: 138.0477 - val_loss: 33470.6367 - val_mae: 137.9877\n",
            "Epoch 232/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 30984.1055 - mae: 131.6204 - val_loss: 32873.6289 - val_mae: 138.3388\n",
            "Epoch 233/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 31150.6133 - mae: 136.3762 - val_loss: 34826.2227 - val_mae: 140.1329\n",
            "Epoch 234/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 31923.9531 - mae: 134.1119 - val_loss: 33614.1602 - val_mae: 141.1911\n",
            "Epoch 235/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 31228.1328 - mae: 133.8782 - val_loss: 32481.4824 - val_mae: 138.8238\n",
            "Epoch 236/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 31187.6230 - mae: 138.5571 - val_loss: 38051.0078 - val_mae: 148.1608\n",
            "Epoch 237/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 38062.0625 - mae: 149.9202 - val_loss: 35922.1133 - val_mae: 146.4097\n",
            "Epoch 238/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 32349.9902 - mae: 131.5834 - val_loss: 33373.5234 - val_mae: 138.1194\n",
            "Epoch 239/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 31480.3242 - mae: 135.7875 - val_loss: 33420.3320 - val_mae: 140.6978\n",
            "Epoch 240/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 31874.3555 - mae: 136.6194 - val_loss: 33782.7266 - val_mae: 142.6884\n",
            "Epoch 241/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 38706.3555 - mae: 151.6215 - val_loss: 47982.8672 - val_mae: 168.6204\n",
            "Epoch 242/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 37211.1133 - mae: 146.0255 - val_loss: 34819.8320 - val_mae: 152.4806\n",
            "Epoch 243/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 37909.2578 - mae: 157.7232 - val_loss: 32880.9297 - val_mae: 140.8414\n",
            "Epoch 244/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 36303.4648 - mae: 143.4659 - val_loss: 38293.6680 - val_mae: 158.4356\n",
            "Epoch 245/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 34082.5508 - mae: 138.7201 - val_loss: 36430.3594 - val_mae: 138.8140\n",
            "Epoch 246/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 32094.8613 - mae: 134.8523 - val_loss: 32788.2305 - val_mae: 139.9773\n",
            "Epoch 247/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 32456.1914 - mae: 139.7334 - val_loss: 34058.0000 - val_mae: 147.9281\n",
            "Epoch 248/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 31769.7402 - mae: 134.5412 - val_loss: 33796.3281 - val_mae: 138.6162\n",
            "Epoch 249/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 31263.7871 - mae: 135.0373 - val_loss: 33902.8984 - val_mae: 139.0750\n",
            "Epoch 250/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 31171.5996 - mae: 133.9765 - val_loss: 34001.7539 - val_mae: 147.6314\n",
            "Epoch 251/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 34041.1914 - mae: 147.9602 - val_loss: 44177.1992 - val_mae: 160.4447\n",
            "Epoch 252/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 35189.7383 - mae: 147.2889 - val_loss: 33458.9648 - val_mae: 143.8033\n",
            "Epoch 253/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 33385.8047 - mae: 137.7643 - val_loss: 34196.6133 - val_mae: 146.4272\n",
            "Epoch 254/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 31029.6230 - mae: 136.9106 - val_loss: 34954.2188 - val_mae: 140.3909\n",
            "Epoch 255/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 32133.5039 - mae: 137.7074 - val_loss: 33900.4023 - val_mae: 137.7990\n",
            "Epoch 256/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 31592.8555 - mae: 131.4432 - val_loss: 33634.0039 - val_mae: 138.3755\n",
            "Epoch 257/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 31422.3047 - mae: 132.0736 - val_loss: 33879.1250 - val_mae: 142.0670\n",
            "Epoch 258/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 31202.0488 - mae: 138.2825 - val_loss: 34607.1172 - val_mae: 141.5568\n",
            "Epoch 259/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 33079.7578 - mae: 137.9572 - val_loss: 35838.2773 - val_mae: 148.5474\n",
            "Epoch 260/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 32178.1426 - mae: 133.7026 - val_loss: 33105.8594 - val_mae: 137.3972\n",
            "Epoch 261/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 31634.5332 - mae: 141.0059 - val_loss: 34095.6719 - val_mae: 140.5283\n",
            "Epoch 262/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 31052.5488 - mae: 133.3458 - val_loss: 34205.0820 - val_mae: 138.0947\n",
            "Epoch 263/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 31141.0410 - mae: 132.8166 - val_loss: 33015.5430 - val_mae: 137.5598\n",
            "Epoch 264/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 30965.6855 - mae: 135.6354 - val_loss: 34212.2070 - val_mae: 137.2374\n",
            "Epoch 265/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 32800.4375 - mae: 135.6702 - val_loss: 35652.3906 - val_mae: 151.6623\n",
            "Epoch 266/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 32760.3555 - mae: 139.3288 - val_loss: 33117.5312 - val_mae: 139.4532\n",
            "Epoch 267/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 31145.1719 - mae: 134.0053 - val_loss: 34765.6406 - val_mae: 136.4787\n",
            "Epoch 268/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 30955.8242 - mae: 129.8143 - val_loss: 33562.5977 - val_mae: 138.8857\n",
            "Epoch 269/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 30616.3945 - mae: 132.3378 - val_loss: 33293.6211 - val_mae: 137.1706\n",
            "Epoch 270/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 30615.8789 - mae: 132.6877 - val_loss: 33063.5312 - val_mae: 136.5754\n",
            "Epoch 271/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 30363.9043 - mae: 133.6112 - val_loss: 33728.6172 - val_mae: 138.9706\n",
            "Epoch 272/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 31998.5781 - mae: 134.2046 - val_loss: 34321.5078 - val_mae: 146.0881\n",
            "Epoch 273/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 31590.1641 - mae: 132.2025 - val_loss: 33097.9492 - val_mae: 138.8151\n",
            "Epoch 274/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 34859.9883 - mae: 153.1553 - val_loss: 50524.2031 - val_mae: 177.2740\n",
            "Epoch 275/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 38573.0117 - mae: 153.9237 - val_loss: 36756.4922 - val_mae: 151.0568\n",
            "Epoch 276/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 35041.3477 - mae: 136.3728 - val_loss: 33336.3672 - val_mae: 142.7715\n",
            "Epoch 277/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32942.0625 - mae: 140.8578 - val_loss: 33185.7891 - val_mae: 137.5158\n",
            "Epoch 278/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 30762.5273 - mae: 135.5390 - val_loss: 33737.4844 - val_mae: 136.9047\n",
            "Epoch 279/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 31806.7383 - mae: 134.0827 - val_loss: 32658.0098 - val_mae: 137.2508\n",
            "Epoch 280/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 31019.0254 - mae: 134.7335 - val_loss: 34441.9570 - val_mae: 136.2533\n",
            "Epoch 281/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 31689.7500 - mae: 135.5295 - val_loss: 34601.3906 - val_mae: 136.8463\n",
            "Epoch 282/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 31245.6367 - mae: 133.5353 - val_loss: 33262.1328 - val_mae: 142.0450\n",
            "Epoch 283/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 30971.8770 - mae: 135.7318 - val_loss: 33550.5156 - val_mae: 140.0143\n",
            "Epoch 284/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 32054.7070 - mae: 134.3976 - val_loss: 36446.1836 - val_mae: 136.6645\n",
            "Epoch 285/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 30725.4570 - mae: 127.7758 - val_loss: 35899.2734 - val_mae: 153.2081\n",
            "Epoch 286/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32426.4160 - mae: 139.7837 - val_loss: 36121.6836 - val_mae: 139.1966\n",
            "Epoch 287/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 31120.7969 - mae: 132.0808 - val_loss: 34532.1562 - val_mae: 142.2443\n",
            "Epoch 288/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 31298.1855 - mae: 132.6853 - val_loss: 33662.1836 - val_mae: 139.1454\n",
            "Epoch 289/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 30474.1289 - mae: 132.6232 - val_loss: 33720.5586 - val_mae: 138.8572\n",
            "Epoch 290/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 30289.0156 - mae: 134.4815 - val_loss: 33600.4883 - val_mae: 139.4835\n",
            "Epoch 291/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 30987.8418 - mae: 134.0274 - val_loss: 33110.2969 - val_mae: 142.0317\n",
            "Epoch 292/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 31715.1504 - mae: 136.3123 - val_loss: 33445.3203 - val_mae: 136.7971\n",
            "Epoch 293/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 30421.9297 - mae: 133.1502 - val_loss: 33700.2305 - val_mae: 138.1589\n",
            "Epoch 294/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 31099.0801 - mae: 137.8352 - val_loss: 37739.0508 - val_mae: 147.7022\n",
            "Epoch 295/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34251.9844 - mae: 140.7123 - val_loss: 38198.1484 - val_mae: 160.7344\n",
            "Epoch 296/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 32253.3555 - mae: 136.7875 - val_loss: 37397.2500 - val_mae: 145.3692\n",
            "Epoch 297/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 30945.4531 - mae: 132.9728 - val_loss: 34151.8594 - val_mae: 142.5738\n",
            "Epoch 298/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 30428.6973 - mae: 131.6689 - val_loss: 32994.9492 - val_mae: 137.6481\n",
            "Epoch 299/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 31189.5215 - mae: 138.5115 - val_loss: 32687.9570 - val_mae: 138.0223\n",
            "Epoch 300/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 30590.4102 - mae: 134.6036 - val_loss: 34154.8750 - val_mae: 137.5540\n",
            "Epoch 301/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 30865.4941 - mae: 133.4355 - val_loss: 32679.1016 - val_mae: 136.1662\n",
            "Epoch 302/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 30557.0918 - mae: 132.4726 - val_loss: 35374.9023 - val_mae: 151.2961\n",
            "Epoch 303/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 38335.3125 - mae: 150.7198 - val_loss: 37774.1875 - val_mae: 143.1536\n",
            "Epoch 304/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 33291.2852 - mae: 136.6640 - val_loss: 33659.1094 - val_mae: 139.2047\n",
            "Epoch 305/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 32383.5547 - mae: 136.1401 - val_loss: 33188.5820 - val_mae: 134.2613\n",
            "Epoch 306/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 31230.3613 - mae: 129.9567 - val_loss: 34302.5586 - val_mae: 146.9747\n",
            "Epoch 307/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 31967.9141 - mae: 138.2588 - val_loss: 40445.7617 - val_mae: 152.2757\n",
            "Epoch 308/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33697.7344 - mae: 139.0040 - val_loss: 33444.5781 - val_mae: 141.4202\n",
            "Epoch 309/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 30649.5625 - mae: 130.1427 - val_loss: 32474.6211 - val_mae: 135.8637\n",
            "Epoch 310/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 30662.8672 - mae: 133.5387 - val_loss: 32278.7441 - val_mae: 136.9521\n",
            "Epoch 311/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 31533.4453 - mae: 133.8534 - val_loss: 33826.0625 - val_mae: 143.3001\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-277e9db75dd4>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1793\u001b[0m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1795\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1796\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2721\u001b[0m         \"\"\"\n\u001b[1;32m   2722\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2723\u001b[0;31m             \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2725\u001b[0m     def train_on_batch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/metrics/base_metric.py\u001b[0m in \u001b[0;36mreset_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   4309\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4310\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4311\u001b[0;31m             \u001b[0m_assign_value_to_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4312\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4313\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\u001b[0m in \u001b[0;36m_assign_value_to_variable\u001b[0;34m(variable, value)\u001b[0m\n\u001b[1;32m   4357\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4358\u001b[0m         \u001b[0;31m# For the normal tf.Variable assign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4359\u001b[0;31m         \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;31m# initialize the variable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_handle_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m       \u001b[0mvalue_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    694\u001b[0m   \u001b[0;31m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m   \u001b[0mpreferred_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreferred_dtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m   return tensor_conversion_registry.convert(\n\u001b[0m\u001b[1;32m    697\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccepted_result_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    333\u001b[0m                                          as_ref=False):\n\u001b[1;32m    334\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;31m# Register the conversion function for the \"unconvertible\" types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[0;32m--> 271\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    282\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m   const_tensor = ops._create_graph_constant(  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    294\u001b[0m ) -> ops._EagerTensorBase:\n\u001b[1;32m    295\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teXhhHrS0Fe2",
        "outputId": "abce34a2-c0ae-4252-fbd0-3e8929bf78a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.23529412, -0.38589212,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.94117647,  0.48547718,  0.        , ...,  0.24489796,\n",
              "         0.        ,  1.44927536],\n",
              "       [ 0.94117647,  0.52697095,  0.        , ...,  1.3877551 ,\n",
              "         0.31372549,  0.02898551],\n",
              "       ...,\n",
              "       [-0.23529412, -0.69294606, -1.        , ...,  0.08163265,\n",
              "        -0.68627451,  0.        ],\n",
              "       [-0.94117647,  0.17842324, -1.        , ..., -0.81632653,\n",
              "        -0.62745098,  0.        ],\n",
              "       [-0.47058824, -0.78423237,  2.        , ...,  1.63265306,\n",
              "         0.        , -0.72463768]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xp7DKigM3FpM",
        "outputId": "47f52958-e9a4-46a0-aaf1-fa1c0751036e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 324 entries, 356 to 103\n",
            "Data columns (total 7 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   Brand                   324 non-null    int64  \n",
            " 1   Model                   324 non-null    int64  \n",
            " 2   Storage                 324 non-null    int64  \n",
            " 3   RAM                     324 non-null    int64  \n",
            " 4   Screen_Size_(inches)    324 non-null    float64\n",
            " 5   Camera_(MP)             324 non-null    float64\n",
            " 6   Battery_Capacity_(mAh)  324 non-null    int64  \n",
            "dtypes: float64(2), int64(5)\n",
            "memory usage: 20.2 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyTTOxFj5Xdj",
        "outputId": "5f44ae74-5ba6-4a0e-b145-de029b8c27d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "Index: 324 entries, 356 to 103\n",
            "Series name: Price_($)\n",
            "Non-Null Count  Dtype  \n",
            "--------------  -----  \n",
            "324 non-null    float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 5.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oJPlYf4L553s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}